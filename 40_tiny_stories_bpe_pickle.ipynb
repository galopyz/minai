{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdea3ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp tiny"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3498a5ca",
   "metadata": {},
   "source": [
    "BPE saving .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb8bde8",
   "metadata": {},
   "source": [
    "# Tiny Stories Hackathon\n",
    "> From Cluster of stars study group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc82c861",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc14c85",
   "metadata": {},
   "source": [
    "### Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e940d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from datasets import load_dataset\n",
    "import tiktoken\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor, BoolTensor\n",
    "from minai import *\n",
    "\n",
    "from functools import partial\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4bc327",
   "metadata": {},
   "source": [
    "Grab tiny stories data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b753de94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import json\n",
    "from fastcore.all import *\n",
    "\n",
    "def load_json(path):\n",
    "    \"Load JSON file from path\"\n",
    "    return json.loads(path.read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d2ea13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#50) [Path('/home/kappa/git/minai/TinyStories_All_data/data23.json'),Path('/home/kappa/git/minai/TinyStories_All_data/data11.json'),Path('/home/kappa/git/minai/TinyStories_All_data/data47.json'),Path('/home/kappa/git/minai/TinyStories_All_data/data26.json'),Path('/home/kappa/git/minai/TinyStories_All_data/data42.json'),Path('/home/kappa/git/minai/TinyStories_All_data/data07.json'),Path('/home/kappa/git/minai/TinyStories_All_data/data02.json'),Path('/home/kappa/git/minai/TinyStories_All_data/data13.json'),Path('/home/kappa/git/minai/TinyStories_All_data/data01.json'),Path('/home/kappa/git/minai/TinyStories_All_data/data33.json'),Path('/home/kappa/git/minai/TinyStories_All_data/data09.json'),Path('/home/kappa/git/minai/TinyStories_All_data/data21.json'),Path('/home/kappa/git/minai/TinyStories_All_data/data30.json'),Path('/home/kappa/git/minai/TinyStories_All_data/data12.json'),Path('/home/kappa/git/minai/TinyStories_All_data/data15.json'),Path('/home/kappa/git/minai/TinyStories_All_data/data27.json'),Path('/home/kappa/git/minai/TinyStories_All_data/data48.json'),Path('/home/kappa/git/minai/TinyStories_All_data/data10.json'),Path('/home/kappa/git/minai/TinyStories_All_data/data43.json'),Path('/home/kappa/git/minai/TinyStories_All_data/data20.json')...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|export\n",
    "path = Path.home()/'git/minai/TinyStories_All_data'\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1295d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'story': 'Once upon a time, there was a big cave. In the cave, there lived a big bear. The bear was very bitter. He did not like to play with others. He just wanted to be alone.\\nOne day, a little bird flew into the cave. The bird wanted to play with the bear. The bear did not like this. He tried to tease the bird. The bird did not go away. The bird kept trying to play with the bear.\\nThen, something unexpected happened. The bear started to laugh. He was not bitter anymore. The little bird and the big bear became friends. They played together every day. They were very happy.',\n",
       " 'instruction': {'prompt:': 'Write a short story (3-5 paragraphs) which only uses very simple words that a 3 year old child would understand. The story should use the verb \"tease\", the noun \"cave\" and the adjective \"bitter\". The story has the following features: something unexpected happens / there is a plot twist. Remember to only use simple words!',\n",
       "  'words': ['tease', 'cave', 'bitter'],\n",
       "  'features': ['Twist']},\n",
       " 'summary': 'A bitter bear living alone in a cave is befriended by a persistent little bird who eventually helps him overcome his bitterness and they become friends.',\n",
       " 'source': 'GPT-4'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|export\n",
    "txt_L = L(load_json(path/'data23.json'))\n",
    "txt_L[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4b5dd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GPT-3.5', 'GPT-4'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(o['source'] for o in txt_L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271864f6",
   "metadata": {},
   "source": [
    "There are 55390 entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998fdb38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55390"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|export\n",
    "txt_gpt4 = L([o for o in txt_L if o['source'] == 'GPT-4'])\n",
    "len(txt_gpt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27505b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a big cave. In the cave, there lived a big bear. The bear was very bitter. He did not like to play with others. He just wanted to be alone.\n",
      "One day, a little bird flew into the cave. The bird wanted to play with the bear. The bear did not like this. He tried to tease the bird. The bird did not go away. The bird kept trying to play with the bear.\n",
      "Then, something unexpected happened. The bear started to laugh. He was not bitter anymore. The little bird and the big bear became friends. They played together every day. They were very happy. \n",
      "Once upon a time there was a young girl named Mary. She loved to explore and never stayed still. One day, when Mary was taking a walk, she stumbled across a giant wreck. She was amazed by what she saw and couldn't believe how big it was.\n",
      "Mary was about to walk away when a voice suddenly spoke. It was an old man who was sitting on a nearby bench. He said, \"Young lady, I know you are curious about the wreck but please don't go \n"
     ]
    }
   ],
   "source": [
    "#|export\n",
    "txt_raw = ' '.join([o['story'] for o in txt_gpt4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0f8539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042ba5b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11769"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_vocab(text):\n",
    "    \"Count unique vocabulary words in text\"\n",
    "    clean_text = re.sub(r'[^a-zA-Z\\s]', ' ', text.lower())\n",
    "    words = [w for w in clean_text.split() if w]\n",
    "    return len(set(words)), set(words)\n",
    "\n",
    "vocab_count, unique_words = count_vocab(' '.join([o['story'] for o in txt_gpt4]))\n",
    "vocab_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6393c430",
   "metadata": {},
   "source": [
    "So, we have 11769 words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5986a22c",
   "metadata": {},
   "source": [
    "Let's tokenize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47ac883",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from minbpe import RegexTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e053673f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[257, 2365, 1597]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|export\n",
    "tokenizer = RegexTokenizer()\n",
    "# tokenizer.train(txt_raw, vocab_size=3000)\n",
    "\n",
    "tokenizer.load((path/\"tok3k_regex.model\").name) # loads the model back from disk\n",
    "tokenizer.encode(\"hello world\") # string -> tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48e2a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' while Fred depend'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([1000, 2000, 2999]) # tokens -> string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82ff827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\\\]^_`abcdefghijklmnopqrstuvwxyz{|}~\\x7f������������������������������������������������������������������������'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(list(range(64, 200))) # tokens -> string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb3b69c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Once upon '"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_raw[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9678ea2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[763, 438, 32]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(txt_raw[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b879bec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# Code from llm from scratch\n",
    "class TinyDataset(Dataset):\n",
    "    def __init__(self, txt, tokenizer, ctx_len):\n",
    "        self.inp = []\n",
    "        self.targ = []\n",
    "#         token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "        token_ids = tokenizer.encode(txt)\n",
    "        for i in range(0, len(token_ids) - ctx_len, ctx_len):\n",
    "            inp_chunk = token_ids[i:i + ctx_len]\n",
    "            targ_chunk = token_ids[i + 1: i + ctx_len + 1]\n",
    "            self.inp.append(torch.tensor(inp_chunk))\n",
    "            self.targ.append(torch.tensor(targ_chunk))\n",
    "\n",
    "    def __len__(self): return len(self.inp)\n",
    "\n",
    "    def __getitem__(self, idx): return self.inp[idx], self.targ[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5461646c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2769"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "55390 // 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bbc54a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2224565"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|export\n",
    "# Using around 55k\n",
    "total_len = int(len(txt_raw) // 20)\n",
    "total_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840e533e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2002108"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|export\n",
    "split = int(total_len * .9)\n",
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b3d49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 763,  438,  258,  ..., 1981,  382,  756]),\n",
       " tensor([438, 258, 397,  ..., 382, 756, 377]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|export\n",
    "ctx_len = 1024\n",
    "trn_txts = txt_raw[:split]\n",
    "val_txts = txt_raw[split:total_len]\n",
    "\n",
    "trn_ds = TinyDataset(trn_txts, tokenizer, ctx_len)\n",
    "val_ds = TinyDataset(val_txts, tokenizer, ctx_len)\n",
    "trn_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59936e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Once upon a time, there was a big cave. In the cave, there lived a big bear. The bear was very bitte'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(trn_ds[0][0].tolist())[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06deb6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' upon a time, there was a big cave. In the cave, there lived a big bear. The bear was very bitter. H'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(trn_ds[0][1].tolist())[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08757872",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f8ee24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 1024]), torch.Size([8, 1024]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|export\n",
    "bs = 8\n",
    "\n",
    "trn_dl, val_dl = get_dls(trn_ds, val_ds, bs, drop_last=True)\n",
    "dls = DataLoaders(trn_dl, val_dl)\n",
    "xb,yb = next(iter(trn_dl))\n",
    "xb.shape,yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09aec692",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bad50e3",
   "metadata": {},
   "source": [
    "### SDPA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55093be6",
   "metadata": {},
   "source": [
    "Here's the `MultiHeadAttention` with Causal attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde98356",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class SDPACausalAttentionBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Attention block implementing multi-head causal (masked) attention using\n",
    "    PyTorch's scaled_dot_product_attention (SDPA).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_dim: int,\n",
    "        num_heads: int,\n",
    "        dropout: float = 0.0,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the causal attention block with SDPA implementation.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        if hidden_dim % num_heads != 0: raise Exception(\"hidden_dim not divisible by num_heads\")\n",
    "        self.head_dim = hidden_dim // num_heads\n",
    "        self.num_heads = num_heads\n",
    "        self.Wq, self.Wk, self.Wv = nn.Linear(hidden_dim, hidden_dim), nn.Linear(hidden_dim, hidden_dim), nn.Linear(hidden_dim, hidden_dim)\n",
    "#         self.Wo = nn.Linear(hidden_dim, hidden_dim)\n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        batch_size, seq_len, hidden_dim = x.shape\n",
    "        q,k,v = self.Wq(x), self.Wk(x), self.Wv(x) # [batch_size, seq_len, d_out]\n",
    "\n",
    "        sdpa_ctx = torch.nn.functional.scaled_dot_product_attention(\n",
    "            q.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1,2), \n",
    "            k.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1,2), \n",
    "            v.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1,2), \n",
    "            dropout_p=0.0, is_causal=True, scale=None)\n",
    "        sdpa_ctx = sdpa_ctx.transpose(1,2).view(batch_size, seq_len, -1)\n",
    "#         return self.dropout(self.Wo(sdpa_ctx))\n",
    "        return sdpa_ctx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a2119c",
   "metadata": {},
   "source": [
    "### FeedForward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbab0dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, act=nn.ReLU()):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(in_dim, hidden_dim)\n",
    "        self.act = act\n",
    "        self.l2 = nn.Linear(hidden_dim, in_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.l2(self.act(self.l1(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36280c0f",
   "metadata": {},
   "source": [
    "### Transformer Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd61c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, emb_dim, ctx_len, n_head, drop_out=0, ff_mult=4, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(emb_dim)\n",
    "        self.ln2 = nn.LayerNorm(emb_dim)\n",
    "        self.mha = SDPACausalAttentionBlock(hidden_dim=emb_dim, num_heads=n_head, dropout=drop_out)\n",
    "        self.do = nn.Dropout(drop_out)\n",
    "        self.ff = FeedForward(emb_dim, emb_dim*ff_mult)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        skip1 = x\n",
    "        x = self.ln1(x)\n",
    "        x = self.mha(x)\n",
    "        x = self.do(x)\n",
    "        x = x + skip1\n",
    "        \n",
    "        skip2 = x\n",
    "        x = self.ln2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.do(x)\n",
    "        x = x + skip2\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d382d7ae",
   "metadata": {},
   "source": [
    "### GPT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cf425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(cfg['vocab_sz'], cfg['emb_dim'])\n",
    "        self.pos_emb = nn.Embedding(cfg['vocab_sz'], cfg['emb_dim'])\n",
    "        self.do = nn.Dropout(cfg['drop_out'])\n",
    "        self.tb = nn.Sequential(\n",
    "            *[TransformerBlock(cfg['emb_dim'], cfg['ctx_len'], cfg['n_head'], cfg['drop_out_tb'],\n",
    "                              cfg['ff_mult'], cfg['qkv_bias']) for _ in range(cfg['n_tb'])])\n",
    "        self.final_ln = nn.LayerNorm(cfg['emb_dim'])\n",
    "        self.final_l  = nn.Linear(cfg['emb_dim'], cfg['vocab_sz'])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        bs, seq_len = x.shape\n",
    "        tok = self.token_emb(x)\n",
    "        pos = self.pos_emb(torch.arange(seq_len, device=x.device))\n",
    "        x = self.do(tok + pos)\n",
    "        x = self.tb(x)\n",
    "        x = self.final_ln(x)\n",
    "        x = self.final_l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2225f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_total_params(model): return sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5c38f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_total_memory(model):\n",
    "    total_params = get_total_params(model)\n",
    "    total_size_bytes = total_params * 4   # Assuming fp32\n",
    "    # Convert to megabytes\n",
    "    total_size_mb = total_size_bytes / (1024 * 1024)\n",
    "    print(f\"Total params: {total_params:,}\")\n",
    "    print(f\"Total size: {total_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f022896",
   "metadata": {},
   "source": [
    "### Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc54096",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx is (batch, n_tokens) array of indices in the current context\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]  # Crop current context if it exceeds the supported context size\n",
    "        with torch.no_grad(): logits = model(idx_cond)         # (bs, n_tokens, vocab_sz)\n",
    "        logits = logits[:, -1, :]                              # (bs, vocab_sz)\n",
    "        probas = torch.softmax(logits, dim=-1)                 # (bs, vocab_sz)\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (bs, 1)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)                # (bs, n_tokens+1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511281b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880ff652",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4c8521",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:].to(def_device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c71c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class GenerateTextCB(Callback):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4747a7b",
   "metadata": {},
   "source": [
    "## Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bca503",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from torcheval.metrics import  MulticlassAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d440d568",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class MixedPrecision(TrainCB):\n",
    "    order = DeviceCB.order+10\n",
    "    def __init__(self, n_inp=1, dtype=torch.bfloat16):\n",
    "        super().__init__(n_inp=n_inp)\n",
    "        self.dtype=dtype\n",
    "    \n",
    "    def before_fit(self, learn): self.scaler = torch.amp.GradScaler('cuda')\n",
    "\n",
    "    def before_batch(self, learn):\n",
    "        self.autocast = torch.autocast(\"cuda\", dtype=self.dtype)\n",
    "        self.autocast.__enter__()\n",
    "\n",
    "    def after_loss(self, learn): self.autocast.__exit__(None, None, None)\n",
    "        \n",
    "    def backward(self, learn): self.scaler.scale(learn.loss).backward()\n",
    "\n",
    "    def step(self, learn):\n",
    "        self.scaler.step(learn.opt)\n",
    "        self.scaler.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ba3aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def loss_fn(pred, targ): return F.cross_entropy(pred.flatten(0, 1), targ.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83922cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "cfg = {\n",
    "    'n_tb': 4,    # num transformer blocks\n",
    "    'vocab_sz': 3000,\n",
    "    'emb_dim': 256 // 64,\n",
    "    'ctx_len': ctx_len,\n",
    "    'n_head': 4,\n",
    "    'drop_out': 0,\n",
    "    'drop_out_tb': 0,  # dropout within transformer blocks\n",
    "    'ff_mult': 4,\n",
    "    'qkv_bias': False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72d6941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 39,904\n",
      "Total size: 0.15 MB\n"
     ]
    }
   ],
   "source": [
    "#|export\n",
    "model = torch.compile(GPTModel(cfg).to(def_device), mode=\"reduce-overhead\")\n",
    "get_total_memory(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d44a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class LLMMetricsCB(MetricsCB):\n",
    "    def __init__(self, *ms, **metrics):\n",
    "        super().__init__(*ms, **metrics)\n",
    "    \n",
    "    def after_batch(self, learn):\n",
    "        x,y,*_ = learn.batch\n",
    "        for m in self.metrics.values(): m.update(to_cpu(learn.preds.flatten(0, 1)), y.flatten())\n",
    "        self.loss.update(learn.loss, weight=len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c41f673",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class TinyProgressCB(ProgressCB):\n",
    "#     order = MetricsCB.order+1\n",
    "    def __init__(self, plot=False, table=True): store_attr()\n",
    "    \n",
    "    def _log(self, d): print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd56e4c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/10 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "      <progress value='45' class='' max='62' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      72.58% [45/62 00:13&lt;00:05 16.694]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#|export\n",
    "# opt = torch.optim.AdamW\n",
    "# cbs = [LLMMetricsCB(accuracy=MulticlassAccuracy()), ProgressCB(plot=False), DeviceCB(),  MixedPrecision()]\n",
    "# cbs = [LLMMetricsCB(accuracy=MulticlassAccuracy(device=def_device)), TinyProgressCB(), DeviceCB(), TrainCB()]\n",
    "# learn = Learner(model, dls, loss_func=loss_fn, cbs=cbs, opt_func=opt)\n",
    "# learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639085e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kappa/git/minai/minai/core.py:509: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  def before_fit(self, learn): self.scaler = torch.amp.GradScaler('cuda')\n",
      "/home/kappa/miniforge3/envs/torch_latest/lib/python3.11/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0.000</td>\n",
       "      <td>8.161</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.001</td>\n",
       "      <td>8.139</td>\n",
       "      <td>0</td>\n",
       "      <td>eval</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kappa/miniforge3/envs/torch_latest/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#|export\n",
    "# set_seed(42)\n",
    "# lr, epochs = 3e-4, 1\n",
    "# tmax = epochs * len(dls.train)\n",
    "# sched = partial(lr_scheduler.OneCycleLR, max_lr=lr, total_steps=tmax)\n",
    "# xtra = [BatchSchedCB(sched)]\n",
    "# model = torch.compile(GPTModel(cfg).to(def_device), mode=\"reduce-overhead\")\n",
    "# cbs = [LLMMetricsCB(accuracy=MulticlassAccuracy()), ProgressCB(plot=True), DeviceCB(),  MixedPrecision()]\n",
    "# # cbs = [LLMMetricsCB(accuracy=MulticlassAccuracy()), ProgressCB(plot=True), DeviceCB(), TrainCB()]\n",
    "# learn = Learner(model, dls, loss_func=loss_fn, cbs=cbs+xtra, opt_func=opt)\n",
    "# learn.fit(epochs, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0cf04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# start_context = \"Once upon a time, there lived a bunny in a field. Her name was Lucy. Lucy loved to have feasts and parties with her bunny friends. One day, when Lucy was about to leave for a feast at a friend's house, she realized she's starting to feel sick. She was so weak she could\"\n",
    "# model.eval()\n",
    "# token_ids = generate(\n",
    "#     model=model.eval(),\n",
    "#     idx=text_to_token_ids(\"Once upon a time, there lived a bunny in a field. Her name was Lucy. Lucy loved to have feasts and parties with her bunny friends. One day, when Lucy was about to leave for a feast at a friend's house, she realized she's starting to feel sick. She was so weak she could\", tokenizer).to(def_device),\n",
    "#     max_new_tokens=150,\n",
    "#     context_size=cfg[\"ctx_len\"],\n",
    "#     top_k=25,\n",
    "#     temperature=1\n",
    "# )\n",
    "\n",
    "# print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6af186",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from fastcore.script import *\n",
    "\n",
    "@call_parse\n",
    "def main(\n",
    "    n_tb:Param(\"Number of transformer blocks\", int)=4,\n",
    "    vocab_sz:Param(\"Vocabulary size\", int)=3000,\n",
    "    emb_dim:Param(\"Embedding dimension\", int)=64,\n",
    "    ctx_len:Param(\"Context length\", int)=256,\n",
    "    n_head:Param(\"Number of attention heads\", int)=4,\n",
    "    epochs:Param(\"Number of epochs\", int)=1,\n",
    "    lr:Param(\"Learning rate\", float)=3e-4,\n",
    "    bs:Param(\"Batch size\", int)=4\n",
    "):\n",
    "    \"Run training with specified parameters\"\n",
    "    print(n_tb, vocab_sz, emb_dim, ctx_len, n_head, epochs, lr, bs)\n",
    "    cfg = dict(n_tb=n_tb, vocab_sz=vocab_sz, emb_dim=emb_dim, ctx_len=ctx_len, \n",
    "              n_head=n_head, drop_out=0, drop_out_tb=0, ff_mult=4, qkv_bias=False)\n",
    "    \n",
    "    model = torch.compile(GPTModel(cfg).to(def_device), mode=\"reduce-overhead\")\n",
    "    \n",
    "    cbs = [LLMMetricsCB(accuracy=MulticlassAccuracy()), TinyProgressCB(), DeviceCB(), MixedPrecision()]\n",
    "    learn = Learner(model, dls, loss_func=loss_fn, cbs=cbs, opt_func=torch.optim.AdamW)\n",
    "    \n",
    "    tmax = epochs * len(dls.train)\n",
    "    sched = partial(lr_scheduler.OneCycleLR, max_lr=lr, total_steps=tmax)\n",
    "    xtra = [BatchSchedCB(sched)]\n",
    "    \n",
    "    learn = Learner(model, dls, loss_func=loss_fn, cbs=cbs+xtra, opt_func=torch.optim.AdamW)\n",
    "    learn.fit(epochs, lr=lr)\n",
    "    \n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e289471c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev import nbdev_export; nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682eba64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
