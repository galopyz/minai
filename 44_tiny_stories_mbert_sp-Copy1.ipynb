{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68bbf607",
   "metadata": {},
   "source": [
    "Using \n",
    "- [x] sdpa \n",
    "- [x] optimizer\n",
    "  - [x] AdamW\n",
    "  - [x] StableAdamW\n",
    "- [x] torch.compile \n",
    "- [ ] more data\n",
    "- [x] MixedPrecision()\n",
    "- [ ] lr_sched\n",
    "- [x] Double layer norm\n",
    "- [ ] Using a custom tokenizer.\n",
    "  - [x] Use minBPE\n",
    "  - [ ] Huggingface Tokenizer\n",
    "- [x] GLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c75570",
   "metadata": {},
   "source": [
    "**TODO**:\n",
    "- [ ] modern bert sequence packing + FA2\n",
    "  - [ ] pad token\n",
    "  - [ ] `__length__`\n",
    "- [ ] Gradient accumulation or microbatch.\n",
    "- [ ] W&B logging.\n",
    "- [ ] Train a tokenizer using huggingface.\n",
    "- [ ] Implement positional embedding with `cu_seqlens`.\n",
    "  - [ ] Absolute\n",
    "  - [ ] Rope\n",
    "- [ ] Generate text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb8bde8",
   "metadata": {},
   "source": [
    "# Tiny Stories Hackathon\n",
    "> From Cluster of stars study group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc82c861",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc14c85",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9e940d7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor, BoolTensor\n",
    "\n",
    "from minai import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4bc327",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Grab tiny stories data from hugging face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55e7cd32",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 2119719\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset('roneneldan/TinyStories')\n",
    "trn = ds['train']\n",
    "val = ds['validation']\n",
    "trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "967927c2",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 21990\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6938ed6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from minbpe import RegexTokenizer\n",
    "from fastcore.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dbed3c4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = Path.home()/'git/minai/TinyStories_All_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65a959b1",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[257, 2365, 1597]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = RegexTokenizer()\n",
    "# tokenizer.train(txt_raw, vocab_size=3000)\n",
    "\n",
    "tokenizer.load((path/\"tok3k_regex.model\").name) # loads the model back from disk\n",
    "tokenizer.encode(\"hello world\") # string -> tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b102ef73",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One day, a little girl named Lily found a needle in her room. She knew it was difficult to play with it because it was sharp. Lily wanted to share the needle with her mom, so she could sew a button on her shirt.\\n\\nLily went to her mom and said, \"Mom, I found this needle. Can you share it with me and sew my shirt?\" Her mom smiled and said, \"Yes, Lily, we can share the needle and fix your shirt.\"\\n\\nTogether, they shared the needle and sewed the button on Lily\\'s shirt. It was not difficult for them because they were sharing and helping each other. After they finished, Lily thanked her mom for sharing the needle and fixing her shirt. They both felt happy because they had shared and worked together.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = trn[0]['text']\n",
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1ca6b4c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def txt_to_toks(txt, toker): return toker.encode(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84a08231",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def toks_to_txt(toks, toker): return toker.decode(toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8452255f",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21197"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_txts = 21197\n",
    "num_txts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57d73f42",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "separator=\"\\n\\n\\n\"\n",
    "ctx_len = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d68efb",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We create a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86bf20f2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def transforms(b):\n",
    "    d = {}\n",
    "    d['input_ids'] = [tokenizer.encode(t, allowed_special={\"<|endoftext|>\"}) for t in b['text']]\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59ccdf74",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def batched(iterable, n):\n",
    "    # batched('ABCDEFG', 3) â†’ ABC DEF G\n",
    "    if n < 1:\n",
    "        raise ValueError(\"n must be at least one\")\n",
    "    iterator = iter(iterable)\n",
    "    while batch := list(itertools.islice(iterator, n)):\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d5014bb",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[516, 327, 44, 258, 390, 479, 402, 406, 507, 258]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tds = ds.with_transform(transforms)\n",
    "tds['train'][0]['input_ids'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed48361f",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 2119719\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tds['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13c9317e",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input_ids': [516,\n",
       "   327,\n",
       "   44,\n",
       "   258,\n",
       "   390,\n",
       "   479,\n",
       "   402,\n",
       "   406,\n",
       "   507,\n",
       "   258,\n",
       "   775,\n",
       "   302,\n",
       "   313,\n",
       "   338,\n",
       "   720,\n",
       "   46,\n",
       "   342,\n",
       "   677,\n",
       "   309,\n",
       "   282,\n",
       "   2876,\n",
       "   265,\n",
       "   325,\n",
       "   328,\n",
       "   309,\n",
       "   708,\n",
       "   309,\n",
       "   282,\n",
       "   2073,\n",
       "   46,\n",
       "   406,\n",
       "   407,\n",
       "   265,\n",
       "   850,\n",
       "   261,\n",
       "   775,\n",
       "   302,\n",
       "   328,\n",
       "   338,\n",
       "   386,\n",
       "   44,\n",
       "   391,\n",
       "   392,\n",
       "   468,\n",
       "   459,\n",
       "   119,\n",
       "   258,\n",
       "   1674,\n",
       "   354,\n",
       "   338,\n",
       "   2377,\n",
       "   304,\n",
       "   10,\n",
       "   670,\n",
       "   426,\n",
       "   265,\n",
       "   338,\n",
       "   386,\n",
       "   266,\n",
       "   323,\n",
       "   44,\n",
       "   317,\n",
       "   844,\n",
       "   44,\n",
       "   337,\n",
       "   507,\n",
       "   733,\n",
       "   775,\n",
       "   302,\n",
       "   46,\n",
       "   1127,\n",
       "   349,\n",
       "   850,\n",
       "   309,\n",
       "   328,\n",
       "   524,\n",
       "   266,\n",
       "   459,\n",
       "   119,\n",
       "   627,\n",
       "   2377,\n",
       "   476,\n",
       "   937,\n",
       "   386,\n",
       "   565,\n",
       "   266,\n",
       "   323,\n",
       "   44,\n",
       "   317,\n",
       "   732,\n",
       "   44,\n",
       "   406,\n",
       "   44,\n",
       "   363,\n",
       "   469,\n",
       "   850,\n",
       "   261,\n",
       "   775,\n",
       "   302,\n",
       "   266,\n",
       "   1125,\n",
       "   629,\n",
       "   2377,\n",
       "   505,\n",
       "   10,\n",
       "   2826,\n",
       "   44,\n",
       "   360,\n",
       "   1208,\n",
       "   261,\n",
       "   775,\n",
       "   302,\n",
       "   266,\n",
       "   459,\n",
       "   119,\n",
       "   263,\n",
       "   261,\n",
       "   1674,\n",
       "   354,\n",
       "   406,\n",
       "   384,\n",
       "   2377,\n",
       "   46,\n",
       "   421,\n",
       "   282,\n",
       "   364,\n",
       "   2876,\n",
       "   387,\n",
       "   493,\n",
       "   708,\n",
       "   360,\n",
       "   405,\n",
       "   1714,\n",
       "   266,\n",
       "   1398,\n",
       "   766,\n",
       "   558,\n",
       "   46,\n",
       "   1559,\n",
       "   360,\n",
       "   1699,\n",
       "   44,\n",
       "   406,\n",
       "   943,\n",
       "   338,\n",
       "   386,\n",
       "   387,\n",
       "   1714,\n",
       "   261,\n",
       "   775,\n",
       "   302,\n",
       "   266,\n",
       "   1125,\n",
       "   297,\n",
       "   338,\n",
       "   2377,\n",
       "   46,\n",
       "   312,\n",
       "   722,\n",
       "   536,\n",
       "   377,\n",
       "   708,\n",
       "   360,\n",
       "   365,\n",
       "   1208,\n",
       "   266,\n",
       "   1228,\n",
       "   458,\n",
       "   46]},\n",
       " {'input_ids': [763,\n",
       "   438,\n",
       "   258,\n",
       "   397,\n",
       "   44,\n",
       "   401,\n",
       "   282,\n",
       "   258,\n",
       "   390,\n",
       "   528,\n",
       "   402,\n",
       "   2456,\n",
       "   626,\n",
       "   46,\n",
       "   2456,\n",
       "   626,\n",
       "   508,\n",
       "   265,\n",
       "   483,\n",
       "   737,\n",
       "   266,\n",
       "   325,\n",
       "   313,\n",
       "   261,\n",
       "   631,\n",
       "   46,\n",
       "   2456,\n",
       "   626,\n",
       "   282,\n",
       "   258,\n",
       "   2489,\n",
       "   528,\n",
       "   708,\n",
       "   285,\n",
       "   704,\n",
       "   365,\n",
       "   561,\n",
       "   268,\n",
       "   117,\n",
       "   417,\n",
       "   46,\n",
       "   1213,\n",
       "   462,\n",
       "   268,\n",
       "   117,\n",
       "   417,\n",
       "   586,\n",
       "   2456,\n",
       "   626,\n",
       "   377,\n",
       "   266,\n",
       "   973,\n",
       "   304,\n",
       "   10,\n",
       "   516,\n",
       "   327,\n",
       "   44,\n",
       "   2456,\n",
       "   626,\n",
       "   282,\n",
       "   1402,\n",
       "   817,\n",
       "   313,\n",
       "   261,\n",
       "   527,\n",
       "   634,\n",
       "   285,\n",
       "   382,\n",
       "   258,\n",
       "   346,\n",
       "   501,\n",
       "   46,\n",
       "   284,\n",
       "   501,\n",
       "   365,\n",
       "   664,\n",
       "   1333,\n",
       "   383,\n",
       "   405,\n",
       "   1455,\n",
       "   297,\n",
       "   46,\n",
       "   2456,\n",
       "   626,\n",
       "   532,\n",
       "   756,\n",
       "   261,\n",
       "   1333,\n",
       "   1455,\n",
       "   266,\n",
       "   407,\n",
       "   265,\n",
       "   325,\n",
       "   328,\n",
       "   493,\n",
       "   46,\n",
       "   2456,\n",
       "   626,\n",
       "   2241,\n",
       "   776,\n",
       "   261,\n",
       "   501,\n",
       "   266,\n",
       "   1233,\n",
       "   261,\n",
       "   1333,\n",
       "   1455,\n",
       "   354,\n",
       "   475,\n",
       "   46,\n",
       "   316,\n",
       "   703,\n",
       "   266,\n",
       "   322,\n",
       "   626,\n",
       "   263,\n",
       "   340,\n",
       "   2771,\n",
       "   304,\n",
       "   10,\n",
       "   2120,\n",
       "   626,\n",
       "   477,\n",
       "   328,\n",
       "   261,\n",
       "   1455,\n",
       "   297,\n",
       "   1333,\n",
       "   431,\n",
       "   327,\n",
       "   46,\n",
       "   931,\n",
       "   309,\n",
       "   282,\n",
       "   397,\n",
       "   265,\n",
       "   483,\n",
       "   584,\n",
       "   44,\n",
       "   2456,\n",
       "   626,\n",
       "   677,\n",
       "   285,\n",
       "   1341,\n",
       "   673,\n",
       "   268,\n",
       "   117,\n",
       "   417,\n",
       "   46,\n",
       "   316,\n",
       "   426,\n",
       "   265,\n",
       "   261,\n",
       "   268,\n",
       "   117,\n",
       "   417,\n",
       "   962,\n",
       "   266,\n",
       "   660,\n",
       "   673,\n",
       "   2489,\n",
       "   268,\n",
       "   117,\n",
       "   417,\n",
       "   46,\n",
       "   1139,\n",
       "   44,\n",
       "   2456,\n",
       "   626,\n",
       "   282,\n",
       "   1367,\n",
       "   265,\n",
       "   483,\n",
       "   737,\n",
       "   266,\n",
       "   325,\n",
       "   601,\n",
       "   261,\n",
       "   988,\n",
       "   327,\n",
       "   46,\n",
       "   710,\n",
       "   2456,\n",
       "   626,\n",
       "   636,\n",
       "   992,\n",
       "   933,\n",
       "   886,\n",
       "   46]},\n",
       " {'input_ids': [516,\n",
       "   327,\n",
       "   44,\n",
       "   258,\n",
       "   390,\n",
       "   779,\n",
       "   402,\n",
       "   1221,\n",
       "   282,\n",
       "   2439,\n",
       "   810,\n",
       "   261,\n",
       "   389,\n",
       "   440,\n",
       "   46,\n",
       "   316,\n",
       "   382,\n",
       "   258,\n",
       "   346,\n",
       "   1798,\n",
       "   266,\n",
       "   407,\n",
       "   265,\n",
       "   322,\n",
       "   413,\n",
       "   46,\n",
       "   317,\n",
       "   1090,\n",
       "   44,\n",
       "   337,\n",
       "   743,\n",
       "   1221,\n",
       "   46,\n",
       "   1174,\n",
       "   349,\n",
       "   367,\n",
       "   265,\n",
       "   325,\n",
       "   476,\n",
       "   543,\n",
       "   261,\n",
       "   390,\n",
       "   779,\n",
       "   46,\n",
       "   284,\n",
       "   1798,\n",
       "   506,\n",
       "   450,\n",
       "   1221,\n",
       "   266,\n",
       "   323,\n",
       "   44,\n",
       "   317,\n",
       "   947,\n",
       "   44,\n",
       "   337,\n",
       "   862,\n",
       "   492,\n",
       "   367,\n",
       "   265,\n",
       "   325,\n",
       "   46,\n",
       "   337,\n",
       "   743,\n",
       "   1192,\n",
       "   266,\n",
       "   337,\n",
       "   862,\n",
       "   492,\n",
       "   735,\n",
       "   2916,\n",
       "   505,\n",
       "   10,\n",
       "   1804,\n",
       "   536,\n",
       "   496,\n",
       "   409,\n",
       "   407,\n",
       "   265,\n",
       "   432,\n",
       "   261,\n",
       "   1798,\n",
       "   735,\n",
       "   833,\n",
       "   46,\n",
       "   316,\n",
       "   1588,\n",
       "   583,\n",
       "   266,\n",
       "   578,\n",
       "   371,\n",
       "   258,\n",
       "   1350,\n",
       "   46,\n",
       "   316,\n",
       "   1533,\n",
       "   383,\n",
       "   261,\n",
       "   631,\n",
       "   468,\n",
       "   533,\n",
       "   630,\n",
       "   1061,\n",
       "   46,\n",
       "   707,\n",
       "   44,\n",
       "   1221,\n",
       "   1588,\n",
       "   265,\n",
       "   261,\n",
       "   1306,\n",
       "   371,\n",
       "   261,\n",
       "   686,\n",
       "   266,\n",
       "   1041,\n",
       "   265,\n",
       "   261,\n",
       "   631,\n",
       "   44,\n",
       "   317,\n",
       "   1936,\n",
       "   44,\n",
       "   631,\n",
       "   44,\n",
       "   432,\n",
       "   627,\n",
       "   545,\n",
       "   358,\n",
       "   735,\n",
       "   2916,\n",
       "   266,\n",
       "   364,\n",
       "   1764,\n",
       "   1782,\n",
       "   687,\n",
       "   10,\n",
       "   412,\n",
       "   631,\n",
       "   837,\n",
       "   1221,\n",
       "   384,\n",
       "   946,\n",
       "   266,\n",
       "   389,\n",
       "   512,\n",
       "   832,\n",
       "   1061,\n",
       "   1366,\n",
       "   354,\n",
       "   261,\n",
       "   389,\n",
       "   440,\n",
       "   46,\n",
       "   284,\n",
       "   1798,\n",
       "   548,\n",
       "   265,\n",
       "   735,\n",
       "   833,\n",
       "   266,\n",
       "   364,\n",
       "   391,\n",
       "   1192,\n",
       "   46,\n",
       "   316,\n",
       "   382,\n",
       "   1221,\n",
       "   266,\n",
       "   323,\n",
       "   44,\n",
       "   317,\n",
       "   848,\n",
       "   349,\n",
       "   44,\n",
       "   390,\n",
       "   779,\n",
       "   44,\n",
       "   387,\n",
       "   1232,\n",
       "   524,\n",
       "   735,\n",
       "   2916,\n",
       "   46,\n",
       "   337,\n",
       "   862,\n",
       "   492,\n",
       "   735,\n",
       "   519,\n",
       "   337,\n",
       "   621,\n",
       "   1764,\n",
       "   1782,\n",
       "   972,\n",
       "   46,\n",
       "   1046,\n",
       "   384,\n",
       "   325,\n",
       "   458,\n",
       "   414,\n",
       "   710,\n",
       "   391,\n",
       "   44,\n",
       "   1221,\n",
       "   266,\n",
       "   261,\n",
       "   1798,\n",
       "   477,\n",
       "   266,\n",
       "   692,\n",
       "   561,\n",
       "   413,\n",
       "   46]},\n",
       " {'input_ids': [763,\n",
       "   438,\n",
       "   258,\n",
       "   397,\n",
       "   44,\n",
       "   313,\n",
       "   258,\n",
       "   1492,\n",
       "   1328,\n",
       "   371,\n",
       "   1286,\n",
       "   44,\n",
       "   401,\n",
       "   282,\n",
       "   258,\n",
       "   390,\n",
       "   277,\n",
       "   370,\n",
       "   439,\n",
       "   501,\n",
       "   46,\n",
       "   284,\n",
       "   277,\n",
       "   370,\n",
       "   439,\n",
       "   501,\n",
       "   282,\n",
       "   380,\n",
       "   496,\n",
       "   708,\n",
       "   309,\n",
       "   449,\n",
       "   364,\n",
       "   500,\n",
       "   671,\n",
       "   413,\n",
       "   46,\n",
       "   1407,\n",
       "   261,\n",
       "   558,\n",
       "   1286,\n",
       "   405,\n",
       "   346,\n",
       "   266,\n",
       "   973,\n",
       "   44,\n",
       "   409,\n",
       "   261,\n",
       "   277,\n",
       "   370,\n",
       "   439,\n",
       "   501,\n",
       "   282,\n",
       "   563,\n",
       "   266,\n",
       "   2404,\n",
       "   46,\n",
       "   284,\n",
       "   277,\n",
       "   370,\n",
       "   439,\n",
       "   501,\n",
       "   282,\n",
       "   842,\n",
       "   118,\n",
       "   1245,\n",
       "   371,\n",
       "   261,\n",
       "   346,\n",
       "   1286,\n",
       "   304,\n",
       "   10,\n",
       "   516,\n",
       "   327,\n",
       "   44,\n",
       "   261,\n",
       "   277,\n",
       "   370,\n",
       "   439,\n",
       "   501,\n",
       "   536,\n",
       "   258,\n",
       "   2578,\n",
       "   302,\n",
       "   313,\n",
       "   832,\n",
       "   2885,\n",
       "   46,\n",
       "   421,\n",
       "   282,\n",
       "   258,\n",
       "   390,\n",
       "   2922,\n",
       "   861,\n",
       "   46,\n",
       "   284,\n",
       "   861,\n",
       "   741,\n",
       "   261,\n",
       "   277,\n",
       "   370,\n",
       "   439,\n",
       "   501,\n",
       "   364,\n",
       "   265,\n",
       "   322,\n",
       "   496,\n",
       "   46,\n",
       "   284,\n",
       "   861,\n",
       "   323,\n",
       "   44,\n",
       "   317,\n",
       "   540,\n",
       "   486,\n",
       "   868,\n",
       "   708,\n",
       "   349,\n",
       "   500,\n",
       "   1304,\n",
       "   277,\n",
       "   370,\n",
       "   1582,\n",
       "   383,\n",
       "   1027,\n",
       "   2526,\n",
       "   398,\n",
       "   284,\n",
       "   277,\n",
       "   370,\n",
       "   439,\n",
       "   501,\n",
       "   548,\n",
       "   265,\n",
       "   735,\n",
       "   258,\n",
       "   390,\n",
       "   833,\n",
       "   304,\n",
       "   10,\n",
       "   934,\n",
       "   397,\n",
       "   426,\n",
       "   354,\n",
       "   44,\n",
       "   261,\n",
       "   277,\n",
       "   370,\n",
       "   439,\n",
       "   501,\n",
       "   2025,\n",
       "   673,\n",
       "   266,\n",
       "   673,\n",
       "   277,\n",
       "   370,\n",
       "   1582,\n",
       "   46,\n",
       "   1407,\n",
       "   261,\n",
       "   823,\n",
       "   313,\n",
       "   261,\n",
       "   1492,\n",
       "   552,\n",
       "   265,\n",
       "   711,\n",
       "   261,\n",
       "   277,\n",
       "   370,\n",
       "   1582,\n",
       "   266,\n",
       "   325,\n",
       "   776,\n",
       "   261,\n",
       "   277,\n",
       "   370,\n",
       "   439,\n",
       "   501,\n",
       "   46,\n",
       "   284,\n",
       "   277,\n",
       "   370,\n",
       "   439,\n",
       "   501,\n",
       "   282,\n",
       "   377,\n",
       "   708,\n",
       "   309,\n",
       "   365,\n",
       "   664,\n",
       "   413,\n",
       "   972,\n",
       "   46,\n",
       "   284,\n",
       "   277,\n",
       "   370,\n",
       "   439,\n",
       "   501,\n",
       "   691,\n",
       "   383,\n",
       "   1011,\n",
       "   1314,\n",
       "   469,\n",
       "   322,\n",
       "   258,\n",
       "   561,\n",
       "   1253,\n",
       "   46,\n",
       "   710,\n",
       "   360,\n",
       "   431,\n",
       "   636,\n",
       "   992,\n",
       "   933,\n",
       "   886,\n",
       "   46]}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 4\n",
    "next(batched(tds['train'].select(range(50)), bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e59606a4",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 21197\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_subset = tds['train'].select(range(num_txts))\n",
    "trn_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78c607d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Sequence packer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fd3464e",
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Copyright 2024 onwards Answer.AI, LightOn, and contributors\n",
    "# License: Apache-2.0\n",
    "\n",
    "import threading\n",
    "import time\n",
    "from abc import ABC, abstractmethod\n",
    "from collections import deque\n",
    "from typing import Generic, Iterable, NamedTuple, Optional, TypeVar, Any, Union, Sequence\n",
    "from composer.core.types import Batch\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from numba import njit\n",
    "\n",
    "\n",
    "import math\n",
    "from composer.core import Time\n",
    "\n",
    "\n",
    "class BatchSizeWarmupScheduler:\n",
    "    def __init__(\n",
    "        self,\n",
    "        min_batch_size: int,\n",
    "        max_batch_size: int,\n",
    "        warmup_tokens: Union[str, Time, int],\n",
    "        world_size: int,\n",
    "    ):\n",
    "        self.min_batch_size = min_batch_size\n",
    "        self.max_batch_size = max_batch_size\n",
    "\n",
    "        if isinstance(warmup_tokens, str):\n",
    "            self.warmup_tokens = Time.from_timestring(warmup_tokens).value\n",
    "        elif isinstance(warmup_tokens, Time):\n",
    "            self.warmup_tokens = warmup_tokens.value\n",
    "        else:\n",
    "            self.warmup_tokens = warmup_tokens\n",
    "        self.warmup_tokens = math.ceil(self.warmup_tokens / world_size)\n",
    "        self._step_thresholds = self._calculate_step_thresholds()\n",
    "\n",
    "    def _calculate_step_thresholds(self):\n",
    "        total_batch_sizes = sum(range(self.min_batch_size, self.max_batch_size))\n",
    "        steps_per_unit = self.warmup_tokens / total_batch_sizes\n",
    "\n",
    "        thresholds = []\n",
    "        cumsum = 0\n",
    "        for batch_size in range(self.min_batch_size, self.max_batch_size):\n",
    "            cumsum += batch_size\n",
    "            steps = math.ceil(steps_per_unit * cumsum)\n",
    "            thresholds.append(steps)\n",
    "        return thresholds\n",
    "\n",
    "    def __call__(self, current_step: int) -> int:\n",
    "        if current_step >= self.warmup_tokens:\n",
    "            return self.max_batch_size\n",
    "\n",
    "        for i, threshold in enumerate(self._step_thresholds):\n",
    "            if current_step < threshold:\n",
    "                return self.min_batch_size + i\n",
    "\n",
    "        # should never hit this, but just in case\n",
    "        return self.max_batch_size\n",
    "\n",
    "\n",
    "class SequencePackerBatchOutputTuple(NamedTuple):\n",
    "    masked_pseqs: torch.Tensor\n",
    "    labels: Optional[torch.Tensor]\n",
    "    cu_seq_lens: list[torch.Tensor]\n",
    "    max_cu_seq_len: list[torch.Tensor]\n",
    "\n",
    "\n",
    "class SequencePacker(ABC):\n",
    "    def __init__(\n",
    "        self,\n",
    "        # params defining the incoming batches of seqs\n",
    "        src_iterable: Iterable[list[list[int]]],\n",
    "        src_batch_size: int,\n",
    "        src_max_seq_len: int,\n",
    "        # params defining outgoing batches of pseqs\n",
    "        out_batch_size: int,\n",
    "        out_pseq_len: int,\n",
    "        # params defining internal behavior\n",
    "        buffer_size: int,\n",
    "        pad_token_id: int = -1,\n",
    "        mask_token_id: int = 0,\n",
    "        ignore_token_id: int = -100,\n",
    "        mask_prob: float = 0.3,\n",
    "        seed=42,\n",
    "        suppress_masking: bool = False,\n",
    "        batch_size_warmup_min_size: Optional[int] = None,\n",
    "        batch_size_warmup_tokens: Optional[Union[str, Time]] = None,\n",
    "        world_size: int = 1,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Takes batches of unpacked, unpadded sequences (seqs) to batches of packed and padded sequences (pseqs).\n",
    "\n",
    "        Every input batch must be a list[list[int]], a list of variable-length sequences of tokens.\n",
    "\n",
    "        Every output batch is a tuple (masked_inputs:Tensor, labels:Tensor, seq_starts_and_end:list).\n",
    "\n",
    "        It performs this streamwise, taking an iterable as the source of incoming batches, and\n",
    "        presents itself as an iterable of outgoing batches.\n",
    "\n",
    "        Args:\n",
    "            src_iterable: An iterable (e.g., a DataLoader), whose iterator yields one incoming batch,\n",
    "                        where a batch is a list of unpadded, variable-length Sequences of token\n",
    "                        IDs. Since this only needs to be an Iterable, it could also be a generator object\n",
    "                         like the result of `itertools.batched(dataset_list,batch_size))`\n",
    "\n",
    "            src_batch_size:  This is the INCOMING batch size, the number of seqs in one batch yielded\n",
    "                          from `src_iterable`'s iterator.\n",
    "\n",
    "            src_max_seq_len: The maximum number of tokens in a seq within an incoming batch.\n",
    "\n",
    "            out_batch_size: the number of pseqs (packed seqs) in one outgoing batch\n",
    "\n",
    "            out_pseq_len: the number of tokens per packed seq, in every outgoing batch\n",
    "\n",
    "            buffer_size: The maximum number of seqs which may be buffered internally.\n",
    "\n",
    "            pad_token_id: The token ID used for padding the space which cannot be filled to reach out_pseq_len.\n",
    "\n",
    "            mask_token_id: The token ID used for masking tokens in the input sequence.\n",
    "\n",
    "            ignore_token_id: The token ID used to ignore tokens. Expected to be applied to every non-masked token, so the model only trains on predictions of masked tokens.\n",
    "\n",
    "            suppress_masking: If True, the sequence packer will not perform masked language modeling.\n",
    "\n",
    "            batch_size_warmup_min_size: If not None, the sequence packer will gradually increase the batch size from batch_size_warmup_min_size to out_batch_size over the course of the warmup_tokens.\n",
    "                                    batch_size_warmup_min_size must be a multiple of micro_batch_size.\n",
    "\n",
    "            batch_size_warmup_tokens: If not None, the sequence packer will gradually increase the batch size from batch_size_warmup_min_size to out_batch_size over the course of the warmup_tokens.\n",
    "\n",
    "            world_size: The number of processes participating in this training run. batch_size_warmup_min_size is divided by this number.\n",
    "        \"\"\"\n",
    "        assert buffer_size >= out_batch_size, f\"required that {buffer_size=} >= {out_batch_size=}\"\n",
    "        self.src_dataloader_len = len(src_iterable)\n",
    "        self.src_iterable = src_iterable\n",
    "        self.src_batch_size = src_batch_size\n",
    "        self.out_batch_size = out_batch_size\n",
    "        self.out_pseq_len = out_pseq_len\n",
    "        self.buffer_size = buffer_size\n",
    "        self.pad_token_id = pad_token_id\n",
    "        self.mask_token_id = mask_token_id\n",
    "        self.ignore_token_id = ignore_token_id\n",
    "        self.mask_prob = mask_prob\n",
    "        self.suppress_masking = suppress_masking\n",
    "        # internals\n",
    "        self.buffer = deque()  # internal buffer holds individual seqs, as tensors.\n",
    "        # for stats to report packing efficiency.\n",
    "        self._seqs_consumed = 0\n",
    "        self._seqs_emitted = 0\n",
    "        # Set random seed\n",
    "        self.seed = seed\n",
    "        self.epoch = -1\n",
    "        self._token_count = 0\n",
    "        self.batch_size_scheduler = None\n",
    "        if batch_size_warmup_min_size is not None and batch_size_warmup_tokens is not None:\n",
    "            self.batch_size_scheduler = BatchSizeWarmupScheduler(\n",
    "                batch_size_warmup_min_size, out_batch_size, batch_size_warmup_tokens, world_size\n",
    "            )\n",
    "        else:\n",
    "            self.batch_size_scheduler = None\n",
    "\n",
    "    @property\n",
    "    def seqs_emitted(self):\n",
    "        \"Number of seqs, incoming from src_iterable, which have been emitted in OUTGOING batches.\"\n",
    "        return self._seqs_emitted\n",
    "\n",
    "    @property\n",
    "    def seqs_consumed(self):\n",
    "        \"Number of seqs, incoming from src_iterable, which have been consumed.\"\n",
    "        return self._seqs_consumed\n",
    "\n",
    "    def _reset_state(self):\n",
    "        self.epoch += 1\n",
    "        self.buffer.clear()\n",
    "        self._seqs_consumed = 0\n",
    "        self._seqs_emitted = 0\n",
    "        self.np_rng = np.random.default_rng(self.epoch + self.seed)\n",
    "\n",
    "        # Update the epoch for the sampler\n",
    "        if isinstance(self.src_iterable, torch.utils.data.dataloader.DataLoader):\n",
    "            if isinstance(self.src_iterable.sampler, torch.utils.data.distributed.DistributedSampler):\n",
    "                self.src_iterable.sampler.set_epoch(self.epoch)\n",
    "\n",
    "    def __iter__(self):\n",
    "        self._reset_state()\n",
    "        self.src_iterator = iter(self.src_iterable)\n",
    "        return self._generate_batches()\n",
    "\n",
    "    def __len__(self):\n",
    "        # rather than estimate the packed length of the dataset, we rely on Composer's ability\n",
    "        # to schedule training the using the number of batches or tokens instead of epochs.\n",
    "        return None\n",
    "\n",
    "    def _fill_buffer(self, max_items_to_add=float(\"inf\")) -> int:\n",
    "        \"\"\"\n",
    "        Refills the internal buffer.\n",
    "\n",
    "        - max_items_to_add: an amount less than or equal to the number of items to add\n",
    "\n",
    "        Returns: the number of items actually added.\n",
    "\n",
    "        The default implementation of this simply extends to src.buffer, which is\n",
    "        initialized as a list in __init__. Subclasses which want to use a different data\n",
    "        structure for internal buffering should override this method and also add\n",
    "        code in __init__ to initialize src.buffer appropriately.\n",
    "\n",
    "        Any implementation of this MUST never place more than self.buffer_size items\n",
    "        in the internal buffer.\n",
    "        \"\"\"\n",
    "        items_added = 0\n",
    "        # NOTE: this should be >=, kept as is to match model training code\n",
    "        # TODO: change if training a new model\n",
    "        while (self.buffer_size - len(self.buffer)) > self.src_batch_size:\n",
    "            try:\n",
    "                # if pulling another batch would fetch more than the requested max, stop\n",
    "                if max_items_to_add < float(\"inf\"):\n",
    "                    if (items_added + self.src_batch_size) > max_items_to_add:\n",
    "                        # print(\"Not adding, because of max_items_to_fetch\")\n",
    "                        break\n",
    "                incoming_batch = next(self.src_iterator)\n",
    "                assert (\n",
    "                    len(incoming_batch) <= self.src_batch_size\n",
    "                ), f\"expected {len(incoming_batch)=} <= {self.src_batch_size=}\"\n",
    "                for item in incoming_batch:\n",
    "                    if len(item[\"input_ids\"]) > 0:  # ignore empty sequences\n",
    "                        self.buffer.append(item[\"input_ids\"])\n",
    "                        items_added += 1\n",
    "                        self._seqs_consumed += 1\n",
    "            except StopIteration:\n",
    "                break\n",
    "        return items_added\n",
    "\n",
    "    def _generate_batches(self):\n",
    "        \"\"\"\n",
    "        Generates batches of packed sequences.\n",
    "\n",
    "        The returned generator's iterator will always, when next() is called on it, either:\n",
    "         - return a valid tuple batch (masked_batch, labels, cu_seq_lens,max_seq_lens)\n",
    "         - raise StopIteration\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            retval = self._create_batch()\n",
    "            if retval is None:\n",
    "                break\n",
    "            batch, lst_cu_seq_lens = retval\n",
    "\n",
    "            assert isinstance(retval, tuple), f\"Unexpected {type(retval)=}\"\n",
    "            assert isinstance(retval[0], np.ndarray), f\"Unexpected {type(retval[0])=}\"\n",
    "            assert isinstance(retval[1], list), f\"Unexpected {type(retval[1])=}\"\n",
    "\n",
    "            cu_seq_lens = [torch.tensor(x, dtype=torch.int32) for x in lst_cu_seq_lens]\n",
    "            max_seq_lens = [torch.max(x[1:] - x[:-1]).item() for x in cu_seq_lens]\n",
    "            assert isinstance(cu_seq_lens, list), f\"Unexpected {type(cu_seq_lens)=}\"\n",
    "            if self.suppress_masking:\n",
    "                yieldval = {\n",
    "                    \"input_ids\": torch.from_numpy(batch),\n",
    "                    \"labels\": None,\n",
    "                    \"cu_seqlens\": cu_seq_lens,\n",
    "                    \"max_seqlen\": max_seq_lens,\n",
    "                }\n",
    "            else:\n",
    "                (masked_batch, labels) = SequencePacker.mlm_masking(\n",
    "                    batch, self.mask_prob, self.mask_token_id, self.pad_token_id, self.ignore_token_id, self.np_rng\n",
    "                )\n",
    "                yieldval = {\n",
    "                    \"input_ids\": torch.from_numpy(masked_batch),\n",
    "                    \"labels\": torch.from_numpy(labels),\n",
    "                    \"cu_seqlens\": cu_seq_lens,\n",
    "                    \"max_seqlen\": max_seq_lens,\n",
    "                    \"attention_mask\": torch.from_numpy(np.where(batch == self.pad_token_id, 0, 1)),\n",
    "                }\n",
    "                self._token_count += yieldval[\"attention_mask\"].sum().item()\n",
    "            # # assert isinstance(yieldval[0], torch.Tensor), f\"Unexpected {type(yieldval[0])=}\"\n",
    "            # if not self.suppress_masking:\n",
    "            #     assert isinstance(yieldval[1], torch.Tensor), f\"Unexpected {type(yieldval[1])=}\"\n",
    "            # assert isinstance(yieldval[2], list), f\"Unexpected {type(yieldval[2])=}\"\n",
    "            # if yieldval[2]:\n",
    "            #     assert isinstance(yieldval[2][0], torch.Tensor), f\"Unexpected {type(yieldval[2][0])=}\"\n",
    "            yield yieldval\n",
    "\n",
    "    @staticmethod\n",
    "    def mlm_masking(\n",
    "        seq: np.ndarray,\n",
    "        mask_prob: float,\n",
    "        mask_token: int,\n",
    "        pad_token: int = -1,\n",
    "        ignore_index: int = -100,\n",
    "        np_rng=np.random.default_rng(),\n",
    "    ) -> tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Prepare masked tokens inputs/labels for masked language modeling: 80% MASK, 10% random, 10% original.\n",
    "\n",
    "        This is exactly a numpy version of transformers' `DataCollatorForLanguageModeling.torch_mask_tokens`\n",
    "        https://github.com/huggingface/transformers/blob/main/src/transformers/data/data_collator.py#L827\n",
    "\n",
    "        It performs masking in a way that produces on expectation the following masked inputs:\n",
    "         - (1-mask_prob) of the original positions will be untouched.\n",
    "         - mask_prob * 80%  of the original positions get replaced with a mask token\n",
    "         - mask_prob * 10%  of the original positions get replaced with a random token\n",
    "         - mask_prob * 10%  of the original positions also remain untouched.\n",
    "        This generates the masked_inputs.\n",
    "\n",
    "        It also generates a labels array, which has ignore tokens in the (1-mask_prob) positions\n",
    "\n",
    "        These proportions are expectation values since the random transformation is performed\n",
    "        independently per element. (This is why it is agnostic wrt shape.)\n",
    "\n",
    "        Args:\n",
    "          seq (np.ndarray): the input token IDs (e.g., a sequence, or batch of seqs)\n",
    "          mask_prob (float): probability of initially masking a token, in the first \"wave\" of masking\n",
    "          mask_token (int): token to use for masking\n",
    "          ignore_index (int): the token indicating that position should be ignored during training. We call it `ignore_index` to conform to the API of the cross entropy loss function.\n",
    "\n",
    "        Returns:\n",
    "            tuple[np.array,np.array]: (masked_seq, labels)\n",
    "                masked_seq: the input seq with some tokens replaced by `mask_token`\n",
    "                labels: the original input seq with non-masked tokens replaced by `ignore_index`\n",
    "        \"\"\"\n",
    "        # Create labels\n",
    "        labels = np.where(seq == pad_token, ignore_index, seq)\n",
    "\n",
    "        # Create a single mask\n",
    "        rand = np_rng.random(seq.shape)\n",
    "\n",
    "        # Partition the probability space appropriately using a single mask\n",
    "        # 80% of the time, we mask the token\n",
    "        mask_mask = rand < mask_prob * 0.8\n",
    "        # 10% of the time, we replace the token with a random token\n",
    "        random_mask = (rand >= mask_prob * 0.8) & (rand < mask_prob * 0.9)\n",
    "        # 10% of the time, we keep the token the same\n",
    "        keep_mask = (rand >= mask_prob * 0.9) & (rand < mask_prob)\n",
    "\n",
    "        # We only compute loss over the tokens marked for masking\n",
    "        labels = np.where(mask_mask | random_mask | keep_mask, labels, ignore_index)\n",
    "\n",
    "        # Apply masking\n",
    "        seq = np.where(mask_mask, mask_token, seq)\n",
    "\n",
    "        # Apply random replacement\n",
    "        random_words = np_rng.integers(0, np.max(seq) + 1, size=seq.shape)\n",
    "        seq = np.where(random_mask, random_words, seq)\n",
    "\n",
    "        return seq, labels\n",
    "\n",
    "    @abstractmethod\n",
    "    def _create_batch(self) -> Optional[tuple[np.ndarray, list[list[int]]]]:\n",
    "        \"\"\"\n",
    "        Returns a batch of packed sequences with its cumulative seq length information.\n",
    "\n",
    "        Or else, returns None if it cannot build a full outgoing batch.\n",
    "\n",
    "        Must mutate self.buffer to remove the sequences that are packed into the batch.\n",
    "\n",
    "        Returns:\n",
    "            (out_batch,cumulative_seq_len):tuple[torch.tensor, list[list[int]]]\n",
    "            where:\n",
    "                - out_batch is a tensor of shape (out_batch_size, out_pseq_len);\n",
    "                - cum_seq_lens is a list of lists, where the outer list is of len out_batch_size,\n",
    "                    and each inner list is of varying length, and contains the start positions of\n",
    "                    every seq in the pseq, and the end position of the last seq in the pseq. This end\n",
    "                    position is necessary to communicate if any padding tokens were added.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "@njit\n",
    "def find_best_fit(remaining_spaces, seq_len):\n",
    "    valid_spaces = seq_len <= remaining_spaces\n",
    "    if np.any(valid_spaces):\n",
    "        valid_space_sizes = remaining_spaces[valid_spaces]\n",
    "        best_fit_idx = np.argmin(valid_space_sizes)\n",
    "        return np.arange(len(remaining_spaces))[valid_spaces][best_fit_idx]\n",
    "    return -1\n",
    "\n",
    "\n",
    "class GreedyBestFitSequencePacker(SequencePacker):\n",
    "    @classmethod\n",
    "    def from_composer(\n",
    "        cls,\n",
    "        src_iterable: Iterable[list[list[int]]],\n",
    "        batch_size: int = 512,\n",
    "        micro_batch_size: int = 32,\n",
    "        max_seq_len: int = 1024,\n",
    "        buffer_size: int = 5120,\n",
    "        # token values\n",
    "        pad_token_id: int = -1,\n",
    "        mask_token_id: int = 0,\n",
    "        ignore_token_id: int = -100,\n",
    "        mask_prob: float = 0.3,\n",
    "        # transform values\n",
    "        seed=42,\n",
    "        suppress_masking=False,\n",
    "        batch_size_warmup_min_size: Optional[int] = None,\n",
    "        batch_size_warmup_tokens: Optional[Union[str, Time]] = None,\n",
    "        world_size: int = 1,\n",
    "    ) -> \"GreedyBestFitSequencePacker\":\n",
    "        if batch_size_warmup_min_size is not None:\n",
    "            if batch_size_warmup_min_size % micro_batch_size != 0:\n",
    "                raise ValueError(f\"{batch_size_warmup_min_size=} must be a multiple of {micro_batch_size=}\")\n",
    "            batch_size_warmup_min_size = int(batch_size_warmup_min_size / micro_batch_size)\n",
    "        return cls(\n",
    "            # input shape\n",
    "            src_iterable=src_iterable,\n",
    "            src_batch_size=batch_size,\n",
    "            src_max_seq_len=max_seq_len,\n",
    "            # output shape\n",
    "            out_batch_size=int(batch_size / micro_batch_size),\n",
    "            out_pseq_len=int(micro_batch_size * max_seq_len),\n",
    "            # internal\n",
    "            buffer_size=buffer_size,\n",
    "            # transformation\n",
    "            pad_token_id=pad_token_id,\n",
    "            mask_token_id=mask_token_id,\n",
    "            ignore_token_id=ignore_token_id,\n",
    "            mask_prob=mask_prob,\n",
    "            seed=seed,\n",
    "            suppress_masking=suppress_masking,\n",
    "            batch_size_warmup_min_size=batch_size_warmup_min_size,\n",
    "            batch_size_warmup_tokens=batch_size_warmup_tokens,\n",
    "            world_size=world_size,\n",
    "        )\n",
    "\n",
    "    def _create_batch(self) -> Optional[tuple[np.ndarray, list[list[int]]]]:\n",
    "        if self.batch_size_scheduler:\n",
    "            self.out_batch_size = self.batch_size_scheduler(self._token_count)\n",
    "\n",
    "        batch = np.full(\n",
    "            (self.out_batch_size, self.out_pseq_len), self.pad_token_id, dtype=np.int64\n",
    "        )  # the pseqs being constructed\n",
    "        seq_counts = np.zeros(self.out_batch_size, dtype=np.int32)  # the count of seqs per pseq\n",
    "        cum_seq_lens = [[0] for _ in range(self.out_batch_size)]\n",
    "        remaining_spaces = np.full(\n",
    "            (self.out_batch_size,), self.out_pseq_len, dtype=np.int32\n",
    "        )  # the space remaining per pseq\n",
    "        temp_buffer = []\n",
    "\n",
    "        while True:\n",
    "            # Check if buffer has more items, and if not replenish\n",
    "            if not self.buffer:\n",
    "                items_to_fetch = self.buffer_size - len(temp_buffer)\n",
    "                items_added = self._fill_buffer(items_to_fetch)\n",
    "                if items_added == 0:\n",
    "                    break\n",
    "\n",
    "            seq = self.buffer.popleft()\n",
    "            seq_len = len(seq)\n",
    "\n",
    "            # Find the best fit (smallest space that can accommodate the sequence)\n",
    "            best_fit_idx = find_best_fit(remaining_spaces, seq_len)\n",
    "            if best_fit_idx != -1:\n",
    "                end_pos = self.out_pseq_len - remaining_spaces[best_fit_idx]\n",
    "                batch[best_fit_idx, end_pos : end_pos + seq_len] = seq\n",
    "                seq_counts[best_fit_idx] += 1\n",
    "                remaining_spaces[best_fit_idx] -= seq_len\n",
    "                cum_seq_lens[best_fit_idx].append(cum_seq_lens[best_fit_idx][-1] + seq_len)\n",
    "            else:\n",
    "                # Can't fit the sequence, save for next batch\n",
    "                temp_buffer.append(seq)\n",
    "\n",
    "        # Add any sequences we skipped back to the start of the buffer\n",
    "        self.buffer.extendleft(temp_buffer)\n",
    "        if np.all(seq_counts > 0):\n",
    "            self._seqs_emitted += np.sum(seq_counts)\n",
    "            for x in cum_seq_lens:\n",
    "                if x[-1] != self.out_pseq_len:\n",
    "                    x.append(self.out_pseq_len)\n",
    "            return batch, cum_seq_lens\n",
    "        else:\n",
    "            # If we can't form a full batch, we return None to signal the end\n",
    "            return None\n",
    "\n",
    "\n",
    "T = TypeVar(\"T\")\n",
    "\n",
    "\n",
    "class BufferedIterable(Generic[T]):\n",
    "    def __init__(self, iterable: Iterable[T], buffer_size: int):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          - iterable: an object which generates a fresh iterator on iter() and which implements len()\n",
    "        \"\"\"\n",
    "        self.iterable = iterable\n",
    "        self.buffer_size = buffer_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        return BufferedIterator(self.iterable, self.buffer_size)\n",
    "\n",
    "\n",
    "class BufferedIterator(Generic[T]):\n",
    "    def __init__(self, iterable: Iterable[T], buffer_size: int):\n",
    "        self.iterator = iter(iterable)\n",
    "        self.buffer = deque(maxlen=buffer_size)\n",
    "        self.buffer_size = buffer_size\n",
    "        self.lock = threading.Lock()\n",
    "        self.exhausted = False\n",
    "        self.filler_thread = threading.Thread(target=self._background_fill, daemon=True)\n",
    "        self.filler_thread.start()\n",
    "\n",
    "    def _background_fill(self):\n",
    "        # Fill up the buffer, whenever possible, in the background\n",
    "        while not self.exhausted:\n",
    "            if len(self.buffer) < self.buffer_size:\n",
    "                try:\n",
    "                    item = next(self.iterator)\n",
    "                    with self.lock:\n",
    "                        self.buffer.append(item)\n",
    "                except StopIteration:\n",
    "                    self.exhausted = True\n",
    "                    break\n",
    "            else:\n",
    "                time.sleep(0.01)  # Sleep for a bit to avoid busy waiting\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self) -> T:\n",
    "        while True:\n",
    "            if not self.buffer:\n",
    "                if self.exhausted:\n",
    "                    # We've exhausted the iterator and the buffer so we're done\n",
    "                    raise StopIteration\n",
    "                else:\n",
    "                    # The buffer is empty but the iterator is not exhausted yet.\n",
    "                    # Let's give the filler thread a chance to add items to the buffer\n",
    "                    time.sleep(0.01)\n",
    "            else:\n",
    "                with self.lock:\n",
    "                    return self.buffer.popleft()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d1b397a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class CausalSequencePacker(GreedyBestFitSequencePacker):\n",
    "    def __len__(self): return self.src_dataloader_len\n",
    "    \n",
    "    def _generate_batches(self):\n",
    "        \"\"\"\n",
    "        Generates batches of packed sequences for causal attention.\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            retval = self._create_batch()\n",
    "            if retval is None:\n",
    "                break\n",
    "            batch, lst_cu_seq_lens = retval\n",
    "\n",
    "            assert isinstance(retval, tuple), f\"Unexpected {type(retval)=}\"\n",
    "            assert isinstance(retval[0], np.ndarray), f\"Unexpected {type(retval[0])=}\"\n",
    "            assert isinstance(retval[1], list), f\"Unexpected {type(retval[1])=}\"\n",
    "\n",
    "            cu_seq_lens = [torch.tensor(x, dtype=torch.int32) for x in lst_cu_seq_lens]\n",
    "            max_seq_lens = [torch.max(x[1:] - x[:-1]).item() for x in cu_seq_lens]\n",
    "            assert isinstance(cu_seq_lens, list), f\"Unexpected {type(cu_seq_lens)=}\"\n",
    "            if self.suppress_masking:\n",
    "                labels = np.full_like(batch, self.pad_token_id)\n",
    "                labels[:, :-1] = batch[:, 1:]\n",
    "                yieldval = {\n",
    "                    \"input_ids\": torch.from_numpy(batch),\n",
    "                    \"labels\": torch.from_numpy(labels),\n",
    "                    \"cu_seqlens\": cu_seq_lens,\n",
    "                    \"max_seqlen\": max_seq_lens,\n",
    "                }\n",
    "            else:\n",
    "                (masked_batch, labels) = SequencePacker.mlm_masking(\n",
    "                    batch, self.mask_prob, self.mask_token_id, self.pad_token_id, self.ignore_token_id, self.np_rng\n",
    "                )\n",
    "                yieldval = {\n",
    "                    \"input_ids\": torch.from_numpy(masked_batch),\n",
    "                    \"labels\": torch.from_numpy(labels),\n",
    "                    \"cu_seqlens\": cu_seq_lens,\n",
    "                    \"max_seqlen\": max_seq_lens,\n",
    "                    \"attention_mask\": torch.from_numpy(np.where(batch == self.pad_token_id, 0, 1)),\n",
    "                }\n",
    "                self._token_count += yieldval[\"attention_mask\"].sum().item()\n",
    "            yield yieldval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "529c59c5",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5300"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "trn_dl = DataLoader(trn_subset, batch_size=bs, collate_fn=lambda x: x)\n",
    "len(trn_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f89e925",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb = next(iter(trn_dl))\n",
    "len(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95469fc4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "out_pseq_len= 1024\n",
    "\n",
    "trn_d = {\n",
    "    \"src_iterable\": trn_dl,\n",
    "    \"src_batch_size\": bs,\n",
    "    \"src_max_seq_len\": 1,\n",
    "    \"out_batch_size\": bs,\n",
    "    \"out_pseq_len\": out_pseq_len,\n",
    "    \"buffer_size\": 64,\n",
    "    \"pad_token_id\": 0,\n",
    "    \"mask_token_id\": -2,\n",
    "    \"ignore_token_id\": -3,\n",
    "    \"mask_prob\": 0.0,\n",
    "    \"seed\": 42,\n",
    "    \"suppress_masking\": True,\n",
    "    \"world_size\": 8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "617230cd",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[516, 327,  44,  ...,   0,   0,   0],\n",
       "         [763, 438, 258,  ...,   0,   0,   0],\n",
       "         [763, 438, 258,  ...,   0,   0,   0],\n",
       "         [763, 438, 258,  ...,   0,   0,   0]]),\n",
       " 'labels': tensor([[327,  44, 258,  ...,   0,   0,   0],\n",
       "         [438, 258, 397,  ...,   0,   0,   0],\n",
       "         [438, 258, 397,  ...,   0,   0,   0],\n",
       "         [438, 258, 397,  ...,   0,   0,   0]]),\n",
       " 'cu_seqlens': [tensor([   0,  169,  358,  571,  788,  954, 1024], dtype=torch.int32),\n",
       "  tensor([   0,  174,  347,  537,  735,  890, 1020, 1024], dtype=torch.int32),\n",
       "  tensor([   0,  220,  343,  579,  766,  901,  997, 1024], dtype=torch.int32),\n",
       "  tensor([   0,  207,  401,  543,  707,  956, 1024], dtype=torch.int32)],\n",
       " 'max_seqlen': [217, 198, 236, 249]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq_trn_dl = CausalSequencePacker(**trn_d)\n",
    "len(sq_trn_dl)\n",
    "sq_batch = next(iter(sq_trn_dl))\n",
    "sq_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb05e516",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1270"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, b in enumerate(sq_trn_dl):\n",
    "    pass\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dcab36c6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_subset = trn_subset = tds['validation'].select(range(len(tds['validation'])//10))\n",
    "val_dl = DataLoader(val_subset, batch_size=bs, collate_fn=lambda x: x)\n",
    "\n",
    "val_d = {\n",
    "    \"src_iterable\": val_dl,\n",
    "    \"src_batch_size\": bs,\n",
    "    \"src_max_seq_len\": 1,\n",
    "    \"out_batch_size\": bs,\n",
    "    \"out_pseq_len\": out_pseq_len,\n",
    "    \"buffer_size\": 64,\n",
    "    \"pad_token_id\": 0,\n",
    "    \"mask_token_id\": -2,\n",
    "    \"ignore_token_id\": -3,\n",
    "    \"mask_prob\": 0.0,\n",
    "    \"seed\": 42,\n",
    "    \"suppress_masking\": True,\n",
    "}\n",
    "sq_val_dl = CausalSequencePacker(**val_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7fddca44",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.CausalSequencePacker at 0x7fc1f611c7d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls = DataLoaders(sq_trn_dl, sq_val_dl)\n",
    "dls.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ac3e632",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5300"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dls.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c1bf0ee",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[516, 327,  44,  ...,   0,   0,   0],\n",
       "         [763, 438, 258,  ...,   0,   0,   0],\n",
       "         [763, 438, 258,  ...,   0,   0,   0],\n",
       "         [763, 438, 258,  ...,   0,   0,   0]]),\n",
       " 'labels': tensor([[327,  44, 258,  ...,   0,   0,   0],\n",
       "         [438, 258, 397,  ...,   0,   0,   0],\n",
       "         [438, 258, 397,  ...,   0,   0,   0],\n",
       "         [438, 258, 397,  ...,   0,   0,   0]]),\n",
       " 'cu_seqlens': [tensor([   0,  169,  358,  571,  788,  954, 1024], dtype=torch.int32),\n",
       "  tensor([   0,  174,  347,  537,  735,  890, 1020, 1024], dtype=torch.int32),\n",
       "  tensor([   0,  220,  343,  579,  766,  901,  997, 1024], dtype=torch.int32),\n",
       "  tensor([   0,  207,  401,  543,  707,  956, 1024], dtype=torch.int32)],\n",
       " 'max_seqlen': [217, 198, 236, 249]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dls.train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6cf3dc02",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([4, 1024]) torch.Size([4, 1024])\n",
      "1 torch.Size([4, 1024]) torch.Size([4, 1024])\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(dls.train):\n",
    "    print(i, batch['input_ids'].shape, batch['labels'].shape)\n",
    "    if i == 1: break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09aec692",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bad50e3",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### FlashCausalAttention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55093be6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here's the `MultiHeadAttention` with Flash Attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55c0443f",
   "metadata": {
    "code_folding": [
     15,
     20,
     39
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class FlashCausalAttentionBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Attention block implementing multi-head causal (masked) attention using\n",
    "    Flash Attention.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_dim: int,\n",
    "        num_heads: int,\n",
    "        dropout: float = 0.0,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the causal attention block with Flash Attention implementation.\n",
    "\n",
    "        Args:\n",
    "            hidden_dim: Dimension of the input and output features\n",
    "            num_heads: Number of attention heads\n",
    "            dropout: Output dropout probability (0.0 means no dropout)\n",
    "\n",
    "        Note:\n",
    "            - Make sure to check that hidden_dim is divisible by num_heads\n",
    "            - Check if Flash Attention is available (FLASH_ATTN_AVAILABLE)\n",
    "            - You'll need to create linear (projection) layers for query, key, and value\n",
    "            - Don't forget the output linear (projection) layer\n",
    "            - Create an output dropout layer\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        if hidden_dim % num_heads != 0: raise Exception(\"hidden_dim not divisible by num_heads\")\n",
    "        self.head_dim = hidden_dim // num_heads\n",
    "        self.num_heads = num_heads\n",
    "        self.Wq, self.Wk, self.Wv = nn.Linear(hidden_dim, hidden_dim), nn.Linear(hidden_dim, hidden_dim), nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.Wo = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x: Tensor, cu_seqlens: Tensor, max_seqlen: int) -> Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "\n",
    "        Args:\n",
    "            x: Input tensor of shape [total_seq_len, hidden_dim].\n",
    "            cu_seqlens: Cumulative sequence lengths tensor of shape [batch_size + 1]\n",
    "                    Used instead of an attention mask for both masking and\n",
    "                    variable-length sequences. Example:\n",
    "                        cu_seqlens = torch.tensor([0, 10, 30, 60])\n",
    "                    This means there are three sequences in the batch:\n",
    "                        - First sequence has 10 tokens\n",
    "                        - Second sequence has 20 tokens\n",
    "                        - Third sequence has 30 tokens\n",
    "            max_seqlen: Maximum sequence length in the batch. In the example above,\n",
    "                        the maximum sequence length is 30.\n",
    "\n",
    "        Returns:\n",
    "            Tensor of shape [total_seq_len, hidden_dim] after attention.\n",
    "        \"\"\"    \n",
    "        if not FLASH_ATTN_AVAILABLE:\n",
    "            raise ImportError(\"Flash Attention is not available. Please install it with `pip install flash-attn`\")\n",
    "        \n",
    "        total_seq_len, hidden_dim = x.shape\n",
    "        q,k,v = self.Wq(x), self.Wk(x), self.Wv(x) # [batch_size, seq_len, d_out]\n",
    "\n",
    "        k_reshaped = k.view(total_seq_len, self.num_heads, self.head_dim)\n",
    "        q_reshaped = q.view(total_seq_len, self.num_heads, self.head_dim)\n",
    "        v_reshaped = v.view(total_seq_len, self.num_heads, self.head_dim)\n",
    "        \n",
    "        output = flash_attn_varlen_func(\n",
    "            q_reshaped,\n",
    "            k_reshaped,\n",
    "            v_reshaped,\n",
    "            cu_seqlens_q=cu_seqlens,\n",
    "            cu_seqlens_k=cu_seqlens,\n",
    "            max_seqlen_q=max_seqlen,\n",
    "            max_seqlen_k=max_seqlen,\n",
    "            causal=True\n",
    "        )\n",
    "\n",
    "        return self.dropout(self.Wo(output.reshape(total_seq_len, hidden_dim)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2c9878f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class FlashCausalAttentionBlock(nn.Module):\n",
    "    \"\"\"Monkey patching\"\"\"\n",
    "    def __init__(self, hidden_dim, num_heads, dropout = 0.0): super().__init__()\n",
    "    \n",
    "    def forward(self, x: Tensor, cu_seqlens: Tensor, max_seqlen: int) -> Tensor:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9cf8210d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "FLASH_ATTN_AVAILABLE = False\n",
    "try:\n",
    "    from flash_attn import flash_attn_varlen_func\n",
    "\n",
    "    FLASH_ATTN_AVAILABLE = True\n",
    "except ImportError:\n",
    "    # Flash Attention is not available\n",
    "    pass\n",
    "\n",
    "# with torch.no_grad(), torch.amp.autocast(device_type=def_device, dtype=torch.bfloat16):\n",
    "#     mha = FlashCausalAttentionBlock(hidden_dim=out_pseq_len, num_heads=1).to(def_device)\n",
    "#     output = mha(out_batches['input_ids'].to(torch.float32).to(def_device), out_batches['cu_seqlens'][0].to(def_device), out_batches['max_seqlen'][0])\n",
    "# output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02ace140",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FlashCausalAttentionBlock()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mha = FlashCausalAttentionBlock(hidden_dim=out_pseq_len, num_heads=2).to(def_device)\n",
    "mha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23c6d722",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def combine_cu_seqlens(cu_seqlens):\n",
    "    \"Combine multiple tensors into cumulative sequence\"\n",
    "    dtype = cu_seqlens[0].dtype\n",
    "    lengths = torch.tensor([t[-1] for t in cu_seqlens[:-1]], dtype=dtype).to(def_device)\n",
    "    offsets = torch.cat([torch.tensor([0], dtype=dtype, device=def_device), torch.cumsum(lengths, dim=0)]).to(dtype)\n",
    "    return torch.cat([t[:-1] if i < len(cu_seqlens)-1 else t for i, t in enumerate(cu_seqlens)]).to(def_device) + offsets.repeat_interleave(torch.tensor([t.numel()-1 if i < len(cu_seqlens)-1 else t.numel() for i, t in enumerate(cu_seqlens)]).to(def_device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a2119c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### FeedForward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fbab0dc2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, act=nn.ReLU()):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(in_dim, hidden_dim, bias=False)\n",
    "        self.act = act\n",
    "        self.l2 = nn.Linear(hidden_dim, in_dim, bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.l2(self.act(self.l1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae0f91a4",
   "metadata": {
    "code_folding": [
     16,
     35,
     38
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class GLU(nn.Module):\n",
    "    \"\"\"\n",
    "    The Gated Linear Unit has two parallel linear transforms: one for the gate and one for the value.\n",
    "    Apply the activation only to the gate, then multiply elementwise with the value, followed by a\n",
    "    final linear projection and optional dropout.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_dim: int,\n",
    "        intermediate_dim: int,\n",
    "        act: nn.Module = nn.GELU,\n",
    "        dropout: float = 0.0,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize a GLU.\n",
    "\n",
    "        Args:\n",
    "            hidden_dim: Dimension of the input and output features\n",
    "            intermediate_dim: Dimension of each intermediate branch\n",
    "                              Often set to 2/3 * 4 * hidden_dim to maintain similar parameter\n",
    "                              count to a standard MLP with 4x expansion\n",
    "            activation: Activation function to use, defaults to GELU\n",
    "            dropout: Output dropout probability (0.0 means no dropout)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.Wv = nn.Linear(hidden_dim, intermediate_dim)\n",
    "        self.Wg = nn.Linear(hidden_dim, intermediate_dim)\n",
    "        self.act = act\n",
    "        self.Wo = nn.Linear(intermediate_dim, hidden_dim)\n",
    "        self.do = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "\n",
    "        Args:\n",
    "            x: Input tensor of shape [batch_size, seq_len, hidden_dim] or [total_seq_len, hidden_dim]\n",
    "\n",
    "        Returns:\n",
    "            Tensor of shape [batch_size, seq_len, hidden_dim] or [total_seq_len, hidden_dim]\n",
    "        \"\"\"\n",
    "        gate = self.act(self.Wg(x))\n",
    "        val = self.Wv(x)\n",
    "        out = self.Wo(gate * val)\n",
    "        return self.do(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36280c0f",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Transformer Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dbd61c74",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, emb_dim, ctx_len, n_head, drop_out=0, ff_mult=4, qkv_bias=False, act=nn.ReLU()):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(emb_dim)\n",
    "        self.ln2 = nn.LayerNorm(emb_dim)\n",
    "        self.ln3 = nn.LayerNorm(emb_dim)\n",
    "        self.ln4 = nn.LayerNorm(emb_dim)\n",
    "        self.mha = FlashCausalAttentionBlock(hidden_dim=emb_dim, num_heads=n_head, dropout=drop_out)\n",
    "        self.ff = GLU(emb_dim, int(emb_dim*ff_mult), act=act)\n",
    "        self.emb_dim = emb_dim\n",
    "    \n",
    "    def forward(self, x, cu_seqlens, max_seqlen):\n",
    "#         import pdb; pdb.set_trace()\n",
    "        x_shape = x.shape\n",
    "        skip1 = x\n",
    "        x = self.ln1(x)\n",
    "        # reshape for flash attention\n",
    "        x = x.view(-1, self.emb_dim)\n",
    "        x = self.mha(x, cu_seqlens, max_seqlen)  # Need to pass (x: Tensor, cu_seqlens: Tensor, max_seqlen: int) \n",
    "        x = x.view(*x_shape)  # x.shape:(total_seq_len, hidden_dim)\n",
    "        x = self.ln2(x) \n",
    "        x = x + skip1\n",
    "        \n",
    "        skip2 = x\n",
    "        x = self.ln3(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.ln4(x)\n",
    "        x = x + skip2\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d382d7ae",
   "metadata": {},
   "source": [
    "### GPT model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba2b6f3",
   "metadata": {},
   "source": [
    "**TODO: create `pos_emb` using `cu_seqlens`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "133be1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pos_ids(seqlens, max_len=None, device=def_device):\n",
    "    if max_len is None: max_len = seqlens[-1].item()\n",
    "    pos_ids = torch.zeros(max_len, dtype=torch.long, device=device)\n",
    "    \n",
    "    for start, end in zip(seqlens[:-1], seqlens[1:]):\n",
    "        pos_ids[start:end] = torch.arange(end - start)\n",
    "    \n",
    "    return pos_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e3cf425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(cfg['vocab_sz'], cfg['emb_dim'])\n",
    "        self.pos_emb = nn.Embedding(cfg['ctx_len'], cfg['emb_dim'])\n",
    "        self.do = nn.Dropout(cfg['drop_out'])\n",
    "        self.tb = nn.ModuleList(\n",
    "            [TransformerBlock(cfg['emb_dim'], cfg['ctx_len'], cfg['n_head'], cfg['drop_out_tb'],\n",
    "                              cfg['ff_mult'], cfg['qkv_bias'], cfg['act']) for _ in range(cfg['n_tb'])])\n",
    "        self.final_ln = nn.LayerNorm(cfg['emb_dim'])\n",
    "        self.final_l  = nn.Linear(cfg['emb_dim'], cfg['vocab_sz'])\n",
    "        self.ctx_len = cfg['ctx_len']\n",
    "    \n",
    "    def forward(self, x, cu_seqlens, max_seqlen):\n",
    "        cu_seqlens = combine_cu_seqlens(cu_seqlens)\n",
    "        max_seqlen = max(max_seqlen)\n",
    "        bs, seq_len = x.shape\n",
    "        tok = self.token_emb(x)\n",
    "        pos = self.pos_emb(create_pos_ids(cu_seqlens, self.ctx_len*bs, device=def_device)).view(bs, seq_len, -1)\n",
    "        x = self.do(tok + pos)\n",
    "        for tb in self.tb:\n",
    "            x = tb(x, cu_seqlens, max_seqlen) \n",
    "        x = self.final_ln(x)\n",
    "        x = self.final_l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7f2225f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_params(model): return sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7f5c38f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_memory(model):\n",
    "    total_params = get_total_params(model)\n",
    "    total_size_bytes = total_params * 4   # Assuming fp32\n",
    "    # Convert to megabytes\n",
    "    total_size_mb = total_size_bytes / (1024 * 1024)\n",
    "    print(f\"Total params: {total_params:,}\")\n",
    "    print(f\"Total size: {total_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f022896",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8bc54096",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx is (batch, n_tokens) array of indices in the current context\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]  # Crop current context if it exceeds the supported context size\n",
    "        with torch.no_grad(): logits = model(idx_cond)         # (bs, n_tokens, vocab_sz)\n",
    "        logits = logits[:, -1, :]                              # (bs, vocab_sz)\n",
    "        probas = torch.softmax(logits, dim=-1)                 # (bs, vocab_sz)\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (bs, 1)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)                # (bs, n_tokens+1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "511281b5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "880ff652",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3d4c8521",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:].to(def_device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4747a7b",
   "metadata": {},
   "source": [
    "## Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853ceb49",
   "metadata": {},
   "source": [
    "**TODO: Add logging on weights and bias.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "90bca503",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torcheval.metrics import  MulticlassAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d440d568",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixedPrecision(TrainCB):\n",
    "    order = DeviceCB.order+10\n",
    "    def __init__(self, n_inp=1, dtype=torch.bfloat16):\n",
    "        super().__init__(n_inp=n_inp)\n",
    "        self.dtype=dtype\n",
    "    \n",
    "    def before_fit(self, learn): self.scaler = torch.amp.GradScaler('cuda')\n",
    "\n",
    "    def before_batch(self, learn):\n",
    "        self.autocast = torch.autocast(\"cuda\", dtype=self.dtype)\n",
    "        self.autocast.__enter__()\n",
    "\n",
    "    def after_loss(self, learn): self.autocast.__exit__(None, None, None)\n",
    "        \n",
    "    def backward(self, learn): self.scaler.scale(learn.loss).backward()\n",
    "\n",
    "    def step(self, learn):\n",
    "        self.scaler.step(learn.opt)\n",
    "        self.scaler.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b83922cb",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'n_tb': 12,    # num transformer blocks\n",
    "    'vocab_sz': 3008,\n",
    "    'emb_dim': 384,\n",
    "    'ctx_len': ctx_len,\n",
    "    'n_head': 12,\n",
    "    'drop_out': 0,\n",
    "    'drop_out_tb': 0,  # dropout within transformer blocks\n",
    "    'ff_mult': 2/3 * 4,\n",
    "    'qkv_bias': False,\n",
    "    'act': nn.GELU(),   # activation function\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "11a3eb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'n_tb': 1,    # num transformer blocks\n",
    "    'vocab_sz': 3008,\n",
    "    'emb_dim': 8,\n",
    "    'ctx_len': 1024,\n",
    "    'n_head': 2,\n",
    "    'drop_out': 0,\n",
    "    'drop_out_tb': 0,  # dropout within transformer blocks\n",
    "    'ff_mult': 2/3 * 4,\n",
    "    'qkv_bias': False,\n",
    "    'act': nn.GELU(),   # activation function\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "68d44a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMMetricsCB(MetricsCB):\n",
    "    \"\"\"Using `learn.lbl` and `learn.inps`\"\"\"\n",
    "    def after_batch(self, learn):\n",
    "        for m in self.metrics.values(): m.update(learn.preds, learn.lbl)\n",
    "        self.loss.update(to_cpu(learn.loss), weight=len(learn.inps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1ed5a6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "# v can also be a list isntead of a tensor.\n",
    "from collections.abc import Mapping\n",
    "\n",
    "def to_device(x, device=def_device):\n",
    "    if isinstance(x, torch.Tensor): return x.to(device)\n",
    "    if isinstance(x, Mapping): return {k:to_device(v, device) for k,v in x.items()}\n",
    "    if isinstance(x, (list, tuple)): return type(x)(to_device(o, device) for o in x)\n",
    "    return x\n",
    "\n",
    "class DeviceCB(Callback):\n",
    "    def __init__(self, device=def_device): store_attr()\n",
    "    def before_fit(self, learn):\n",
    "        if hasattr(learn.model, 'to'): learn.model.to(self.device)\n",
    "    def before_batch(self, learn): learn.batch = to_device(learn.batch, device=self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9eada510",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "# Supports multiple `inp_nm` and `lbl_nm`\n",
    "def _get_inp(b, n_inp, inp_nm):\n",
    "    if inp_nm is None: return b[:n_inp]\n",
    "    if isinstance(inp_nm, (list, tuple)): return [b[k] for k in inp_nm]\n",
    "    return [b[inp_nm]]\n",
    "\n",
    "def _get_lbl(b, n_inp, lbl_nm):\n",
    "    if lbl_nm is None: return b[:n_inp]\n",
    "    if isinstance(lbl_nm, (list, tuple)): return [b[k] for k in lbl_nm]\n",
    "    return [b[lbl_nm]]\n",
    "\n",
    "def _get_preds(b, preds_nm):\n",
    "    return b if preds_nm is None else getattr(b, preds_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b9636646",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainCB(Callback):\n",
    "    def __init__(self, n_inp=1, inp_nm=None, lbl_nm=None, preds_nm=None):\n",
    "        self.n_inp = n_inp\n",
    "        self.n_inp,self.inp_nm,self.lbl_nm,self.preds_nm = n_inp,inp_nm,lbl_nm,preds_nm\n",
    "\n",
    "    def predict(self, learn):\n",
    "        inps = _get_inp(learn.batch, self.n_inp, self.inp_nm)\n",
    "        learn.preds = learn.model(*inps)\n",
    "\n",
    "    def get_loss(self, learn):\n",
    "        lbls = _get_lbl(learn.batch, self.n_inp, self.lbl_nm)\n",
    "        preds = _get_preds(learn.preds, self.preds_nm)\n",
    "        learn.loss = learn.loss_func(preds, *lbls)\n",
    "\n",
    "    def backward(self, learn): learn.loss.backward()\n",
    "    def step(self, learn): learn.opt.step()\n",
    "    def zero_grad(self, learn): learn.opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "79e3c579",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class LLMTrainCB(TrainCB):\n",
    "    \"\"\"First label is chosen and flattened for LLM training.\n",
    "       Added learn.inps, learn.preds, and learn.lbl\n",
    "       Don't need separate loss fn.\"\"\"\n",
    "    \n",
    "    def predict(self, learn):\n",
    "        learn.inps = _get_inp(learn.batch, self.n_inp, self.inp_nm)\n",
    "        learn.preds = learn.model(*learn.inps).flatten(0, 1)\n",
    "    \n",
    "    def get_loss(self, learn):\n",
    "        learn.lbl = _get_lbl(learn.batch, self.n_inp, self.lbl_nm)[0].flatten() # flattened\n",
    "        learn.loss = learn.loss_func(learn.preds, learn.lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d72d6941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 59,962\n",
      "Total size: 0.23 MB\n"
     ]
    }
   ],
   "source": [
    "# model = torch.compile(GPTModel(cfg).to(def_device), mode=\"reduce-overhead\")\n",
    "model = GPTModel(cfg).to(def_device)\n",
    "get_total_memory(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "fd56e4c1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/10 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "      <progress value='58' class='' max='5300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      1.09% [58/5300 00:13&lt;20:17 17.168]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "opt = torch.optim.AdamW\n",
    "cbs = [LLMMetricsCB(accuracy=MulticlassAccuracy()), \n",
    "       LLMTrainCB(inp_nm=['input_ids', 'cu_seqlens', 'max_seqlen'], lbl_nm='labels'),\n",
    "       ProgressCB(), DeviceCB()]  \n",
    "learn = Learner(model, dls, loss_func=F.cross_entropy, cbs=cbs, opt_func=opt)\n",
    "with torch.amp.autocast(device_type=def_device, dtype=torch.bfloat16):\n",
    "    learn.lr_find()\n",
    "# learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a5b3c09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[32m/tmp/ipykernel_221659/1110160815.py\u001b[39m(\u001b[92m20\u001b[39m)\u001b[36mforward\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[32m     18\u001b[39m         tok = self.token_emb(x)\n",
      "\u001b[32m     19\u001b[39m         pos = self.pos_emb(create_pos_ids(cu_seqlens, self.ctx_len*bs, device=def_device))\n",
      "\u001b[32m---> 20\u001b[39m         x = self.do(tok + pos)\n",
      "\u001b[32m     21\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m tb \u001b[38;5;28;01min\u001b[39;00m self.tb:\n",
      "\u001b[32m     22\u001b[39m             x = tb(x, cu_seqlens, max_seqlen)\n",
      "\n",
      "ipdb> to.shape\n",
      "*** NameError: name 'to' is not defined\n",
      "ipdb> tok.shape\n",
      "torch.Size([4, 1024, 8])\n",
      "ipdb> pos.shape\n",
      "torch.Size([4096, 8])\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "import pdb; pdb.pm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8295f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1f47ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, epochs = 1e-4, 2\n",
    "tmax = epochs * len(dls.train)\n",
    "sched = partial(lr_scheduler.OneCycleLR, max_lr=lr, total_steps=tmax)\n",
    "xtra = [BatchSchedCB(sched)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639085e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/2 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "      <progress value='14914' class='' max='529930' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      2.81% [14914/529930 33:21&lt;19:12:08 3.646]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[250]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      5\u001b[39m cbs = [LLMMetricsCB(accuracy=MulticlassAccuracy()), \n\u001b[32m      6\u001b[39m        LLMTrainCB(inp_nm=[\u001b[33m'\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcu_seqlens\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmax_seqlen\u001b[39m\u001b[33m'\u001b[39m], lbl_nm=\u001b[33m'\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m      7\u001b[39m        ProgressCB(plot=\u001b[38;5;28;01mTrue\u001b[39;00m), DeviceCB()] \n\u001b[32m      8\u001b[39m learn = Learner(model, dls, loss_func=loss_fn, cbs=cbs+xtra, opt_func=opt)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mlearn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/minai/minai/core.py:264\u001b[39m, in \u001b[36mLearner.fit\u001b[39m\u001b[34m(self, n_epochs, train, valid, cbs, lr)\u001b[39m\n\u001b[32m    262\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m lr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: lr = \u001b[38;5;28mself\u001b[39m.lr\n\u001b[32m    263\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.opt_func: \u001b[38;5;28mself\u001b[39m.opt = \u001b[38;5;28mself\u001b[39m.opt_func(\u001b[38;5;28mself\u001b[39m.model.parameters(), lr)\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    266\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m cbs: \u001b[38;5;28mself\u001b[39m.cbs.remove(cb)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/minai/minai/core.py:198\u001b[39m, in \u001b[36mwith_cbs.__call__.<locals>._f\u001b[39m\u001b[34m(o, *args, **kwargs)\u001b[39m\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    197\u001b[39m     o.callback(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.nm\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    199\u001b[39m     o.callback(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.nm\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m()[\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mCancel\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.nm.title()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mException\u001b[39m\u001b[33m'\u001b[39m]: \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/minai/minai/core.py:252\u001b[39m, in \u001b[36mLearner._fit\u001b[39m\u001b[34m(self, train, valid)\u001b[39m\n\u001b[32m    250\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.epoch_sz \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28mself\u001b[39m.train_dl = CycleDL(\u001b[38;5;28mself\u001b[39m.train_dl, \u001b[38;5;28mself\u001b[39m.epoch_sz)\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.epochs:\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m train: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mone_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    253\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[32m    254\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m torch.inference_mode(): \u001b[38;5;28mself\u001b[39m.one_epoch(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/minai/minai/core.py:245\u001b[39m, in \u001b[36mLearner.one_epoch\u001b[39m\u001b[34m(self, training)\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28mself\u001b[39m.model.train(training)\n\u001b[32m    244\u001b[39m \u001b[38;5;28mself\u001b[39m.dl = \u001b[38;5;28mself\u001b[39m.train_dl \u001b[38;5;28;01mif\u001b[39;00m training \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dls.valid\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/minai/minai/core.py:198\u001b[39m, in \u001b[36mwith_cbs.__call__.<locals>._f\u001b[39m\u001b[34m(o, *args, **kwargs)\u001b[39m\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    197\u001b[39m     o.callback(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.nm\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    199\u001b[39m     o.callback(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.nm\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m()[\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mCancel\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.nm.title()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mException\u001b[39m\u001b[33m'\u001b[39m]: \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/minai/minai/core.py:240\u001b[39m, in \u001b[36mLearner._one_epoch\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;129m@with_cbs\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mepoch\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_one_epoch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter,\u001b[38;5;28mself\u001b[39m.batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.dl): \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/minai/minai/core.py:199\u001b[39m, in \u001b[36mwith_cbs.__call__.<locals>._f\u001b[39m\u001b[34m(o, *args, **kwargs)\u001b[39m\n\u001b[32m    197\u001b[39m     o.callback(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.nm\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m    198\u001b[39m     f(o, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m     \u001b[43mo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mafter_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnm\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m()[\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mCancel\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.nm.title()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mException\u001b[39m\u001b[33m'\u001b[39m]: \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m: o.callback(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mcleanup_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.nm\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/minai/minai/core.py:272\u001b[39m, in \u001b[36mLearner.callback\u001b[39m\u001b[34m(self, method_nm)\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcallback\u001b[39m(\u001b[38;5;28mself\u001b[39m, method_nm): \u001b[43mrun_cbs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_nm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/minai/minai/core.py:189\u001b[39m, in \u001b[36mrun_cbs\u001b[39m\u001b[34m(cbs, method_nm, learn)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(cbs, key=attrgetter(\u001b[33m'\u001b[39m\u001b[33morder\u001b[39m\u001b[33m'\u001b[39m)):\n\u001b[32m    188\u001b[39m     method = \u001b[38;5;28mgetattr\u001b[39m(cb, method_nm, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearn\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/minai/minai/core.py:402\u001b[39m, in \u001b[36mProgressCB.after_batch\u001b[39m\u001b[34m(self, learn)\u001b[39m\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.plot \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(learn, \u001b[33m'\u001b[39m\u001b[33mmetrics\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m learn.training:\n\u001b[32m    401\u001b[39m     \u001b[38;5;28mself\u001b[39m.losses.append(learn.loss.item())\n\u001b[32m--> \u001b[39m\u001b[32m402\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmbar\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mL\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlosses\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlosses\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/fromscratch/lib/python3.12/site-packages/fastprogress/fastprogress.py:208\u001b[39m, in \u001b[36mNBMasterBar.update_graph\u001b[39m\u001b[34m(self, graphs, x_bounds, y_bounds, figsize)\u001b[39m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x_bounds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28mself\u001b[39m.graph_ax.set_xlim(*x_bounds)\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y_bounds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28mself\u001b[39m.graph_ax.set_ylim(*y_bounds)\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgraph_out\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgraph_ax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfigure\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/fromscratch/lib/python3.12/site-packages/IPython/core/display_functions.py:354\u001b[39m, in \u001b[36mDisplayHandle.update\u001b[39m\u001b[34m(self, obj, **kwargs)\u001b[39m\n\u001b[32m    344\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj, **kwargs):\n\u001b[32m    345\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Update existing displays with my id\u001b[39;00m\n\u001b[32m    346\u001b[39m \n\u001b[32m    347\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    352\u001b[39m \u001b[33;03m        additional keyword arguments passed to update_display\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m     \u001b[43mupdate_display\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdisplay_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/fromscratch/lib/python3.12/site-packages/IPython/core/display_functions.py:306\u001b[39m, in \u001b[36mupdate_display\u001b[39m\u001b[34m(obj, display_id, **kwargs)\u001b[39m\n\u001b[32m    292\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Update an existing display by id\u001b[39;00m\n\u001b[32m    293\u001b[39m \n\u001b[32m    294\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    303\u001b[39m \u001b[33;03m:func:`display`\u001b[39;00m\n\u001b[32m    304\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    305\u001b[39m kwargs[\u001b[33m'\u001b[39m\u001b[33mupdate\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m306\u001b[39m \u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisplay_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/fromscratch/lib/python3.12/site-packages/IPython/core/display_functions.py:278\u001b[39m, in \u001b[36mdisplay\u001b[39m\u001b[34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[39m\n\u001b[32m    276\u001b[39m     publish_display_data(data=obj, metadata=metadata, **kwargs)\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m278\u001b[39m     format_dict, md_dict = \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    279\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m format_dict:\n\u001b[32m    280\u001b[39m         \u001b[38;5;66;03m# nothing to display (e.g. _ipython_display_ took over)\u001b[39;00m\n\u001b[32m    281\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/fromscratch/lib/python3.12/site-packages/IPython/core/formatters.py:238\u001b[39m, in \u001b[36mDisplayFormatter.format\u001b[39m\u001b[34m(self, obj, include, exclude)\u001b[39m\n\u001b[32m    236\u001b[39m md = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m     data = \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# FIXME: log the exception\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/fromscratch/lib/python3.12/site-packages/decorator.py:235\u001b[39m, in \u001b[36mdecorate.<locals>.fun\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[32m    234\u001b[39m     args, kw = fix(args, kw, sig)\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/fromscratch/lib/python3.12/site-packages/IPython/core/formatters.py:282\u001b[39m, in \u001b[36mcatch_format_error\u001b[39m\u001b[34m(method, self, *args, **kwargs)\u001b[39m\n\u001b[32m    280\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"show traceback on failed format call\"\"\"\u001b[39;00m\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m     r = \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[32m    284\u001b[39m     \u001b[38;5;66;03m# don't warn on NotImplementedErrors\u001b[39;00m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._check_return(\u001b[38;5;28;01mNone\u001b[39;00m, args[\u001b[32m0\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/fromscratch/lib/python3.12/site-packages/IPython/core/formatters.py:402\u001b[39m, in \u001b[36mBaseFormatter.__call__\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprinter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[38;5;66;03m# Finally look for special method names\u001b[39;00m\n\u001b[32m    404\u001b[39m method = get_real_method(obj, \u001b[38;5;28mself\u001b[39m.print_method)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/fromscratch/lib/python3.12/site-packages/IPython/core/pylabtools.py:170\u001b[39m, in \u001b[36mprint_figure\u001b[39m\u001b[34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[39m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend_bases\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasBase\n\u001b[32m    168\u001b[39m     FigureCanvasBase(fig)\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m \u001b[43mfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcanvas\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbytes_io\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m data = bytes_io.getvalue()\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fmt == \u001b[33m'\u001b[39m\u001b[33msvg\u001b[39m\u001b[33m'\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/fromscratch/lib/python3.12/site-packages/matplotlib/backend_bases.py:2184\u001b[39m, in \u001b[36mFigureCanvasBase.print_figure\u001b[39m\u001b[34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[39m\n\u001b[32m   2180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   2181\u001b[39m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[32m   2182\u001b[39m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[32m   2183\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m cbook._setattr_cm(\u001b[38;5;28mself\u001b[39m.figure, dpi=dpi):\n\u001b[32m-> \u001b[39m\u001b[32m2184\u001b[39m         result = \u001b[43mprint_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2185\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2186\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2187\u001b[39m \u001b[43m            \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[43m=\u001b[49m\u001b[43medgecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2188\u001b[39m \u001b[43m            \u001b[49m\u001b[43morientation\u001b[49m\u001b[43m=\u001b[49m\u001b[43morientation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2189\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbbox_inches_restore\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_bbox_inches_restore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2190\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2191\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   2192\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/fromscratch/lib/python3.12/site-packages/matplotlib/backend_bases.py:2040\u001b[39m, in \u001b[36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   2036\u001b[39m     optional_kws = {  \u001b[38;5;66;03m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[32m   2037\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdpi\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfacecolor\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33medgecolor\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33morientation\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2038\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mbbox_inches_restore\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m   2039\u001b[39m     skip = optional_kws - {*inspect.signature(meth).parameters}\n\u001b[32m-> \u001b[39m\u001b[32m2040\u001b[39m     print_method = functools.wraps(meth)(\u001b[38;5;28;01mlambda\u001b[39;00m *args, **kwargs: \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2041\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   2042\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[32m   2043\u001b[39m     print_method = meth\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/fromscratch/lib/python3.12/site-packages/matplotlib/backends/backend_agg.py:481\u001b[39m, in \u001b[36mFigureCanvasAgg.print_png\u001b[39m\u001b[34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[39m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprint_png\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, *, metadata=\u001b[38;5;28;01mNone\u001b[39;00m, pil_kwargs=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    435\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    436\u001b[39m \u001b[33;03m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[32m    437\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    479\u001b[39m \u001b[33;03m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[32m    480\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m481\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_print_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpng\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/fromscratch/lib/python3.12/site-packages/matplotlib/backends/backend_agg.py:429\u001b[39m, in \u001b[36mFigureCanvasAgg._print_pil\u001b[39m\u001b[34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[39m\n\u001b[32m    424\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_print_pil\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, fmt, pil_kwargs, metadata=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    425\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    426\u001b[39m \u001b[33;03m    Draw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[32m    427\u001b[39m \u001b[33;03m    *pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[32m    428\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m429\u001b[39m     \u001b[43mFigureCanvasAgg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    430\u001b[39m     mpl.image.imsave(\n\u001b[32m    431\u001b[39m         filename_or_obj, \u001b[38;5;28mself\u001b[39m.buffer_rgba(), \u001b[38;5;28mformat\u001b[39m=fmt, origin=\u001b[33m\"\u001b[39m\u001b[33mupper\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    432\u001b[39m         dpi=\u001b[38;5;28mself\u001b[39m.figure.dpi, metadata=metadata, pil_kwargs=pil_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/fromscratch/lib/python3.12/site-packages/matplotlib/backends/backend_agg.py:382\u001b[39m, in \u001b[36mFigureCanvasAgg.draw\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    379\u001b[39m \u001b[38;5;66;03m# Acquire a lock on the shared font cache.\u001b[39;00m\n\u001b[32m    380\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.toolbar._wait_cursor_for_draw_cm() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.toolbar\n\u001b[32m    381\u001b[39m       \u001b[38;5;28;01melse\u001b[39;00m nullcontext()):\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfigure\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    383\u001b[39m     \u001b[38;5;66;03m# A GUI class may be need to update a window using this draw, so\u001b[39;00m\n\u001b[32m    384\u001b[39m     \u001b[38;5;66;03m# don't forget to call the superclass.\u001b[39;00m\n\u001b[32m    385\u001b[39m     \u001b[38;5;28msuper\u001b[39m().draw()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/fromscratch/lib/python3.12/site-packages/matplotlib/artist.py:94\u001b[39m, in \u001b[36m_finalize_rasterization.<locals>.draw_wrapper\u001b[39m\u001b[34m(artist, renderer, *args, **kwargs)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(draw)\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdraw_wrapper\u001b[39m(artist, renderer, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     result = \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m renderer._rasterizing:\n\u001b[32m     96\u001b[39m         renderer.stop_rasterizing()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/fromscratch/lib/python3.12/site-packages/matplotlib/artist.py:71\u001b[39m, in \u001b[36mallow_rasterization.<locals>.draw_wrapper\u001b[39m\u001b[34m(artist, renderer)\u001b[39m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     69\u001b[39m         renderer.start_filter()\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/fromscratch/lib/python3.12/site-packages/matplotlib/figure.py:3257\u001b[39m, in \u001b[36mFigure.draw\u001b[39m\u001b[34m(self, renderer)\u001b[39m\n\u001b[32m   3254\u001b[39m             \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[32m   3256\u001b[39m     \u001b[38;5;28mself\u001b[39m.patch.draw(renderer)\n\u001b[32m-> \u001b[39m\u001b[32m3257\u001b[39m     \u001b[43mmimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3260\u001b[39m     renderer.close_group(\u001b[33m'\u001b[39m\u001b[33mfigure\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   3261\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/fromscratch/lib/python3.12/site-packages/matplotlib/image.py:134\u001b[39m, in \u001b[36m_draw_list_compositing_images\u001b[39m\u001b[34m(renderer, parent, artists, suppress_composite)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[32m    133\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m         \u001b[43ma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    136\u001b[39m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[32m    137\u001b[39m     image_group = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/fromscratch/lib/python3.12/site-packages/matplotlib/artist.py:71\u001b[39m, in \u001b[36mallow_rasterization.<locals>.draw_wrapper\u001b[39m\u001b[34m(artist, renderer)\u001b[39m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     69\u001b[39m         renderer.start_filter()\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/fromscratch/lib/python3.12/site-packages/matplotlib/axes/_base.py:3210\u001b[39m, in \u001b[36m_AxesBase.draw\u001b[39m\u001b[34m(self, renderer)\u001b[39m\n\u001b[32m   3207\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m artists_rasterized:\n\u001b[32m   3208\u001b[39m     _draw_rasterized(\u001b[38;5;28mself\u001b[39m.get_figure(root=\u001b[38;5;28;01mTrue\u001b[39;00m), artists_rasterized, renderer)\n\u001b[32m-> \u001b[39m\u001b[32m3210\u001b[39m \u001b[43mmimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3211\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3213\u001b[39m renderer.close_group(\u001b[33m'\u001b[39m\u001b[33maxes\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   3214\u001b[39m \u001b[38;5;28mself\u001b[39m.stale = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/fromscratch/lib/python3.12/site-packages/matplotlib/image.py:134\u001b[39m, in \u001b[36m_draw_list_compositing_images\u001b[39m\u001b[34m(renderer, parent, artists, suppress_composite)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[32m    133\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m         \u001b[43ma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    136\u001b[39m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[32m    137\u001b[39m     image_group = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/fromscratch/lib/python3.12/site-packages/matplotlib/artist.py:71\u001b[39m, in \u001b[36mallow_rasterization.<locals>.draw_wrapper\u001b[39m\u001b[34m(artist, renderer)\u001b[39m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     69\u001b[39m         renderer.start_filter()\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/fromscratch/lib/python3.12/site-packages/matplotlib/lines.py:807\u001b[39m, in \u001b[36mLine2D.draw\u001b[39m\u001b[34m(self, renderer)\u001b[39m\n\u001b[32m    804\u001b[39m         gc.set_foreground(lc_rgba, isRGBA=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    806\u001b[39m         gc.set_dashes(*\u001b[38;5;28mself\u001b[39m._dash_pattern)\n\u001b[32m--> \u001b[39m\u001b[32m807\u001b[39m         \u001b[43mrenderer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maffine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrozen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    808\u001b[39m         gc.restore()\n\u001b[32m    810\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._marker \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._markersize > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/fromscratch/lib/python3.12/site-packages/matplotlib/backends/backend_agg.py:130\u001b[39m, in \u001b[36mRendererAgg.draw_path\u001b[39m\u001b[34m(self, gc, path, transform, rgbFace)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    129\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_renderer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrgbFace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    131\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOverflowError\u001b[39;00m:\n\u001b[32m    132\u001b[39m         cant_chunk = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seed(42)\n",
    "# model = torch.compile(GPTModel(cfg).to(def_device), mode=\"reduce-overhead\")\n",
    "model = GPTModel(cfg).to(def_device)\n",
    "# cbs = [LLMMetricsCB(accuracy=MulticlassAccuracy()), ProgressCB(plot=True), DeviceCB(), MixedPrecision()]\n",
    "cbs = [LLMMetricsCB(accuracy=MulticlassAccuracy()), \n",
    "       LLMTrainCB(inp_nm=['input_ids', 'cu_seqlens', 'max_seqlen'], lbl_nm='labels'),\n",
    "       ProgressCB(plot=True), DeviceCB()] \n",
    "learn = Learner(model, dls, loss_func=loss_fn, cbs=cbs+xtra, opt_func=opt)\n",
    "learn.fit(epochs, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b000fadd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(529930, 5498)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dls.train), len(dls.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c640af47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for i, b in enumerate(dls.train):\n",
    "    if i % 10==0 : print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0cf04f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "GPTModel.forward() missing 2 required positional arguments: 'cu_seqlens' and 'max_seqlen'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[113]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m start_context = \u001b[33m\"\u001b[39m\u001b[33mOnce upon a time, there lived a bunny in a field. Her name was Lucy. Lucy loved to have feasts and parties with her bunny friends. One day, when Lucy was about to leave for a feast at a friend\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms house, she realized she\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms starting to feel sick. She was so weak she could\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      2\u001b[39m model.eval()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m token_ids = \u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_to_token_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mOnce upon a time, there lived a bunny in a field. Her name was Lucy. Lucy loved to have feasts and parties with her bunny friends. One day, when Lucy was about to leave for a feast at a friend\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43ms house, she realized she\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43ms starting to feel sick. She was so weak she could\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdef_device\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m180\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mctx_len\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.1\u001b[39;49m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mOutput text:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, token_ids_to_text(token_ids, tokenizer))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[86]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mgenerate\u001b[39m\u001b[34m(model, idx, max_new_tokens, context_size, temperature, top_k, eos_id)\u001b[39m\n\u001b[32m      3\u001b[39m idx_cond = idx[:, -context_size:].to(def_device)\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     logits = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx_cond\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m logits = logits[:, -\u001b[32m1\u001b[39m, :]\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m top_k \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# Keep only top_k values\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/fromscratch/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/fromscratch/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[31mTypeError\u001b[39m: GPTModel.forward() missing 2 required positional arguments: 'cu_seqlens' and 'max_seqlen'"
     ]
    }
   ],
   "source": [
    "start_context = \"Once upon a time, there lived a bunny in a field. Her name was Lucy. Lucy loved to have feasts and parties with her bunny friends. One day, when Lucy was about to leave for a feast at a friend's house, she realized she's starting to feel sick. She was so weak she could\"\n",
    "model.eval()\n",
    "token_ids = generate(\n",
    "    model=model.eval(),\n",
    "    idx=text_to_token_ids(\"Once upon a time, there lived a bunny in a field. Her name was Lucy. Lucy loved to have feasts and parties with her bunny friends. One day, when Lucy was about to leave for a feast at a friend's house, she realized she's starting to feel sick. She was so weak she could\", tokenizer).to(def_device),\n",
    "    max_new_tokens=180,\n",
    "    context_size=cfg[\"ctx_len\"],\n",
    "    top_k=25,\n",
    "    temperature=1.1\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f52dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97909f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Once upon a time, there lived a bunny in a fie...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Once upon a time, there lived a bunny in a fie...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Once upon a time, there lived a bunny in a fie...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Once upon a time, there lived a bunny in a fie...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Once upon a time, there lived a bunny in a fie...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  completion\n",
       "0  Once upon a time, there lived a bunny in a fie...         NaN\n",
       "1  Once upon a time, there lived a bunny in a fie...         NaN\n",
       "2  Once upon a time, there lived a bunny in a fie...         NaN\n",
       "3  Once upon a time, there lived a bunny in a fie...         NaN\n",
       "4  Once upon a time, there lived a bunny in a fie...         NaN"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('evaluation_prompts.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd516a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(row, model, tokenizer, max_tokens=180, context_size=cfg[\"ctx_len\"], \n",
    "                top_k=25, temperature=1.3):\n",
    "    # Tokenize the prompt\n",
    "    toks = text_to_token_ids(row['prompt'], tokenizer)\n",
    "    \n",
    "    # Generate completion\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=toks.to(def_device),\n",
    "        max_new_tokens=max_tokens,\n",
    "        context_size=context_size,\n",
    "        top_k=top_k,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    \n",
    "    # Extract only the generated part (not the original prompt)\n",
    "    completion = token_ids_to_text(token_ids[:, toks.shape[1]:], tokenizer)\n",
    "    \n",
    "    return completion\n",
    "\n",
    "# Apply the function to each row in the dataframe\n",
    "df['completion'] = df.apply(lambda row: process_row(row, model, tokenizer), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b414bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Once upon a time, there lived a bunny in a fie...</td>\n",
       "      <td>not move.\\n\\nLucy saw that Lucy was tired and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Once upon a time, there lived a bunny in a fie...</td>\n",
       "      <td>not breathe.\\n\\nLuckily, Lucy heard a loud ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Once upon a time, there lived a bunny in a fie...</td>\n",
       "      <td>not find her way back home. Lucy's mommy was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Once upon a time, there lived a bunny in a fie...</td>\n",
       "      <td>barely breathe again!\\n\\nLucy knew her friend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Once upon a time, there lived a bunny in a fie...</td>\n",
       "      <td>hard out.\\n\\nAt home, Lucy's mom gave her a w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  Once upon a time, there lived a bunny in a fie...   \n",
       "1  Once upon a time, there lived a bunny in a fie...   \n",
       "2  Once upon a time, there lived a bunny in a fie...   \n",
       "3  Once upon a time, there lived a bunny in a fie...   \n",
       "4  Once upon a time, there lived a bunny in a fie...   \n",
       "\n",
       "                                          completion  \n",
       "0   not move.\\n\\nLucy saw that Lucy was tired and...  \n",
       "1   not breathe.\\n\\nLuckily, Lucy heard a loud ye...  \n",
       "2   not find her way back home. Lucy's mommy was ...  \n",
       "3   barely breathe again!\\n\\nLucy knew her friend...  \n",
       "4   hard out.\\n\\nAt home, Lucy's mom gave her a w...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c81171",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"0401_init.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12510bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Once upon a time, there lived a bunny in a fie...</td>\n",
       "      <td>not move.\\n\\nLucy saw that Lucy was tired and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Once upon a time, there lived a bunny in a fie...</td>\n",
       "      <td>not breathe.\\n\\nLuckily, Lucy heard a loud ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Once upon a time, there lived a bunny in a fie...</td>\n",
       "      <td>not find her way back home. Lucy's mommy was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Once upon a time, there lived a bunny in a fie...</td>\n",
       "      <td>barely breathe again!\\n\\nLucy knew her friend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Once upon a time, there lived a bunny in a fie...</td>\n",
       "      <td>hard out.\\n\\nAt home, Lucy's mom gave her a w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  Once upon a time, there lived a bunny in a fie...   \n",
       "1  Once upon a time, there lived a bunny in a fie...   \n",
       "2  Once upon a time, there lived a bunny in a fie...   \n",
       "3  Once upon a time, there lived a bunny in a fie...   \n",
       "4  Once upon a time, there lived a bunny in a fie...   \n",
       "\n",
       "                                          completion  \n",
       "0   not move.\\n\\nLucy saw that Lucy was tired and...  \n",
       "1   not breathe.\\n\\nLuckily, Lucy heard a loud ye...  \n",
       "2   not find her way back home. Lucy's mommy was ...  \n",
       "3   barely breathe again!\\n\\nLucy knew her friend...  \n",
       "4   hard out.\\n\\nAt home, Lucy's mom gave her a w...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"0401_init.csv\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d027adbf",
   "metadata": {},
   "source": [
    "Hyperparameters: Learning rate, optimizer: Gradient clipping, batch size: 4k\n",
    "\n",
    "Mixed precision -> weight decay needed. (bfloat16)\n",
    "\n",
    "Distributed data parallel: Split data into 2 and use graident accumulation\n",
    "\n",
    "Fully Sharded data parallel: shard of data into GPUs as layer goes.\n",
    "\n",
    "CPU offload\n",
    "\n",
    "DataLoader: Use for loop.\n",
    "\n",
    "!!!!! Look at the data. !!!!!\n",
    "\n",
    "Eval: next token accuracy, loss\n",
    "\n",
    "Try GLU instead of ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87eff7e9",
   "metadata": {},
   "source": [
    "Tips: \n",
    "\n",
    "1. Try simple model.\n",
    "2. Weight Tying.\n",
    "3. Hyperparameter sweep\n",
    "4. minbpe\n",
    "\n",
    "\n",
    "Get sequencing packing to work -> iterate faster\n",
    "flash attention."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8019726f",
   "metadata": {},
   "source": [
    "Use triton cross entropy loss or compile nn.crosstropyloss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c27a80a",
   "metadata": {},
   "source": [
    "Add view(-1,...) before flash attention and remove view(-1,...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e289471c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d01d2c9f",
   "metadata": {},
   "source": [
    "Questions:\n",
    "- What is a good padding token?\n",
    "- How to use dictionary?\n",
    "- `View` in MHA\n",
    "- What does `src_max_seq_len` do?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72152b7",
   "metadata": {},
   "source": [
    "Tokenizer train with number fo merges and optionally add count."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
