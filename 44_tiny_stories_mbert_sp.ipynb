{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68bbf607",
   "metadata": {},
   "source": [
    "Using \n",
    "- sdpa \n",
    "- optimizer\n",
    "- compile \n",
    "- more data\n",
    "- MixedPrecision()\n",
    "- lr_sched\n",
    "- Double layer norm\n",
    "- Using a custom tokenizer.\n",
    "- GLU\n",
    "- sdpa linear\n",
    "- modern bert sequence packing + FA2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb8bde8",
   "metadata": {},
   "source": [
    "# Tiny Stories Hackathon\n",
    "> From Cluster of stars study group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc82c861",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc14c85",
   "metadata": {},
   "source": [
    "### Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e940d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import tiktoken\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor, BoolTensor\n",
    "\n",
    "from minai import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4bc327",
   "metadata": {},
   "source": [
    "Grab tiny stories data from hugging face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e7cd32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 2119719\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset('roneneldan/TinyStories')\n",
    "trn = ds['train']\n",
    "val = ds['validation']\n",
    "trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967927c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 21990\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6938ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minbpe import RegexTokenizer\n",
    "from fastcore.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbed3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path.home()/'git/minai/TinyStories_All_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a959b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[257, 2365, 1597]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = RegexTokenizer()\n",
    "# tokenizer.train(txt_raw, vocab_size=3000)\n",
    "\n",
    "tokenizer.load((path/\"tok3k_regex.model\").name) # loads the model back from disk\n",
    "tokenizer.encode(\"hello world\") # string -> tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b102ef73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One day, a little girl named Lily found a needle in her room. She knew it was difficult to play with it because it was sharp. Lily wanted to share the needle with her mom, so she could sew a button on her shirt.\\n\\nLily went to her mom and said, \"Mom, I found this needle. Can you share it with me and sew my shirt?\" Her mom smiled and said, \"Yes, Lily, we can share the needle and fix your shirt.\"\\n\\nTogether, they shared the needle and sewed the button on Lily\\'s shirt. It was not difficult for them because they were sharing and helping each other. After they finished, Lily thanked her mom for sharing the needle and fixing her shirt. They both felt happy because they had shared and worked together.'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = trn[0]['text']\n",
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ca6b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_to_toks(txt, toker): return toker.encode(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a08231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toks_to_txt(toks, toker): return toker.decode(toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8452255f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_txts = 10\n",
    "num_txts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d73f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "separator=\"\\n\\n\\n\"\n",
    "ctx_len = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d68efb",
   "metadata": {},
   "source": [
    "We create a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bf20f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforms(b):\n",
    "    d = {}\n",
    "    d['input_ids'] = [tokenizer.encode(t, allowed_special={\"<|endoftext|>\"}) for t in b['text']]\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ccdf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched(iterable, n):\n",
    "    # batched('ABCDEFG', 3) â†’ ABC DEF G\n",
    "    if n < 1:\n",
    "        raise ValueError(\"n must be at least one\")\n",
    "    iterator = iter(iterable)\n",
    "    while batch := list(itertools.islice(iterator, n)):\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5014bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[516, 327, 44, 258, 390, 479, 402, 406, 507, 258]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tds = ds.with_transform(transforms)\n",
    "tds['train'][0]['input_ids'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed48361f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 2119719\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tds['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c9317e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input_ids': [516,\n",
       "   327,\n",
       "   44,\n",
       "   258,\n",
       "   390,\n",
       "   479,\n",
       "   402,\n",
       "   406,\n",
       "   507,\n",
       "   258,\n",
       "   775,\n",
       "   302,\n",
       "   313,\n",
       "   338,\n",
       "   720,\n",
       "   46,\n",
       "   342,\n",
       "   677,\n",
       "   309,\n",
       "   282,\n",
       "   2876,\n",
       "   265,\n",
       "   325,\n",
       "   328,\n",
       "   309,\n",
       "   708,\n",
       "   309,\n",
       "   282,\n",
       "   2073,\n",
       "   46,\n",
       "   406,\n",
       "   407,\n",
       "   265,\n",
       "   850,\n",
       "   261,\n",
       "   775,\n",
       "   302,\n",
       "   328,\n",
       "   338,\n",
       "   386,\n",
       "   44,\n",
       "   391,\n",
       "   392,\n",
       "   468,\n",
       "   459,\n",
       "   119,\n",
       "   258,\n",
       "   1674,\n",
       "   354,\n",
       "   338,\n",
       "   2377,\n",
       "   304,\n",
       "   10,\n",
       "   670,\n",
       "   426,\n",
       "   265,\n",
       "   338,\n",
       "   386,\n",
       "   266,\n",
       "   323,\n",
       "   44,\n",
       "   317,\n",
       "   844,\n",
       "   44,\n",
       "   337,\n",
       "   507,\n",
       "   733,\n",
       "   775,\n",
       "   302,\n",
       "   46,\n",
       "   1127,\n",
       "   349,\n",
       "   850,\n",
       "   309,\n",
       "   328,\n",
       "   524,\n",
       "   266,\n",
       "   459,\n",
       "   119,\n",
       "   627,\n",
       "   2377,\n",
       "   476,\n",
       "   937,\n",
       "   386,\n",
       "   565,\n",
       "   266,\n",
       "   323,\n",
       "   44,\n",
       "   317,\n",
       "   732,\n",
       "   44,\n",
       "   406,\n",
       "   44,\n",
       "   363,\n",
       "   469,\n",
       "   850,\n",
       "   261,\n",
       "   775,\n",
       "   302,\n",
       "   266,\n",
       "   1125,\n",
       "   629,\n",
       "   2377,\n",
       "   505,\n",
       "   10,\n",
       "   2826,\n",
       "   44,\n",
       "   360,\n",
       "   1208,\n",
       "   261,\n",
       "   775,\n",
       "   302,\n",
       "   266,\n",
       "   459,\n",
       "   119,\n",
       "   263,\n",
       "   261,\n",
       "   1674,\n",
       "   354,\n",
       "   406,\n",
       "   384,\n",
       "   2377,\n",
       "   46,\n",
       "   421,\n",
       "   282,\n",
       "   364,\n",
       "   2876,\n",
       "   387,\n",
       "   493,\n",
       "   708,\n",
       "   360,\n",
       "   405,\n",
       "   1714,\n",
       "   266,\n",
       "   1398,\n",
       "   766,\n",
       "   558,\n",
       "   46,\n",
       "   1559,\n",
       "   360,\n",
       "   1699,\n",
       "   44,\n",
       "   406,\n",
       "   943,\n",
       "   338,\n",
       "   386,\n",
       "   387,\n",
       "   1714,\n",
       "   261,\n",
       "   775,\n",
       "   302,\n",
       "   266,\n",
       "   1125,\n",
       "   297,\n",
       "   338,\n",
       "   2377,\n",
       "   46,\n",
       "   312,\n",
       "   722,\n",
       "   536,\n",
       "   377,\n",
       "   708,\n",
       "   360,\n",
       "   365,\n",
       "   1208,\n",
       "   266,\n",
       "   1228,\n",
       "   458,\n",
       "   46]},\n",
       " {'input_ids': [763,\n",
       "   438,\n",
       "   258,\n",
       "   397,\n",
       "   44,\n",
       "   401,\n",
       "   282,\n",
       "   258,\n",
       "   390,\n",
       "   528,\n",
       "   402,\n",
       "   2456,\n",
       "   626,\n",
       "   46,\n",
       "   2456,\n",
       "   626,\n",
       "   508,\n",
       "   265,\n",
       "   483,\n",
       "   737,\n",
       "   266,\n",
       "   325,\n",
       "   313,\n",
       "   261,\n",
       "   631,\n",
       "   46,\n",
       "   2456,\n",
       "   626,\n",
       "   282,\n",
       "   258,\n",
       "   2489,\n",
       "   528,\n",
       "   708,\n",
       "   285,\n",
       "   704,\n",
       "   365,\n",
       "   561,\n",
       "   268,\n",
       "   117,\n",
       "   417,\n",
       "   46,\n",
       "   1213,\n",
       "   462,\n",
       "   268,\n",
       "   117,\n",
       "   417,\n",
       "   586,\n",
       "   2456,\n",
       "   626,\n",
       "   377,\n",
       "   266,\n",
       "   973,\n",
       "   304,\n",
       "   10,\n",
       "   516,\n",
       "   327,\n",
       "   44,\n",
       "   2456,\n",
       "   626,\n",
       "   282,\n",
       "   1402,\n",
       "   817,\n",
       "   313,\n",
       "   261,\n",
       "   527,\n",
       "   634,\n",
       "   285,\n",
       "   382,\n",
       "   258,\n",
       "   346,\n",
       "   501,\n",
       "   46,\n",
       "   284,\n",
       "   501,\n",
       "   365,\n",
       "   664,\n",
       "   1333,\n",
       "   383,\n",
       "   405,\n",
       "   1455,\n",
       "   297,\n",
       "   46,\n",
       "   2456,\n",
       "   626,\n",
       "   532,\n",
       "   756,\n",
       "   261,\n",
       "   1333,\n",
       "   1455,\n",
       "   266,\n",
       "   407,\n",
       "   265,\n",
       "   325,\n",
       "   328,\n",
       "   493,\n",
       "   46,\n",
       "   2456,\n",
       "   626,\n",
       "   2241,\n",
       "   776,\n",
       "   261,\n",
       "   501,\n",
       "   266,\n",
       "   1233,\n",
       "   261,\n",
       "   1333,\n",
       "   1455,\n",
       "   354,\n",
       "   475,\n",
       "   46,\n",
       "   316,\n",
       "   703,\n",
       "   266,\n",
       "   322,\n",
       "   626,\n",
       "   263,\n",
       "   340,\n",
       "   2771,\n",
       "   304,\n",
       "   10,\n",
       "   2120,\n",
       "   626,\n",
       "   477,\n",
       "   328,\n",
       "   261,\n",
       "   1455,\n",
       "   297,\n",
       "   1333,\n",
       "   431,\n",
       "   327,\n",
       "   46,\n",
       "   931,\n",
       "   309,\n",
       "   282,\n",
       "   397,\n",
       "   265,\n",
       "   483,\n",
       "   584,\n",
       "   44,\n",
       "   2456,\n",
       "   626,\n",
       "   677,\n",
       "   285,\n",
       "   1341,\n",
       "   673,\n",
       "   268,\n",
       "   117,\n",
       "   417,\n",
       "   46,\n",
       "   316,\n",
       "   426,\n",
       "   265,\n",
       "   261,\n",
       "   268,\n",
       "   117,\n",
       "   417,\n",
       "   962,\n",
       "   266,\n",
       "   660,\n",
       "   673,\n",
       "   2489,\n",
       "   268,\n",
       "   117,\n",
       "   417,\n",
       "   46,\n",
       "   1139,\n",
       "   44,\n",
       "   2456,\n",
       "   626,\n",
       "   282,\n",
       "   1367,\n",
       "   265,\n",
       "   483,\n",
       "   737,\n",
       "   266,\n",
       "   325,\n",
       "   601,\n",
       "   261,\n",
       "   988,\n",
       "   327,\n",
       "   46,\n",
       "   710,\n",
       "   2456,\n",
       "   626,\n",
       "   636,\n",
       "   992,\n",
       "   933,\n",
       "   886,\n",
       "   46]},\n",
       " {'input_ids': [516,\n",
       "   327,\n",
       "   44,\n",
       "   258,\n",
       "   390,\n",
       "   779,\n",
       "   402,\n",
       "   1221,\n",
       "   282,\n",
       "   2439,\n",
       "   810,\n",
       "   261,\n",
       "   389,\n",
       "   440,\n",
       "   46,\n",
       "   316,\n",
       "   382,\n",
       "   258,\n",
       "   346,\n",
       "   1798,\n",
       "   266,\n",
       "   407,\n",
       "   265,\n",
       "   322,\n",
       "   413,\n",
       "   46,\n",
       "   317,\n",
       "   1090,\n",
       "   44,\n",
       "   337,\n",
       "   743,\n",
       "   1221,\n",
       "   46,\n",
       "   1174,\n",
       "   349,\n",
       "   367,\n",
       "   265,\n",
       "   325,\n",
       "   476,\n",
       "   543,\n",
       "   261,\n",
       "   390,\n",
       "   779,\n",
       "   46,\n",
       "   284,\n",
       "   1798,\n",
       "   506,\n",
       "   450,\n",
       "   1221,\n",
       "   266,\n",
       "   323,\n",
       "   44,\n",
       "   317,\n",
       "   947,\n",
       "   44,\n",
       "   337,\n",
       "   862,\n",
       "   492,\n",
       "   367,\n",
       "   265,\n",
       "   325,\n",
       "   46,\n",
       "   337,\n",
       "   743,\n",
       "   1192,\n",
       "   266,\n",
       "   337,\n",
       "   862,\n",
       "   492,\n",
       "   735,\n",
       "   2916,\n",
       "   505,\n",
       "   10,\n",
       "   1804,\n",
       "   536,\n",
       "   496,\n",
       "   409,\n",
       "   407,\n",
       "   265,\n",
       "   432,\n",
       "   261,\n",
       "   1798,\n",
       "   735,\n",
       "   833,\n",
       "   46,\n",
       "   316,\n",
       "   1588,\n",
       "   583,\n",
       "   266,\n",
       "   578,\n",
       "   371,\n",
       "   258,\n",
       "   1350,\n",
       "   46,\n",
       "   316,\n",
       "   1533,\n",
       "   383,\n",
       "   261,\n",
       "   631,\n",
       "   468,\n",
       "   533,\n",
       "   630,\n",
       "   1061,\n",
       "   46,\n",
       "   707,\n",
       "   44,\n",
       "   1221,\n",
       "   1588,\n",
       "   265,\n",
       "   261,\n",
       "   1306,\n",
       "   371,\n",
       "   261,\n",
       "   686,\n",
       "   266,\n",
       "   1041,\n",
       "   265,\n",
       "   261,\n",
       "   631,\n",
       "   44,\n",
       "   317,\n",
       "   1936,\n",
       "   44,\n",
       "   631,\n",
       "   44,\n",
       "   432,\n",
       "   627,\n",
       "   545,\n",
       "   358,\n",
       "   735,\n",
       "   2916,\n",
       "   266,\n",
       "   364,\n",
       "   1764,\n",
       "   1782,\n",
       "   687,\n",
       "   10,\n",
       "   412,\n",
       "   631,\n",
       "   837,\n",
       "   1221,\n",
       "   384,\n",
       "   946,\n",
       "   266,\n",
       "   389,\n",
       "   512,\n",
       "   832,\n",
       "   1061,\n",
       "   1366,\n",
       "   354,\n",
       "   261,\n",
       "   389,\n",
       "   440,\n",
       "   46,\n",
       "   284,\n",
       "   1798,\n",
       "   548,\n",
       "   265,\n",
       "   735,\n",
       "   833,\n",
       "   266,\n",
       "   364,\n",
       "   391,\n",
       "   1192,\n",
       "   46,\n",
       "   316,\n",
       "   382,\n",
       "   1221,\n",
       "   266,\n",
       "   323,\n",
       "   44,\n",
       "   317,\n",
       "   848,\n",
       "   349,\n",
       "   44,\n",
       "   390,\n",
       "   779,\n",
       "   44,\n",
       "   387,\n",
       "   1232,\n",
       "   524,\n",
       "   735,\n",
       "   2916,\n",
       "   46,\n",
       "   337,\n",
       "   862,\n",
       "   492,\n",
       "   735,\n",
       "   519,\n",
       "   337,\n",
       "   621,\n",
       "   1764,\n",
       "   1782,\n",
       "   972,\n",
       "   46,\n",
       "   1046,\n",
       "   384,\n",
       "   325,\n",
       "   458,\n",
       "   414,\n",
       "   710,\n",
       "   391,\n",
       "   44,\n",
       "   1221,\n",
       "   266,\n",
       "   261,\n",
       "   1798,\n",
       "   477,\n",
       "   266,\n",
       "   692,\n",
       "   561,\n",
       "   413,\n",
       "   46]},\n",
       " {'input_ids': [763,\n",
       "   438,\n",
       "   258,\n",
       "   397,\n",
       "   44,\n",
       "   313,\n",
       "   258,\n",
       "   1492,\n",
       "   1328,\n",
       "   371,\n",
       "   1286,\n",
       "   44,\n",
       "   401,\n",
       "   282,\n",
       "   258,\n",
       "   390,\n",
       "   277,\n",
       "   370,\n",
       "   439,\n",
       "   501,\n",
       "   46,\n",
       "   284,\n",
       "   277,\n",
       "   370,\n",
       "   439,\n",
       "   501,\n",
       "   282,\n",
       "   380,\n",
       "   496,\n",
       "   708,\n",
       "   309,\n",
       "   449,\n",
       "   364,\n",
       "   500,\n",
       "   671,\n",
       "   413,\n",
       "   46,\n",
       "   1407,\n",
       "   261,\n",
       "   558,\n",
       "   1286,\n",
       "   405,\n",
       "   346,\n",
       "   266,\n",
       "   973,\n",
       "   44,\n",
       "   409,\n",
       "   261,\n",
       "   277,\n",
       "   370,\n",
       "   439,\n",
       "   501,\n",
       "   282,\n",
       "   563,\n",
       "   266,\n",
       "   2404,\n",
       "   46,\n",
       "   284,\n",
       "   277,\n",
       "   370,\n",
       "   439,\n",
       "   501,\n",
       "   282,\n",
       "   842,\n",
       "   118,\n",
       "   1245,\n",
       "   371,\n",
       "   261,\n",
       "   346,\n",
       "   1286,\n",
       "   304,\n",
       "   10,\n",
       "   516,\n",
       "   327,\n",
       "   44,\n",
       "   261,\n",
       "   277,\n",
       "   370,\n",
       "   439,\n",
       "   501,\n",
       "   536,\n",
       "   258,\n",
       "   2578,\n",
       "   302,\n",
       "   313,\n",
       "   832,\n",
       "   2885,\n",
       "   46,\n",
       "   421,\n",
       "   282,\n",
       "   258,\n",
       "   390,\n",
       "   2922,\n",
       "   861,\n",
       "   46,\n",
       "   284,\n",
       "   861,\n",
       "   741,\n",
       "   261,\n",
       "   277,\n",
       "   370,\n",
       "   439,\n",
       "   501,\n",
       "   364,\n",
       "   265,\n",
       "   322,\n",
       "   496,\n",
       "   46,\n",
       "   284,\n",
       "   861,\n",
       "   323,\n",
       "   44,\n",
       "   317,\n",
       "   540,\n",
       "   486,\n",
       "   868,\n",
       "   708,\n",
       "   349,\n",
       "   500,\n",
       "   1304,\n",
       "   277,\n",
       "   370,\n",
       "   1582,\n",
       "   383,\n",
       "   1027,\n",
       "   2526,\n",
       "   398,\n",
       "   284,\n",
       "   277,\n",
       "   370,\n",
       "   439,\n",
       "   501,\n",
       "   548,\n",
       "   265,\n",
       "   735,\n",
       "   258,\n",
       "   390,\n",
       "   833,\n",
       "   304,\n",
       "   10,\n",
       "   934,\n",
       "   397,\n",
       "   426,\n",
       "   354,\n",
       "   44,\n",
       "   261,\n",
       "   277,\n",
       "   370,\n",
       "   439,\n",
       "   501,\n",
       "   2025,\n",
       "   673,\n",
       "   266,\n",
       "   673,\n",
       "   277,\n",
       "   370,\n",
       "   1582,\n",
       "   46,\n",
       "   1407,\n",
       "   261,\n",
       "   823,\n",
       "   313,\n",
       "   261,\n",
       "   1492,\n",
       "   552,\n",
       "   265,\n",
       "   711,\n",
       "   261,\n",
       "   277,\n",
       "   370,\n",
       "   1582,\n",
       "   266,\n",
       "   325,\n",
       "   776,\n",
       "   261,\n",
       "   277,\n",
       "   370,\n",
       "   439,\n",
       "   501,\n",
       "   46,\n",
       "   284,\n",
       "   277,\n",
       "   370,\n",
       "   439,\n",
       "   501,\n",
       "   282,\n",
       "   377,\n",
       "   708,\n",
       "   309,\n",
       "   365,\n",
       "   664,\n",
       "   413,\n",
       "   972,\n",
       "   46,\n",
       "   284,\n",
       "   277,\n",
       "   370,\n",
       "   439,\n",
       "   501,\n",
       "   691,\n",
       "   383,\n",
       "   1011,\n",
       "   1314,\n",
       "   469,\n",
       "   322,\n",
       "   258,\n",
       "   561,\n",
       "   1253,\n",
       "   46,\n",
       "   710,\n",
       "   360,\n",
       "   431,\n",
       "   636,\n",
       "   992,\n",
       "   933,\n",
       "   886,\n",
       "   46]}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 4\n",
    "next(batched(tds['train'].select(range(50)), bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ead127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_batches = list(batched(tds['train'].select(range(100)), bs))\n",
    "len(input_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8732d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'input_ids': [516,\n",
       "    327,\n",
       "    44,\n",
       "    258,\n",
       "    390,\n",
       "    479,\n",
       "    402,\n",
       "    406,\n",
       "    507,\n",
       "    258,\n",
       "    775,\n",
       "    302,\n",
       "    313,\n",
       "    338,\n",
       "    720,\n",
       "    46,\n",
       "    342,\n",
       "    677,\n",
       "    309,\n",
       "    282,\n",
       "    2876,\n",
       "    265,\n",
       "    325,\n",
       "    328,\n",
       "    309,\n",
       "    708,\n",
       "    309,\n",
       "    282,\n",
       "    2073,\n",
       "    46,\n",
       "    406,\n",
       "    407,\n",
       "    265,\n",
       "    850,\n",
       "    261,\n",
       "    775,\n",
       "    302,\n",
       "    328,\n",
       "    338,\n",
       "    386,\n",
       "    44,\n",
       "    391,\n",
       "    392,\n",
       "    468,\n",
       "    459,\n",
       "    119,\n",
       "    258,\n",
       "    1674,\n",
       "    354,\n",
       "    338,\n",
       "    2377,\n",
       "    304,\n",
       "    10,\n",
       "    670,\n",
       "    426,\n",
       "    265,\n",
       "    338,\n",
       "    386,\n",
       "    266,\n",
       "    323,\n",
       "    44,\n",
       "    317,\n",
       "    844,\n",
       "    44,\n",
       "    337,\n",
       "    507,\n",
       "    733,\n",
       "    775,\n",
       "    302,\n",
       "    46,\n",
       "    1127,\n",
       "    349,\n",
       "    850,\n",
       "    309,\n",
       "    328,\n",
       "    524,\n",
       "    266,\n",
       "    459,\n",
       "    119,\n",
       "    627,\n",
       "    2377,\n",
       "    476,\n",
       "    937,\n",
       "    386,\n",
       "    565,\n",
       "    266,\n",
       "    323,\n",
       "    44,\n",
       "    317,\n",
       "    732,\n",
       "    44,\n",
       "    406,\n",
       "    44,\n",
       "    363,\n",
       "    469,\n",
       "    850,\n",
       "    261,\n",
       "    775,\n",
       "    302,\n",
       "    266,\n",
       "    1125,\n",
       "    629,\n",
       "    2377,\n",
       "    505,\n",
       "    10,\n",
       "    2826,\n",
       "    44,\n",
       "    360,\n",
       "    1208,\n",
       "    261,\n",
       "    775,\n",
       "    302,\n",
       "    266,\n",
       "    459,\n",
       "    119,\n",
       "    263,\n",
       "    261,\n",
       "    1674,\n",
       "    354,\n",
       "    406,\n",
       "    384,\n",
       "    2377,\n",
       "    46,\n",
       "    421,\n",
       "    282,\n",
       "    364,\n",
       "    2876,\n",
       "    387,\n",
       "    493,\n",
       "    708,\n",
       "    360,\n",
       "    405,\n",
       "    1714,\n",
       "    266,\n",
       "    1398,\n",
       "    766,\n",
       "    558,\n",
       "    46,\n",
       "    1559,\n",
       "    360,\n",
       "    1699,\n",
       "    44,\n",
       "    406,\n",
       "    943,\n",
       "    338,\n",
       "    386,\n",
       "    387,\n",
       "    1714,\n",
       "    261,\n",
       "    775,\n",
       "    302,\n",
       "    266,\n",
       "    1125,\n",
       "    297,\n",
       "    338,\n",
       "    2377,\n",
       "    46,\n",
       "    312,\n",
       "    722,\n",
       "    536,\n",
       "    377,\n",
       "    708,\n",
       "    360,\n",
       "    365,\n",
       "    1208,\n",
       "    266,\n",
       "    1228,\n",
       "    458,\n",
       "    46]},\n",
       "  {'input_ids': [763,\n",
       "    438,\n",
       "    258,\n",
       "    397,\n",
       "    44,\n",
       "    401,\n",
       "    282,\n",
       "    258,\n",
       "    390,\n",
       "    528,\n",
       "    402,\n",
       "    2456,\n",
       "    626,\n",
       "    46,\n",
       "    2456,\n",
       "    626,\n",
       "    508,\n",
       "    265,\n",
       "    483,\n",
       "    737,\n",
       "    266,\n",
       "    325,\n",
       "    313,\n",
       "    261,\n",
       "    631,\n",
       "    46,\n",
       "    2456,\n",
       "    626,\n",
       "    282,\n",
       "    258,\n",
       "    2489,\n",
       "    528,\n",
       "    708,\n",
       "    285,\n",
       "    704,\n",
       "    365,\n",
       "    561,\n",
       "    268,\n",
       "    117,\n",
       "    417,\n",
       "    46,\n",
       "    1213,\n",
       "    462,\n",
       "    268,\n",
       "    117,\n",
       "    417,\n",
       "    586,\n",
       "    2456,\n",
       "    626,\n",
       "    377,\n",
       "    266,\n",
       "    973,\n",
       "    304,\n",
       "    10,\n",
       "    516,\n",
       "    327,\n",
       "    44,\n",
       "    2456,\n",
       "    626,\n",
       "    282,\n",
       "    1402,\n",
       "    817,\n",
       "    313,\n",
       "    261,\n",
       "    527,\n",
       "    634,\n",
       "    285,\n",
       "    382,\n",
       "    258,\n",
       "    346,\n",
       "    501,\n",
       "    46,\n",
       "    284,\n",
       "    501,\n",
       "    365,\n",
       "    664,\n",
       "    1333,\n",
       "    383,\n",
       "    405,\n",
       "    1455,\n",
       "    297,\n",
       "    46,\n",
       "    2456,\n",
       "    626,\n",
       "    532,\n",
       "    756,\n",
       "    261,\n",
       "    1333,\n",
       "    1455,\n",
       "    266,\n",
       "    407,\n",
       "    265,\n",
       "    325,\n",
       "    328,\n",
       "    493,\n",
       "    46,\n",
       "    2456,\n",
       "    626,\n",
       "    2241,\n",
       "    776,\n",
       "    261,\n",
       "    501,\n",
       "    266,\n",
       "    1233,\n",
       "    261,\n",
       "    1333,\n",
       "    1455,\n",
       "    354,\n",
       "    475,\n",
       "    46,\n",
       "    316,\n",
       "    703,\n",
       "    266,\n",
       "    322,\n",
       "    626,\n",
       "    263,\n",
       "    340,\n",
       "    2771,\n",
       "    304,\n",
       "    10,\n",
       "    2120,\n",
       "    626,\n",
       "    477,\n",
       "    328,\n",
       "    261,\n",
       "    1455,\n",
       "    297,\n",
       "    1333,\n",
       "    431,\n",
       "    327,\n",
       "    46,\n",
       "    931,\n",
       "    309,\n",
       "    282,\n",
       "    397,\n",
       "    265,\n",
       "    483,\n",
       "    584,\n",
       "    44,\n",
       "    2456,\n",
       "    626,\n",
       "    677,\n",
       "    285,\n",
       "    1341,\n",
       "    673,\n",
       "    268,\n",
       "    117,\n",
       "    417,\n",
       "    46,\n",
       "    316,\n",
       "    426,\n",
       "    265,\n",
       "    261,\n",
       "    268,\n",
       "    117,\n",
       "    417,\n",
       "    962,\n",
       "    266,\n",
       "    660,\n",
       "    673,\n",
       "    2489,\n",
       "    268,\n",
       "    117,\n",
       "    417,\n",
       "    46,\n",
       "    1139,\n",
       "    44,\n",
       "    2456,\n",
       "    626,\n",
       "    282,\n",
       "    1367,\n",
       "    265,\n",
       "    483,\n",
       "    737,\n",
       "    266,\n",
       "    325,\n",
       "    601,\n",
       "    261,\n",
       "    988,\n",
       "    327,\n",
       "    46,\n",
       "    710,\n",
       "    2456,\n",
       "    626,\n",
       "    636,\n",
       "    992,\n",
       "    933,\n",
       "    886,\n",
       "    46]},\n",
       "  {'input_ids': [516,\n",
       "    327,\n",
       "    44,\n",
       "    258,\n",
       "    390,\n",
       "    779,\n",
       "    402,\n",
       "    1221,\n",
       "    282,\n",
       "    2439,\n",
       "    810,\n",
       "    261,\n",
       "    389,\n",
       "    440,\n",
       "    46,\n",
       "    316,\n",
       "    382,\n",
       "    258,\n",
       "    346,\n",
       "    1798,\n",
       "    266,\n",
       "    407,\n",
       "    265,\n",
       "    322,\n",
       "    413,\n",
       "    46,\n",
       "    317,\n",
       "    1090,\n",
       "    44,\n",
       "    337,\n",
       "    743,\n",
       "    1221,\n",
       "    46,\n",
       "    1174,\n",
       "    349,\n",
       "    367,\n",
       "    265,\n",
       "    325,\n",
       "    476,\n",
       "    543,\n",
       "    261,\n",
       "    390,\n",
       "    779,\n",
       "    46,\n",
       "    284,\n",
       "    1798,\n",
       "    506,\n",
       "    450,\n",
       "    1221,\n",
       "    266,\n",
       "    323,\n",
       "    44,\n",
       "    317,\n",
       "    947,\n",
       "    44,\n",
       "    337,\n",
       "    862,\n",
       "    492,\n",
       "    367,\n",
       "    265,\n",
       "    325,\n",
       "    46,\n",
       "    337,\n",
       "    743,\n",
       "    1192,\n",
       "    266,\n",
       "    337,\n",
       "    862,\n",
       "    492,\n",
       "    735,\n",
       "    2916,\n",
       "    505,\n",
       "    10,\n",
       "    1804,\n",
       "    536,\n",
       "    496,\n",
       "    409,\n",
       "    407,\n",
       "    265,\n",
       "    432,\n",
       "    261,\n",
       "    1798,\n",
       "    735,\n",
       "    833,\n",
       "    46,\n",
       "    316,\n",
       "    1588,\n",
       "    583,\n",
       "    266,\n",
       "    578,\n",
       "    371,\n",
       "    258,\n",
       "    1350,\n",
       "    46,\n",
       "    316,\n",
       "    1533,\n",
       "    383,\n",
       "    261,\n",
       "    631,\n",
       "    468,\n",
       "    533,\n",
       "    630,\n",
       "    1061,\n",
       "    46,\n",
       "    707,\n",
       "    44,\n",
       "    1221,\n",
       "    1588,\n",
       "    265,\n",
       "    261,\n",
       "    1306,\n",
       "    371,\n",
       "    261,\n",
       "    686,\n",
       "    266,\n",
       "    1041,\n",
       "    265,\n",
       "    261,\n",
       "    631,\n",
       "    44,\n",
       "    317,\n",
       "    1936,\n",
       "    44,\n",
       "    631,\n",
       "    44,\n",
       "    432,\n",
       "    627,\n",
       "    545,\n",
       "    358,\n",
       "    735,\n",
       "    2916,\n",
       "    266,\n",
       "    364,\n",
       "    1764,\n",
       "    1782,\n",
       "    687,\n",
       "    10,\n",
       "    412,\n",
       "    631,\n",
       "    837,\n",
       "    1221,\n",
       "    384,\n",
       "    946,\n",
       "    266,\n",
       "    389,\n",
       "    512,\n",
       "    832,\n",
       "    1061,\n",
       "    1366,\n",
       "    354,\n",
       "    261,\n",
       "    389,\n",
       "    440,\n",
       "    46,\n",
       "    284,\n",
       "    1798,\n",
       "    548,\n",
       "    265,\n",
       "    735,\n",
       "    833,\n",
       "    266,\n",
       "    364,\n",
       "    391,\n",
       "    1192,\n",
       "    46,\n",
       "    316,\n",
       "    382,\n",
       "    1221,\n",
       "    266,\n",
       "    323,\n",
       "    44,\n",
       "    317,\n",
       "    848,\n",
       "    349,\n",
       "    44,\n",
       "    390,\n",
       "    779,\n",
       "    44,\n",
       "    387,\n",
       "    1232,\n",
       "    524,\n",
       "    735,\n",
       "    2916,\n",
       "    46,\n",
       "    337,\n",
       "    862,\n",
       "    492,\n",
       "    735,\n",
       "    519,\n",
       "    337,\n",
       "    621,\n",
       "    1764,\n",
       "    1782,\n",
       "    972,\n",
       "    46,\n",
       "    1046,\n",
       "    384,\n",
       "    325,\n",
       "    458,\n",
       "    414,\n",
       "    710,\n",
       "    391,\n",
       "    44,\n",
       "    1221,\n",
       "    266,\n",
       "    261,\n",
       "    1798,\n",
       "    477,\n",
       "    266,\n",
       "    692,\n",
       "    561,\n",
       "    413,\n",
       "    46]},\n",
       "  {'input_ids': [763,\n",
       "    438,\n",
       "    258,\n",
       "    397,\n",
       "    44,\n",
       "    313,\n",
       "    258,\n",
       "    1492,\n",
       "    1328,\n",
       "    371,\n",
       "    1286,\n",
       "    44,\n",
       "    401,\n",
       "    282,\n",
       "    258,\n",
       "    390,\n",
       "    277,\n",
       "    370,\n",
       "    439,\n",
       "    501,\n",
       "    46,\n",
       "    284,\n",
       "    277,\n",
       "    370,\n",
       "    439,\n",
       "    501,\n",
       "    282,\n",
       "    380,\n",
       "    496,\n",
       "    708,\n",
       "    309,\n",
       "    449,\n",
       "    364,\n",
       "    500,\n",
       "    671,\n",
       "    413,\n",
       "    46,\n",
       "    1407,\n",
       "    261,\n",
       "    558,\n",
       "    1286,\n",
       "    405,\n",
       "    346,\n",
       "    266,\n",
       "    973,\n",
       "    44,\n",
       "    409,\n",
       "    261,\n",
       "    277,\n",
       "    370,\n",
       "    439,\n",
       "    501,\n",
       "    282,\n",
       "    563,\n",
       "    266,\n",
       "    2404,\n",
       "    46,\n",
       "    284,\n",
       "    277,\n",
       "    370,\n",
       "    439,\n",
       "    501,\n",
       "    282,\n",
       "    842,\n",
       "    118,\n",
       "    1245,\n",
       "    371,\n",
       "    261,\n",
       "    346,\n",
       "    1286,\n",
       "    304,\n",
       "    10,\n",
       "    516,\n",
       "    327,\n",
       "    44,\n",
       "    261,\n",
       "    277,\n",
       "    370,\n",
       "    439,\n",
       "    501,\n",
       "    536,\n",
       "    258,\n",
       "    2578,\n",
       "    302,\n",
       "    313,\n",
       "    832,\n",
       "    2885,\n",
       "    46,\n",
       "    421,\n",
       "    282,\n",
       "    258,\n",
       "    390,\n",
       "    2922,\n",
       "    861,\n",
       "    46,\n",
       "    284,\n",
       "    861,\n",
       "    741,\n",
       "    261,\n",
       "    277,\n",
       "    370,\n",
       "    439,\n",
       "    501,\n",
       "    364,\n",
       "    265,\n",
       "    322,\n",
       "    496,\n",
       "    46,\n",
       "    284,\n",
       "    861,\n",
       "    323,\n",
       "    44,\n",
       "    317,\n",
       "    540,\n",
       "    486,\n",
       "    868,\n",
       "    708,\n",
       "    349,\n",
       "    500,\n",
       "    1304,\n",
       "    277,\n",
       "    370,\n",
       "    1582,\n",
       "    383,\n",
       "    1027,\n",
       "    2526,\n",
       "    398,\n",
       "    284,\n",
       "    277,\n",
       "    370,\n",
       "    439,\n",
       "    501,\n",
       "    548,\n",
       "    265,\n",
       "    735,\n",
       "    258,\n",
       "    390,\n",
       "    833,\n",
       "    304,\n",
       "    10,\n",
       "    934,\n",
       "    397,\n",
       "    426,\n",
       "    354,\n",
       "    44,\n",
       "    261,\n",
       "    277,\n",
       "    370,\n",
       "    439,\n",
       "    501,\n",
       "    2025,\n",
       "    673,\n",
       "    266,\n",
       "    673,\n",
       "    277,\n",
       "    370,\n",
       "    1582,\n",
       "    46,\n",
       "    1407,\n",
       "    261,\n",
       "    823,\n",
       "    313,\n",
       "    261,\n",
       "    1492,\n",
       "    552,\n",
       "    265,\n",
       "    711,\n",
       "    261,\n",
       "    277,\n",
       "    370,\n",
       "    1582,\n",
       "    266,\n",
       "    325,\n",
       "    776,\n",
       "    261,\n",
       "    277,\n",
       "    370,\n",
       "    439,\n",
       "    501,\n",
       "    46,\n",
       "    284,\n",
       "    277,\n",
       "    370,\n",
       "    439,\n",
       "    501,\n",
       "    282,\n",
       "    377,\n",
       "    708,\n",
       "    309,\n",
       "    365,\n",
       "    664,\n",
       "    413,\n",
       "    972,\n",
       "    46,\n",
       "    284,\n",
       "    277,\n",
       "    370,\n",
       "    439,\n",
       "    501,\n",
       "    691,\n",
       "    383,\n",
       "    1011,\n",
       "    1314,\n",
       "    469,\n",
       "    322,\n",
       "    258,\n",
       "    561,\n",
       "    1253,\n",
       "    46,\n",
       "    710,\n",
       "    360,\n",
       "    431,\n",
       "    636,\n",
       "    992,\n",
       "    933,\n",
       "    886,\n",
       "    46]}],\n",
       " [{'input_ids': [763,\n",
       "    438,\n",
       "    258,\n",
       "    397,\n",
       "    44,\n",
       "    401,\n",
       "    282,\n",
       "    258,\n",
       "    390,\n",
       "    479,\n",
       "    402,\n",
       "    406,\n",
       "    46,\n",
       "    406,\n",
       "    532,\n",
       "    265,\n",
       "    1371,\n",
       "    392,\n",
       "    282,\n",
       "    258,\n",
       "    2053,\n",
       "    2184,\n",
       "    2108,\n",
       "    46,\n",
       "    342,\n",
       "    636,\n",
       "    313,\n",
       "    258,\n",
       "    346,\n",
       "    1576,\n",
       "    328,\n",
       "    338,\n",
       "    696,\n",
       "    413,\n",
       "    44,\n",
       "    258,\n",
       "    456,\n",
       "    266,\n",
       "    258,\n",
       "    465,\n",
       "    304,\n",
       "    10,\n",
       "    516,\n",
       "    327,\n",
       "    44,\n",
       "    1000,\n",
       "    585,\n",
       "    313,\n",
       "    261,\n",
       "    1576,\n",
       "    44,\n",
       "    406,\n",
       "    507,\n",
       "    258,\n",
       "    346,\n",
       "    277,\n",
       "    571,\n",
       "    2066,\n",
       "    98,\n",
       "    46,\n",
       "    284,\n",
       "    277,\n",
       "    571,\n",
       "    2066,\n",
       "    98,\n",
       "    282,\n",
       "    313,\n",
       "    261,\n",
       "    936,\n",
       "    371,\n",
       "    338,\n",
       "    442,\n",
       "    1043,\n",
       "    46,\n",
       "    342,\n",
       "    407,\n",
       "    265,\n",
       "    650,\n",
       "    334,\n",
       "    292,\n",
       "    371,\n",
       "    309,\n",
       "    44,\n",
       "    409,\n",
       "    392,\n",
       "    282,\n",
       "    607,\n",
       "    371,\n",
       "    261,\n",
       "    2212,\n",
       "    383,\n",
       "    636,\n",
       "    401,\n",
       "    304,\n",
       "    10,\n",
       "    670,\n",
       "    543,\n",
       "    338,\n",
       "    413,\n",
       "    44,\n",
       "    261,\n",
       "    456,\n",
       "    266,\n",
       "    261,\n",
       "    465,\n",
       "    44,\n",
       "    265,\n",
       "    432,\n",
       "    338,\n",
       "    46,\n",
       "    312,\n",
       "    431,\n",
       "    1228,\n",
       "    458,\n",
       "    265,\n",
       "    873,\n",
       "    261,\n",
       "    277,\n",
       "    571,\n",
       "    2066,\n",
       "    98,\n",
       "    46,\n",
       "    284,\n",
       "    2212,\n",
       "    282,\n",
       "    496,\n",
       "    44,\n",
       "    409,\n",
       "    309,\n",
       "    507,\n",
       "    258,\n",
       "    545,\n",
       "    584,\n",
       "    697,\n",
       "    46,\n",
       "    406,\n",
       "    44,\n",
       "    261,\n",
       "    456,\n",
       "    44,\n",
       "    266,\n",
       "    261,\n",
       "    465,\n",
       "    405,\n",
       "    377,\n",
       "    360,\n",
       "    468,\n",
       "    325,\n",
       "    1807,\n",
       "    261,\n",
       "    277,\n",
       "    571,\n",
       "    2066,\n",
       "    98,\n",
       "    313,\n",
       "    261,\n",
       "    936,\n",
       "    46,\n",
       "    710,\n",
       "    360,\n",
       "    431,\n",
       "    636,\n",
       "    992,\n",
       "    933,\n",
       "    886,\n",
       "    46]},\n",
       "  {'input_ids': [763,\n",
       "    438,\n",
       "    258,\n",
       "    397,\n",
       "    44,\n",
       "    313,\n",
       "    258,\n",
       "    346,\n",
       "    1903,\n",
       "    44,\n",
       "    401,\n",
       "    282,\n",
       "    258,\n",
       "    1800,\n",
       "    399,\n",
       "    279,\n",
       "    881,\n",
       "    46,\n",
       "    284,\n",
       "    1800,\n",
       "    399,\n",
       "    279,\n",
       "    881,\n",
       "    532,\n",
       "    265,\n",
       "    1349,\n",
       "    313,\n",
       "    261,\n",
       "    686,\n",
       "    431,\n",
       "    327,\n",
       "    734,\n",
       "    46,\n",
       "    421,\n",
       "    282,\n",
       "    380,\n",
       "    377,\n",
       "    634,\n",
       "    309,\n",
       "    468,\n",
       "    1349,\n",
       "    266,\n",
       "    2290,\n",
       "    313,\n",
       "    261,\n",
       "    1903,\n",
       "    304,\n",
       "    10,\n",
       "    516,\n",
       "    327,\n",
       "    44,\n",
       "    258,\n",
       "    390,\n",
       "    497,\n",
       "    402,\n",
       "    341,\n",
       "    552,\n",
       "    265,\n",
       "    325,\n",
       "    328,\n",
       "    261,\n",
       "    1800,\n",
       "    399,\n",
       "    279,\n",
       "    881,\n",
       "    46,\n",
       "    341,\n",
       "    266,\n",
       "    261,\n",
       "    1800,\n",
       "    399,\n",
       "    279,\n",
       "    881,\n",
       "    1814,\n",
       "    313,\n",
       "    261,\n",
       "    686,\n",
       "    458,\n",
       "    46,\n",
       "    312,\n",
       "    703,\n",
       "    266,\n",
       "    365,\n",
       "    258,\n",
       "    653,\n",
       "    371,\n",
       "    442,\n",
       "    46,\n",
       "    284,\n",
       "    631,\n",
       "    282,\n",
       "    1875,\n",
       "    44,\n",
       "    266,\n",
       "    261,\n",
       "    686,\n",
       "    282,\n",
       "    1061,\n",
       "    304,\n",
       "    10,\n",
       "    1260,\n",
       "    258,\n",
       "    1000,\n",
       "    44,\n",
       "    309,\n",
       "    282,\n",
       "    397,\n",
       "    387,\n",
       "    341,\n",
       "    265,\n",
       "    483,\n",
       "    584,\n",
       "    46,\n",
       "    316,\n",
       "    323,\n",
       "    1418,\n",
       "    265,\n",
       "    261,\n",
       "    1800,\n",
       "    399,\n",
       "    279,\n",
       "    881,\n",
       "    266,\n",
       "    760,\n",
       "    309,\n",
       "    258,\n",
       "    346,\n",
       "    695,\n",
       "    46,\n",
       "    284,\n",
       "    1800,\n",
       "    399,\n",
       "    279,\n",
       "    881,\n",
       "    282,\n",
       "    496,\n",
       "    265,\n",
       "    547,\n",
       "    341,\n",
       "    483,\n",
       "    44,\n",
       "    409,\n",
       "    309,\n",
       "    677,\n",
       "    360,\n",
       "    529,\n",
       "    325,\n",
       "    458,\n",
       "    601,\n",
       "    1105,\n",
       "    46,\n",
       "    707,\n",
       "    44,\n",
       "    261,\n",
       "    1800,\n",
       "    399,\n",
       "    279,\n",
       "    881,\n",
       "    1102,\n",
       "    1349,\n",
       "    297,\n",
       "    313,\n",
       "    261,\n",
       "    686,\n",
       "    44,\n",
       "    2425,\n",
       "    387,\n",
       "    261,\n",
       "    988,\n",
       "    442,\n",
       "    327,\n",
       "    328,\n",
       "    341,\n",
       "    46]},\n",
       "  {'input_ids': [763,\n",
       "    438,\n",
       "    258,\n",
       "    397,\n",
       "    44,\n",
       "    313,\n",
       "    258,\n",
       "    563,\n",
       "    1020,\n",
       "    44,\n",
       "    401,\n",
       "    282,\n",
       "    258,\n",
       "    1974,\n",
       "    2887,\n",
       "    390,\n",
       "    479,\n",
       "    402,\n",
       "    406,\n",
       "    46,\n",
       "    342,\n",
       "    282,\n",
       "    704,\n",
       "    496,\n",
       "    708,\n",
       "    392,\n",
       "    1036,\n",
       "    338,\n",
       "    1226,\n",
       "    446,\n",
       "    44,\n",
       "    258,\n",
       "    2963,\n",
       "    302,\n",
       "    46,\n",
       "    342,\n",
       "    506,\n",
       "    1577,\n",
       "    313,\n",
       "    338,\n",
       "    605,\n",
       "    409,\n",
       "    468,\n",
       "    364,\n",
       "    572,\n",
       "    309,\n",
       "    304,\n",
       "    10,\n",
       "    516,\n",
       "    1163,\n",
       "    327,\n",
       "    44,\n",
       "    406,\n",
       "    426,\n",
       "    265,\n",
       "    261,\n",
       "    527,\n",
       "    265,\n",
       "    325,\n",
       "    46,\n",
       "    342,\n",
       "    382,\n",
       "    258,\n",
       "    346,\n",
       "    2010,\n",
       "    371,\n",
       "    686,\n",
       "    266,\n",
       "    578,\n",
       "    338,\n",
       "    2963,\n",
       "    302,\n",
       "    1446,\n",
       "    322,\n",
       "    401,\n",
       "    46,\n",
       "    342,\n",
       "    587,\n",
       "    338,\n",
       "    789,\n",
       "    313,\n",
       "    261,\n",
       "    686,\n",
       "    265,\n",
       "    391,\n",
       "    881,\n",
       "    309,\n",
       "    266,\n",
       "    506,\n",
       "    387,\n",
       "    338,\n",
       "    446,\n",
       "    46,\n",
       "    342,\n",
       "    536,\n",
       "    575,\n",
       "    450,\n",
       "    261,\n",
       "    1554,\n",
       "    283,\n",
       "    371,\n",
       "    261,\n",
       "    2010,\n",
       "    304,\n",
       "    10,\n",
       "    670,\n",
       "    1487,\n",
       "    309,\n",
       "    485,\n",
       "    266,\n",
       "    382,\n",
       "    383,\n",
       "    309,\n",
       "    282,\n",
       "    338,\n",
       "    2963,\n",
       "    302,\n",
       "    33,\n",
       "    342,\n",
       "    282,\n",
       "    391,\n",
       "    377,\n",
       "    383,\n",
       "    392,\n",
       "    507,\n",
       "    309,\n",
       "    46,\n",
       "    939,\n",
       "    383,\n",
       "    327,\n",
       "    354,\n",
       "    44,\n",
       "    406,\n",
       "    282,\n",
       "    858,\n",
       "    1974,\n",
       "    2887,\n",
       "    601,\n",
       "    46,\n",
       "    342,\n",
       "    477,\n",
       "    328,\n",
       "    338,\n",
       "    2963,\n",
       "    302,\n",
       "    589,\n",
       "    327,\n",
       "    266,\n",
       "    704,\n",
       "    1102,\n",
       "    309,\n",
       "    1372,\n",
       "    265,\n",
       "    338,\n",
       "    46,\n",
       "    710,\n",
       "    634,\n",
       "    392,\n",
       "    382,\n",
       "    1851,\n",
       "    1120,\n",
       "    44,\n",
       "    392,\n",
       "    529,\n",
       "    963,\n",
       "    266,\n",
       "    1195,\n",
       "    756,\n",
       "    392,\n",
       "    507,\n",
       "    338,\n",
       "    446,\n",
       "    46]},\n",
       "  {'input_ids': [763,\n",
       "    438,\n",
       "    258,\n",
       "    397,\n",
       "    44,\n",
       "    313,\n",
       "    258,\n",
       "    2770,\n",
       "    1020,\n",
       "    44,\n",
       "    401,\n",
       "    636,\n",
       "    258,\n",
       "    390,\n",
       "    497,\n",
       "    402,\n",
       "    341,\n",
       "    46,\n",
       "    341,\n",
       "    508,\n",
       "    265,\n",
       "    740,\n",
       "    266,\n",
       "    325,\n",
       "    697,\n",
       "    46,\n",
       "    451,\n",
       "    327,\n",
       "    44,\n",
       "    341,\n",
       "    382,\n",
       "    258,\n",
       "    1178,\n",
       "    313,\n",
       "    261,\n",
       "    527,\n",
       "    46,\n",
       "    316,\n",
       "    282,\n",
       "    729,\n",
       "    266,\n",
       "    407,\n",
       "    265,\n",
       "    1528,\n",
       "    261,\n",
       "    1178,\n",
       "    304,\n",
       "    10,\n",
       "    645,\n",
       "    426,\n",
       "    265,\n",
       "    340,\n",
       "    358,\n",
       "    44,\n",
       "    1669,\n",
       "    44,\n",
       "    266,\n",
       "    323,\n",
       "    44,\n",
       "    317,\n",
       "    914,\n",
       "    384,\n",
       "    1922,\n",
       "    261,\n",
       "    1178,\n",
       "    414,\n",
       "    1669,\n",
       "    565,\n",
       "    266,\n",
       "    323,\n",
       "    44,\n",
       "    317,\n",
       "    732,\n",
       "    44,\n",
       "    781,\n",
       "    384,\n",
       "    483,\n",
       "    414,\n",
       "    312,\n",
       "    275,\n",
       "    1879,\n",
       "    368,\n",
       "    328,\n",
       "    261,\n",
       "    558,\n",
       "    1006,\n",
       "    266,\n",
       "    1564,\n",
       "    387,\n",
       "    261,\n",
       "    1178,\n",
       "    265,\n",
       "    322,\n",
       "    103,\n",
       "    270,\n",
       "    46,\n",
       "    931,\n",
       "    360,\n",
       "    837,\n",
       "    261,\n",
       "    1504,\n",
       "    317,\n",
       "    71,\n",
       "    111,\n",
       "    414,\n",
       "    44,\n",
       "    360,\n",
       "    548,\n",
       "    1374,\n",
       "    445,\n",
       "    737,\n",
       "    445,\n",
       "    360,\n",
       "    468,\n",
       "    304,\n",
       "    10,\n",
       "    645,\n",
       "    266,\n",
       "    1669,\n",
       "    598,\n",
       "    328,\n",
       "    431,\n",
       "    470,\n",
       "    2310,\n",
       "    263,\n",
       "    44,\n",
       "    1847,\n",
       "    266,\n",
       "    1111,\n",
       "    442,\n",
       "    46,\n",
       "    312,\n",
       "    468,\n",
       "    735,\n",
       "    261,\n",
       "    861,\n",
       "    313,\n",
       "    470,\n",
       "    1309,\n",
       "    445,\n",
       "    360,\n",
       "    334,\n",
       "    2490,\n",
       "    265,\n",
       "    261,\n",
       "    2317,\n",
       "    2315,\n",
       "    46,\n",
       "    964,\n",
       "    261,\n",
       "    882,\n",
       "    44,\n",
       "    341,\n",
       "    1583,\n",
       "    261,\n",
       "    1178,\n",
       "    266,\n",
       "    1669,\n",
       "    552,\n",
       "    313,\n",
       "    459,\n",
       "    1324,\n",
       "    262,\n",
       "    46,\n",
       "    312,\n",
       "    405,\n",
       "    722,\n",
       "    391,\n",
       "    377,\n",
       "    266,\n",
       "    900,\n",
       "    371,\n",
       "    493,\n",
       "    2933,\n",
       "    46,\n",
       "    312,\n",
       "    2798,\n",
       "    1771,\n",
       "    328,\n",
       "    470,\n",
       "    413,\n",
       "    266,\n",
       "    365,\n",
       "    258,\n",
       "    968,\n",
       "    327,\n",
       "    450,\n",
       "    261,\n",
       "    527,\n",
       "    46]}]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_batches[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78c607d",
   "metadata": {},
   "source": [
    "### Sequence packer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd3464e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2024 onwards Answer.AI, LightOn, and contributors\n",
    "# License: Apache-2.0\n",
    "\n",
    "import threading\n",
    "import time\n",
    "from abc import ABC, abstractmethod\n",
    "from collections import deque\n",
    "from typing import Generic, Iterable, NamedTuple, Optional, TypeVar, Any, Union, Sequence\n",
    "from composer.core.types import Batch\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from numba import njit\n",
    "\n",
    "\n",
    "import math\n",
    "from composer.core import Time\n",
    "\n",
    "\n",
    "class BatchSizeWarmupScheduler:\n",
    "    def __init__(\n",
    "        self,\n",
    "        min_batch_size: int,\n",
    "        max_batch_size: int,\n",
    "        warmup_tokens: Union[str, Time, int],\n",
    "        world_size: int,\n",
    "    ):\n",
    "        self.min_batch_size = min_batch_size\n",
    "        self.max_batch_size = max_batch_size\n",
    "\n",
    "        if isinstance(warmup_tokens, str):\n",
    "            self.warmup_tokens = Time.from_timestring(warmup_tokens).value\n",
    "        elif isinstance(warmup_tokens, Time):\n",
    "            self.warmup_tokens = warmup_tokens.value\n",
    "        else:\n",
    "            self.warmup_tokens = warmup_tokens\n",
    "        self.warmup_tokens = math.ceil(self.warmup_tokens / world_size)\n",
    "        self._step_thresholds = self._calculate_step_thresholds()\n",
    "\n",
    "    def _calculate_step_thresholds(self):\n",
    "        total_batch_sizes = sum(range(self.min_batch_size, self.max_batch_size))\n",
    "        steps_per_unit = self.warmup_tokens / total_batch_sizes\n",
    "\n",
    "        thresholds = []\n",
    "        cumsum = 0\n",
    "        for batch_size in range(self.min_batch_size, self.max_batch_size):\n",
    "            cumsum += batch_size\n",
    "            steps = math.ceil(steps_per_unit * cumsum)\n",
    "            thresholds.append(steps)\n",
    "        return thresholds\n",
    "\n",
    "    def __call__(self, current_step: int) -> int:\n",
    "        if current_step >= self.warmup_tokens:\n",
    "            return self.max_batch_size\n",
    "\n",
    "        for i, threshold in enumerate(self._step_thresholds):\n",
    "            if current_step < threshold:\n",
    "                return self.min_batch_size + i\n",
    "\n",
    "        # should never hit this, but just in case\n",
    "        return self.max_batch_size\n",
    "\n",
    "\n",
    "class SequencePackerBatchOutputTuple(NamedTuple):\n",
    "    masked_pseqs: torch.Tensor\n",
    "    labels: Optional[torch.Tensor]\n",
    "    cu_seq_lens: list[torch.Tensor]\n",
    "    max_cu_seq_len: list[torch.Tensor]\n",
    "\n",
    "\n",
    "class SequencePacker(ABC):\n",
    "    def __init__(\n",
    "        self,\n",
    "        # params defining the incoming batches of seqs\n",
    "        src_iterable: Iterable[list[list[int]]],\n",
    "        src_batch_size: int,\n",
    "        src_max_seq_len: int,\n",
    "        # params defining outgoing batches of pseqs\n",
    "        out_batch_size: int,\n",
    "        out_pseq_len: int,\n",
    "        # params defining internal behavior\n",
    "        buffer_size: int,\n",
    "        pad_token_id: int = -1,\n",
    "        mask_token_id: int = 0,\n",
    "        ignore_token_id: int = -100,\n",
    "        mask_prob: float = 0.3,\n",
    "        seed=42,\n",
    "        suppress_masking: bool = False,\n",
    "        batch_size_warmup_min_size: Optional[int] = None,\n",
    "        batch_size_warmup_tokens: Optional[Union[str, Time]] = None,\n",
    "        world_size: int = 1,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Takes batches of unpacked, unpadded sequences (seqs) to batches of packed and padded sequences (pseqs).\n",
    "\n",
    "        Every input batch must be a list[list[int]], a list of variable-length sequences of tokens.\n",
    "\n",
    "        Every output batch is a tuple (masked_inputs:Tensor, labels:Tensor, seq_starts_and_end:list).\n",
    "\n",
    "        It performs this streamwise, taking an iterable as the source of incoming batches, and\n",
    "        presents itself as an iterable of outgoing batches.\n",
    "\n",
    "        Args:\n",
    "            src_iterable: An iterable (e.g., a DataLoader), whose iterator yields one incoming batch,\n",
    "                        where a batch is a list of unpadded, variable-length Sequences of token\n",
    "                        IDs. Since this only needs to be an Iterable, it could also be a generator object\n",
    "                         like the result of `itertools.batched(dataset_list,batch_size))`\n",
    "\n",
    "            src_batch_size:  This is the INCOMING batch size, the number of seqs in one batch yielded\n",
    "                          from `src_iterable`'s iterator.\n",
    "\n",
    "            src_max_seq_len: The maximum number of tokens in a seq within an incoming batch.\n",
    "\n",
    "            out_batch_size: the number of pseqs (packed seqs) in one outgoing batch\n",
    "\n",
    "            out_pseq_len: the number of tokens per packed seq, in every outgoing batch\n",
    "\n",
    "            buffer_size: The maximum number of seqs which may be buffered internally.\n",
    "\n",
    "            pad_token_id: The token ID used for padding the space which cannot be filled to reach out_pseq_len.\n",
    "\n",
    "            mask_token_id: The token ID used for masking tokens in the input sequence.\n",
    "\n",
    "            ignore_token_id: The token ID used to ignore tokens. Expected to be applied to every non-masked token, so the model only trains on predictions of masked tokens.\n",
    "\n",
    "            suppress_masking: If True, the sequence packer will not perform masked language modeling.\n",
    "\n",
    "            batch_size_warmup_min_size: If not None, the sequence packer will gradually increase the batch size from batch_size_warmup_min_size to out_batch_size over the course of the warmup_tokens.\n",
    "                                    batch_size_warmup_min_size must be a multiple of micro_batch_size.\n",
    "\n",
    "            batch_size_warmup_tokens: If not None, the sequence packer will gradually increase the batch size from batch_size_warmup_min_size to out_batch_size over the course of the warmup_tokens.\n",
    "\n",
    "            world_size: The number of processes participating in this training run. batch_size_warmup_min_size is divided by this number.\n",
    "        \"\"\"\n",
    "        assert buffer_size >= out_batch_size, f\"required that {buffer_size=} >= {out_batch_size=}\"\n",
    "        self.src_dataloader_len = len(src_iterable)\n",
    "        self.src_iterable = src_iterable\n",
    "        self.src_batch_size = src_batch_size\n",
    "        self.out_batch_size = out_batch_size\n",
    "        self.out_pseq_len = out_pseq_len\n",
    "        self.buffer_size = buffer_size\n",
    "        self.pad_token_id = pad_token_id\n",
    "        self.mask_token_id = mask_token_id\n",
    "        self.ignore_token_id = ignore_token_id\n",
    "        self.mask_prob = mask_prob\n",
    "        self.suppress_masking = suppress_masking\n",
    "        # internals\n",
    "        self.buffer = deque()  # internal buffer holds individual seqs, as tensors.\n",
    "        # for stats to report packing efficiency.\n",
    "        self._seqs_consumed = 0\n",
    "        self._seqs_emitted = 0\n",
    "        # Set random seed\n",
    "        self.seed = seed\n",
    "        self.epoch = -1\n",
    "        self._token_count = 0\n",
    "        self.batch_size_scheduler = None\n",
    "        if batch_size_warmup_min_size is not None and batch_size_warmup_tokens is not None:\n",
    "            self.batch_size_scheduler = BatchSizeWarmupScheduler(\n",
    "                batch_size_warmup_min_size, out_batch_size, batch_size_warmup_tokens, world_size\n",
    "            )\n",
    "        else:\n",
    "            self.batch_size_scheduler = None\n",
    "\n",
    "    @property\n",
    "    def seqs_emitted(self):\n",
    "        \"Number of seqs, incoming from src_iterable, which have been emitted in OUTGOING batches.\"\n",
    "        return self._seqs_emitted\n",
    "\n",
    "    @property\n",
    "    def seqs_consumed(self):\n",
    "        \"Number of seqs, incoming from src_iterable, which have been consumed.\"\n",
    "        return self._seqs_consumed\n",
    "\n",
    "    def _reset_state(self):\n",
    "        self.epoch += 1\n",
    "        self.buffer.clear()\n",
    "        self._seqs_consumed = 0\n",
    "        self._seqs_emitted = 0\n",
    "        self.np_rng = np.random.default_rng(self.epoch + self.seed)\n",
    "\n",
    "        # Update the epoch for the sampler\n",
    "        if isinstance(self.src_iterable, torch.utils.data.dataloader.DataLoader):\n",
    "            if isinstance(self.src_iterable.sampler, torch.utils.data.distributed.DistributedSampler):\n",
    "                self.src_iterable.sampler.set_epoch(self.epoch)\n",
    "\n",
    "    def __iter__(self):\n",
    "        self._reset_state()\n",
    "        self.src_iterator = iter(self.src_iterable)\n",
    "        return self._generate_batches()\n",
    "\n",
    "    def __len__(self):\n",
    "        # rather than estimate the packed length of the dataset, we rely on Composer's ability\n",
    "        # to schedule training the using the number of batches or tokens instead of epochs.\n",
    "        return None\n",
    "\n",
    "    def _fill_buffer(self, max_items_to_add=float(\"inf\")) -> int:\n",
    "        \"\"\"\n",
    "        Refills the internal buffer.\n",
    "\n",
    "        - max_items_to_add: an amount less than or equal to the number of items to add\n",
    "\n",
    "        Returns: the number of items actually added.\n",
    "\n",
    "        The default implementation of this simply extends to src.buffer, which is\n",
    "        initialized as a list in __init__. Subclasses which want to use a different data\n",
    "        structure for internal buffering should override this method and also add\n",
    "        code in __init__ to initialize src.buffer appropriately.\n",
    "\n",
    "        Any implementation of this MUST never place more than self.buffer_size items\n",
    "        in the internal buffer.\n",
    "        \"\"\"\n",
    "        items_added = 0\n",
    "        # NOTE: this should be >=, kept as is to match model training code\n",
    "        # TODO: change if training a new model\n",
    "        while (self.buffer_size - len(self.buffer)) > self.src_batch_size:\n",
    "            try:\n",
    "                # if pulling another batch would fetch more than the requested max, stop\n",
    "                if max_items_to_add < float(\"inf\"):\n",
    "                    if (items_added + self.src_batch_size) > max_items_to_add:\n",
    "                        # print(\"Not adding, because of max_items_to_fetch\")\n",
    "                        break\n",
    "                incoming_batch = next(self.src_iterator)\n",
    "                assert (\n",
    "                    len(incoming_batch) <= self.src_batch_size\n",
    "                ), f\"expected {len(incoming_batch)=} <= {self.src_batch_size=}\"\n",
    "                for item in incoming_batch:\n",
    "                    if len(item[\"input_ids\"]) > 0:  # ignore empty sequences\n",
    "                        self.buffer.append(item[\"input_ids\"])\n",
    "                        items_added += 1\n",
    "                        self._seqs_consumed += 1\n",
    "            except StopIteration:\n",
    "                break\n",
    "        return items_added\n",
    "\n",
    "    def _generate_batches(self):\n",
    "        \"\"\"\n",
    "        Generates batches of packed sequences.\n",
    "\n",
    "        The returned generator's iterator will always, when next() is called on it, either:\n",
    "         - return a valid tuple batch (masked_batch, labels, cu_seq_lens,max_seq_lens)\n",
    "         - raise StopIteration\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            retval = self._create_batch()\n",
    "            if retval is None:\n",
    "                break\n",
    "            batch, lst_cu_seq_lens = retval\n",
    "\n",
    "            assert isinstance(retval, tuple), f\"Unexpected {type(retval)=}\"\n",
    "            assert isinstance(retval[0], np.ndarray), f\"Unexpected {type(retval[0])=}\"\n",
    "            assert isinstance(retval[1], list), f\"Unexpected {type(retval[1])=}\"\n",
    "\n",
    "            cu_seq_lens = [torch.tensor(x, dtype=torch.int32) for x in lst_cu_seq_lens]\n",
    "            max_seq_lens = [torch.max(x[1:] - x[:-1]).item() for x in cu_seq_lens]\n",
    "            assert isinstance(cu_seq_lens, list), f\"Unexpected {type(cu_seq_lens)=}\"\n",
    "            if self.suppress_masking:\n",
    "                yieldval = {\n",
    "                    \"input_ids\": torch.from_numpy(batch),\n",
    "                    \"labels\": None,\n",
    "                    \"cu_seqlens\": cu_seq_lens,\n",
    "                    \"max_seqlen\": max_seq_lens,\n",
    "                }\n",
    "            else:\n",
    "                (masked_batch, labels) = SequencePacker.mlm_masking(\n",
    "                    batch, self.mask_prob, self.mask_token_id, self.pad_token_id, self.ignore_token_id, self.np_rng\n",
    "                )\n",
    "                yieldval = {\n",
    "                    \"input_ids\": torch.from_numpy(masked_batch),\n",
    "                    \"labels\": torch.from_numpy(labels),\n",
    "                    \"cu_seqlens\": cu_seq_lens,\n",
    "                    \"max_seqlen\": max_seq_lens,\n",
    "                    \"attention_mask\": torch.from_numpy(np.where(batch == self.pad_token_id, 0, 1)),\n",
    "                }\n",
    "                self._token_count += yieldval[\"attention_mask\"].sum().item()\n",
    "            # # assert isinstance(yieldval[0], torch.Tensor), f\"Unexpected {type(yieldval[0])=}\"\n",
    "            # if not self.suppress_masking:\n",
    "            #     assert isinstance(yieldval[1], torch.Tensor), f\"Unexpected {type(yieldval[1])=}\"\n",
    "            # assert isinstance(yieldval[2], list), f\"Unexpected {type(yieldval[2])=}\"\n",
    "            # if yieldval[2]:\n",
    "            #     assert isinstance(yieldval[2][0], torch.Tensor), f\"Unexpected {type(yieldval[2][0])=}\"\n",
    "            yield yieldval\n",
    "\n",
    "    @staticmethod\n",
    "    def mlm_masking(\n",
    "        seq: np.ndarray,\n",
    "        mask_prob: float,\n",
    "        mask_token: int,\n",
    "        pad_token: int = -1,\n",
    "        ignore_index: int = -100,\n",
    "        np_rng=np.random.default_rng(),\n",
    "    ) -> tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Prepare masked tokens inputs/labels for masked language modeling: 80% MASK, 10% random, 10% original.\n",
    "\n",
    "        This is exactly a numpy version of transformers' `DataCollatorForLanguageModeling.torch_mask_tokens`\n",
    "        https://github.com/huggingface/transformers/blob/main/src/transformers/data/data_collator.py#L827\n",
    "\n",
    "        It performs masking in a way that produces on expectation the following masked inputs:\n",
    "         - (1-mask_prob) of the original positions will be untouched.\n",
    "         - mask_prob * 80%  of the original positions get replaced with a mask token\n",
    "         - mask_prob * 10%  of the original positions get replaced with a random token\n",
    "         - mask_prob * 10%  of the original positions also remain untouched.\n",
    "        This generates the masked_inputs.\n",
    "\n",
    "        It also generates a labels array, which has ignore tokens in the (1-mask_prob) positions\n",
    "\n",
    "        These proportions are expectation values since the random transformation is performed\n",
    "        independently per element. (This is why it is agnostic wrt shape.)\n",
    "\n",
    "        Args:\n",
    "          seq (np.ndarray): the input token IDs (e.g., a sequence, or batch of seqs)\n",
    "          mask_prob (float): probability of initially masking a token, in the first \"wave\" of masking\n",
    "          mask_token (int): token to use for masking\n",
    "          ignore_index (int): the token indicating that position should be ignored during training. We call it `ignore_index` to conform to the API of the cross entropy loss function.\n",
    "\n",
    "        Returns:\n",
    "            tuple[np.array,np.array]: (masked_seq, labels)\n",
    "                masked_seq: the input seq with some tokens replaced by `mask_token`\n",
    "                labels: the original input seq with non-masked tokens replaced by `ignore_index`\n",
    "        \"\"\"\n",
    "        # Create labels\n",
    "        labels = np.where(seq == pad_token, ignore_index, seq)\n",
    "\n",
    "        # Create a single mask\n",
    "        rand = np_rng.random(seq.shape)\n",
    "\n",
    "        # Partition the probability space appropriately using a single mask\n",
    "        # 80% of the time, we mask the token\n",
    "        mask_mask = rand < mask_prob * 0.8\n",
    "        # 10% of the time, we replace the token with a random token\n",
    "        random_mask = (rand >= mask_prob * 0.8) & (rand < mask_prob * 0.9)\n",
    "        # 10% of the time, we keep the token the same\n",
    "        keep_mask = (rand >= mask_prob * 0.9) & (rand < mask_prob)\n",
    "\n",
    "        # We only compute loss over the tokens marked for masking\n",
    "        labels = np.where(mask_mask | random_mask | keep_mask, labels, ignore_index)\n",
    "\n",
    "        # Apply masking\n",
    "        seq = np.where(mask_mask, mask_token, seq)\n",
    "\n",
    "        # Apply random replacement\n",
    "        random_words = np_rng.integers(0, np.max(seq) + 1, size=seq.shape)\n",
    "        seq = np.where(random_mask, random_words, seq)\n",
    "\n",
    "        return seq, labels\n",
    "\n",
    "    @abstractmethod\n",
    "    def _create_batch(self) -> Optional[tuple[np.ndarray, list[list[int]]]]:\n",
    "        \"\"\"\n",
    "        Returns a batch of packed sequences with its cumulative seq length information.\n",
    "\n",
    "        Or else, returns None if it cannot build a full outgoing batch.\n",
    "\n",
    "        Must mutate self.buffer to remove the sequences that are packed into the batch.\n",
    "\n",
    "        Returns:\n",
    "            (out_batch,cumulative_seq_len):tuple[torch.tensor, list[list[int]]]\n",
    "            where:\n",
    "                - out_batch is a tensor of shape (out_batch_size, out_pseq_len);\n",
    "                - cum_seq_lens is a list of lists, where the outer list is of len out_batch_size,\n",
    "                    and each inner list is of varying length, and contains the start positions of\n",
    "                    every seq in the pseq, and the end position of the last seq in the pseq. This end\n",
    "                    position is necessary to communicate if any padding tokens were added.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "@njit\n",
    "def find_best_fit(remaining_spaces, seq_len):\n",
    "    valid_spaces = seq_len <= remaining_spaces\n",
    "    if np.any(valid_spaces):\n",
    "        valid_space_sizes = remaining_spaces[valid_spaces]\n",
    "        best_fit_idx = np.argmin(valid_space_sizes)\n",
    "        return np.arange(len(remaining_spaces))[valid_spaces][best_fit_idx]\n",
    "    return -1\n",
    "\n",
    "\n",
    "class GreedyBestFitSequencePacker(SequencePacker):\n",
    "    @classmethod\n",
    "    def from_composer(\n",
    "        cls,\n",
    "        src_iterable: Iterable[list[list[int]]],\n",
    "        batch_size: int = 512,\n",
    "        micro_batch_size: int = 32,\n",
    "        max_seq_len: int = 1024,\n",
    "        buffer_size: int = 5120,\n",
    "        # token values\n",
    "        pad_token_id: int = -1,\n",
    "        mask_token_id: int = 0,\n",
    "        ignore_token_id: int = -100,\n",
    "        mask_prob: float = 0.3,\n",
    "        # transform values\n",
    "        seed=42,\n",
    "        suppress_masking=False,\n",
    "        batch_size_warmup_min_size: Optional[int] = None,\n",
    "        batch_size_warmup_tokens: Optional[Union[str, Time]] = None,\n",
    "        world_size: int = 1,\n",
    "    ) -> \"GreedyBestFitSequencePacker\":\n",
    "        if batch_size_warmup_min_size is not None:\n",
    "            if batch_size_warmup_min_size % micro_batch_size != 0:\n",
    "                raise ValueError(f\"{batch_size_warmup_min_size=} must be a multiple of {micro_batch_size=}\")\n",
    "            batch_size_warmup_min_size = int(batch_size_warmup_min_size / micro_batch_size)\n",
    "        return cls(\n",
    "            # input shape\n",
    "            src_iterable=src_iterable,\n",
    "            src_batch_size=batch_size,\n",
    "            src_max_seq_len=max_seq_len,\n",
    "            # output shape\n",
    "            out_batch_size=int(batch_size / micro_batch_size),\n",
    "            out_pseq_len=int(micro_batch_size * max_seq_len),\n",
    "            # internal\n",
    "            buffer_size=buffer_size,\n",
    "            # transformation\n",
    "            pad_token_id=pad_token_id,\n",
    "            mask_token_id=mask_token_id,\n",
    "            ignore_token_id=ignore_token_id,\n",
    "            mask_prob=mask_prob,\n",
    "            seed=seed,\n",
    "            suppress_masking=suppress_masking,\n",
    "            batch_size_warmup_min_size=batch_size_warmup_min_size,\n",
    "            batch_size_warmup_tokens=batch_size_warmup_tokens,\n",
    "            world_size=world_size,\n",
    "        )\n",
    "\n",
    "    def _create_batch(self) -> Optional[tuple[np.ndarray, list[list[int]]]]:\n",
    "        if self.batch_size_scheduler:\n",
    "            self.out_batch_size = self.batch_size_scheduler(self._token_count)\n",
    "\n",
    "        batch = np.full(\n",
    "            (self.out_batch_size, self.out_pseq_len), self.pad_token_id, dtype=np.int64\n",
    "        )  # the pseqs being constructed\n",
    "        seq_counts = np.zeros(self.out_batch_size, dtype=np.int32)  # the count of seqs per pseq\n",
    "        cum_seq_lens = [[0] for _ in range(self.out_batch_size)]\n",
    "        remaining_spaces = np.full(\n",
    "            (self.out_batch_size,), self.out_pseq_len, dtype=np.int32\n",
    "        )  # the space remaining per pseq\n",
    "        temp_buffer = []\n",
    "\n",
    "        while True:\n",
    "            # Check if buffer has more items, and if not replenish\n",
    "            if not self.buffer:\n",
    "                items_to_fetch = self.buffer_size - len(temp_buffer)\n",
    "                items_added = self._fill_buffer(items_to_fetch)\n",
    "                if items_added == 0:\n",
    "                    break\n",
    "\n",
    "            seq = self.buffer.popleft()\n",
    "            seq_len = len(seq)\n",
    "\n",
    "            # Find the best fit (smallest space that can accommodate the sequence)\n",
    "            best_fit_idx = find_best_fit(remaining_spaces, seq_len)\n",
    "            if best_fit_idx != -1:\n",
    "                end_pos = self.out_pseq_len - remaining_spaces[best_fit_idx]\n",
    "                batch[best_fit_idx, end_pos : end_pos + seq_len] = seq\n",
    "                seq_counts[best_fit_idx] += 1\n",
    "                remaining_spaces[best_fit_idx] -= seq_len\n",
    "                cum_seq_lens[best_fit_idx].append(cum_seq_lens[best_fit_idx][-1] + seq_len)\n",
    "            else:\n",
    "                # Can't fit the sequence, save for next batch\n",
    "                temp_buffer.append(seq)\n",
    "\n",
    "        # Add any sequences we skipped back to the start of the buffer\n",
    "        self.buffer.extendleft(temp_buffer)\n",
    "        if np.all(seq_counts > 0):\n",
    "            self._seqs_emitted += np.sum(seq_counts)\n",
    "            for x in cum_seq_lens:\n",
    "                if x[-1] != self.out_pseq_len:\n",
    "                    x.append(self.out_pseq_len)\n",
    "            return batch, cum_seq_lens\n",
    "        else:\n",
    "            # If we can't form a full batch, we return None to signal the end\n",
    "            return None\n",
    "\n",
    "\n",
    "T = TypeVar(\"T\")\n",
    "\n",
    "\n",
    "class BufferedIterable(Generic[T]):\n",
    "    def __init__(self, iterable: Iterable[T], buffer_size: int):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          - iterable: an object which generates a fresh iterator on iter() and which implements len()\n",
    "        \"\"\"\n",
    "        self.iterable = iterable\n",
    "        self.buffer_size = buffer_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        return BufferedIterator(self.iterable, self.buffer_size)\n",
    "\n",
    "\n",
    "class BufferedIterator(Generic[T]):\n",
    "    def __init__(self, iterable: Iterable[T], buffer_size: int):\n",
    "        self.iterator = iter(iterable)\n",
    "        self.buffer = deque(maxlen=buffer_size)\n",
    "        self.buffer_size = buffer_size\n",
    "        self.lock = threading.Lock()\n",
    "        self.exhausted = False\n",
    "        self.filler_thread = threading.Thread(target=self._background_fill, daemon=True)\n",
    "        self.filler_thread.start()\n",
    "\n",
    "    def _background_fill(self):\n",
    "        # Fill up the buffer, whenever possible, in the background\n",
    "        while not self.exhausted:\n",
    "            if len(self.buffer) < self.buffer_size:\n",
    "                try:\n",
    "                    item = next(self.iterator)\n",
    "                    with self.lock:\n",
    "                        self.buffer.append(item)\n",
    "                except StopIteration:\n",
    "                    self.exhausted = True\n",
    "                    break\n",
    "            else:\n",
    "                time.sleep(0.01)  # Sleep for a bit to avoid busy waiting\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self) -> T:\n",
    "        while True:\n",
    "            if not self.buffer:\n",
    "                if self.exhausted:\n",
    "                    # We've exhausted the iterator and the buffer so we're done\n",
    "                    raise StopIteration\n",
    "                else:\n",
    "                    # The buffer is empty but the iterator is not exhausted yet.\n",
    "                    # Let's give the filler thread a chance to add items to the buffer\n",
    "                    time.sleep(0.01)\n",
    "            else:\n",
    "                with self.lock:\n",
    "                    return self.buffer.popleft()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1b397a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSequencePacker(GreedyBestFitSequencePacker):\n",
    "    def _generate_batches(self):\n",
    "        \"\"\"\n",
    "        Generates batches of packed sequences for causal attention.\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            retval = self._create_batch()\n",
    "            if retval is None:\n",
    "                break\n",
    "            batch, lst_cu_seq_lens = retval\n",
    "\n",
    "            assert isinstance(retval, tuple), f\"Unexpected {type(retval)=}\"\n",
    "            assert isinstance(retval[0], np.ndarray), f\"Unexpected {type(retval[0])=}\"\n",
    "            assert isinstance(retval[1], list), f\"Unexpected {type(retval[1])=}\"\n",
    "\n",
    "            cu_seq_lens = [torch.tensor(x, dtype=torch.int32) for x in lst_cu_seq_lens]\n",
    "            max_seq_lens = [torch.max(x[1:] - x[:-1]).item() for x in cu_seq_lens]\n",
    "            assert isinstance(cu_seq_lens, list), f\"Unexpected {type(cu_seq_lens)=}\"\n",
    "            if self.suppress_masking:\n",
    "                yieldval = {\n",
    "                    \"input_ids\": torch.from_numpy(batch[:, :-1]),\n",
    "                    \"labels\": torch.from_numpy(batch[:, 1:]),\n",
    "                    \"cu_seqlens\": cu_seq_lens,\n",
    "                    \"max_seqlen\": max_seq_lens,\n",
    "                }\n",
    "            else:\n",
    "                (masked_batch, labels) = SequencePacker.mlm_masking(\n",
    "                    batch, self.mask_prob, self.mask_token_id, self.pad_token_id, self.ignore_token_id, self.np_rng\n",
    "                )\n",
    "                yieldval = {\n",
    "                    \"input_ids\": torch.from_numpy(masked_batch),\n",
    "                    \"labels\": torch.from_numpy(labels),\n",
    "                    \"cu_seqlens\": cu_seq_lens,\n",
    "                    \"max_seqlen\": max_seq_lens,\n",
    "                    \"attention_mask\": torch.from_numpy(np.where(batch == self.pad_token_id, 0, 1)),\n",
    "                }\n",
    "                self._token_count += yieldval[\"attention_mask\"].sum().item()\n",
    "            yield yieldval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95469fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_batches = list(batched(xds, bs))\n",
    "d = {\n",
    "    \"src_iterable\": input_batches,\n",
    "    \"src_batch_size\": bs,\n",
    "    \"src_max_seq_len\": 1,\n",
    "    \"out_batch_size\": 1,\n",
    "    \"out_pseq_len\": 500,\n",
    "    \"buffer_size\": 5,\n",
    "    \"pad_token_id\": -1,\n",
    "    \"mask_token_id\": -2,\n",
    "    \"ignore_token_id\": -3,\n",
    "    \"mask_prob\": 0.0,\n",
    "    \"seed\": 42,\n",
    "    \"suppress_masking\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e285d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 516,  327,   44,  258,  390,  479,  402,  406,  507,  258,  775,  302,\n",
       "           313,  338,  720,   46,  342,  677,  309,  282, 2876,  265,  325,  328,\n",
       "           309,  708,  309,  282, 2073,   46,  406,  407,  265,  850,  261,  775,\n",
       "           302,  328,  338,  386,   44,  391,  392,  468,  459,  119,  258, 1674,\n",
       "           354,  338, 2377,  304,   10,  670,  426,  265,  338,  386,  266,  323,\n",
       "            44,  317,  844,   44,  337,  507,  733,  775,  302,   46, 1127,  349,\n",
       "           850,  309,  328,  524,  266,  459,  119,  627, 2377,  476,  937,  386,\n",
       "           565,  266,  323,   44,  317,  732,   44,  406,   44,  363,  469,  850,\n",
       "           261,  775,  302,  266, 1125,  629, 2377,  505,   10, 2826,   44,  360,\n",
       "          1208,  261,  775,  302,  266,  459,  119,  263,  261, 1674,  354,  406,\n",
       "           384, 2377,   46,  421,  282,  364, 2876,  387,  493,  708,  360,  405,\n",
       "          1714,  266, 1398,  766,  558,   46, 1559,  360, 1699,   44,  406,  943,\n",
       "           338,  386,  387, 1714,  261,  775,  302,  266, 1125,  297,  338, 2377,\n",
       "            46,  312,  722,  536,  377,  708,  360,  365, 1208,  266, 1228,  458,\n",
       "            46,  763,  438,  258,  397,   44,  401,  282,  258,  390,  528,  402,\n",
       "          2456,  626,   46, 2456,  626,  508,  265,  483,  737,  266,  325,  313,\n",
       "           261,  631,   46, 2456,  626,  282,  258, 2489,  528,  708,  285,  704,\n",
       "           365,  561,  268,  117,  417,   46, 1213,  462,  268,  117,  417,  586,\n",
       "          2456,  626,  377,  266,  973,  304,   10,  516,  327,   44, 2456,  626,\n",
       "           282, 1402,  817,  313,  261,  527,  634,  285,  382,  258,  346,  501,\n",
       "            46,  284,  501,  365,  664, 1333,  383,  405, 1455,  297,   46, 2456,\n",
       "           626,  532,  756,  261, 1333, 1455,  266,  407,  265,  325,  328,  493,\n",
       "            46, 2456,  626, 2241,  776,  261,  501,  266, 1233,  261, 1333, 1455,\n",
       "           354,  475,   46,  316,  703,  266,  322,  626,  263,  340, 2771,  304,\n",
       "            10, 2120,  626,  477,  328,  261, 1455,  297, 1333,  431,  327,   46,\n",
       "           931,  309,  282,  397,  265,  483,  584,   44, 2456,  626,  677,  285,\n",
       "          1341,  673,  268,  117,  417,   46,  316,  426,  265,  261,  268,  117,\n",
       "           417,  962,  266,  660,  673, 2489,  268,  117,  417,   46, 1139,   44,\n",
       "          2456,  626,  282, 1367,  265,  483,  737,  266,  325,  601,  261,  988,\n",
       "           327,   46,  710, 2456,  626,  636,  992,  933,  886,   46,   -1,   -1,\n",
       "            -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
       "            -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
       "            -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
       "            -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
       "            -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
       "            -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
       "            -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
       "            -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
       "            -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
       "            -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
       "            -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
       "            -1,   -1,   -1,   -1,   -1,   -1,   -1]]),\n",
       " 'labels': tensor([[ 327,   44,  258,  390,  479,  402,  406,  507,  258,  775,  302,  313,\n",
       "           338,  720,   46,  342,  677,  309,  282, 2876,  265,  325,  328,  309,\n",
       "           708,  309,  282, 2073,   46,  406,  407,  265,  850,  261,  775,  302,\n",
       "           328,  338,  386,   44,  391,  392,  468,  459,  119,  258, 1674,  354,\n",
       "           338, 2377,  304,   10,  670,  426,  265,  338,  386,  266,  323,   44,\n",
       "           317,  844,   44,  337,  507,  733,  775,  302,   46, 1127,  349,  850,\n",
       "           309,  328,  524,  266,  459,  119,  627, 2377,  476,  937,  386,  565,\n",
       "           266,  323,   44,  317,  732,   44,  406,   44,  363,  469,  850,  261,\n",
       "           775,  302,  266, 1125,  629, 2377,  505,   10, 2826,   44,  360, 1208,\n",
       "           261,  775,  302,  266,  459,  119,  263,  261, 1674,  354,  406,  384,\n",
       "          2377,   46,  421,  282,  364, 2876,  387,  493,  708,  360,  405, 1714,\n",
       "           266, 1398,  766,  558,   46, 1559,  360, 1699,   44,  406,  943,  338,\n",
       "           386,  387, 1714,  261,  775,  302,  266, 1125,  297,  338, 2377,   46,\n",
       "           312,  722,  536,  377,  708,  360,  365, 1208,  266, 1228,  458,   46,\n",
       "           763,  438,  258,  397,   44,  401,  282,  258,  390,  528,  402, 2456,\n",
       "           626,   46, 2456,  626,  508,  265,  483,  737,  266,  325,  313,  261,\n",
       "           631,   46, 2456,  626,  282,  258, 2489,  528,  708,  285,  704,  365,\n",
       "           561,  268,  117,  417,   46, 1213,  462,  268,  117,  417,  586, 2456,\n",
       "           626,  377,  266,  973,  304,   10,  516,  327,   44, 2456,  626,  282,\n",
       "          1402,  817,  313,  261,  527,  634,  285,  382,  258,  346,  501,   46,\n",
       "           284,  501,  365,  664, 1333,  383,  405, 1455,  297,   46, 2456,  626,\n",
       "           532,  756,  261, 1333, 1455,  266,  407,  265,  325,  328,  493,   46,\n",
       "          2456,  626, 2241,  776,  261,  501,  266, 1233,  261, 1333, 1455,  354,\n",
       "           475,   46,  316,  703,  266,  322,  626,  263,  340, 2771,  304,   10,\n",
       "          2120,  626,  477,  328,  261, 1455,  297, 1333,  431,  327,   46,  931,\n",
       "           309,  282,  397,  265,  483,  584,   44, 2456,  626,  677,  285, 1341,\n",
       "           673,  268,  117,  417,   46,  316,  426,  265,  261,  268,  117,  417,\n",
       "           962,  266,  660,  673, 2489,  268,  117,  417,   46, 1139,   44, 2456,\n",
       "           626,  282, 1367,  265,  483,  737,  266,  325,  601,  261,  988,  327,\n",
       "            46,  710, 2456,  626,  636,  992,  933,  886,   46,   -1,   -1,   -1,\n",
       "            -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
       "            -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
       "            -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
       "            -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
       "            -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
       "            -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
       "            -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
       "            -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
       "            -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
       "            -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
       "            -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
       "            -1,   -1,   -1,   -1,   -1,   -1,   -1]]),\n",
       " 'cu_seqlens': [tensor([  0, 169, 358, 500], dtype=torch.int32)],\n",
       " 'max_seqlen': [189]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_batches = next(iter(CausalSequencePacker(**d)))\n",
    "out_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09aec692",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bad50e3",
   "metadata": {},
   "source": [
    "### FlashCausalAttention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55093be6",
   "metadata": {},
   "source": [
    "Here's the `MultiHeadAttention` with Flash Attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c0443f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlashCausalAttentionBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Attention block implementing multi-head causal (masked) attention using\n",
    "    Flash Attention.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_dim: int,\n",
    "        num_heads: int,\n",
    "        dropout: float = 0.0,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the causal attention block with Flash Attention implementation.\n",
    "\n",
    "        Args:\n",
    "            hidden_dim: Dimension of the input and output features\n",
    "            num_heads: Number of attention heads\n",
    "            dropout: Output dropout probability (0.0 means no dropout)\n",
    "\n",
    "        Note:\n",
    "            - Make sure to check that hidden_dim is divisible by num_heads\n",
    "            - Check if Flash Attention is available (FLASH_ATTN_AVAILABLE)\n",
    "            - You'll need to create linear (projection) layers for query, key, and value\n",
    "            - Don't forget the output linear (projection) layer\n",
    "            - Create an output dropout layer\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        if hidden_dim % num_heads != 0: raise Exception(\"hidden_dim not divisible by num_heads\")\n",
    "        self.head_dim = hidden_dim // num_heads\n",
    "        self.num_heads = num_heads\n",
    "        self.Wq, self.Wk, self.Wv = nn.Linear(hidden_dim, hidden_dim), nn.Linear(hidden_dim, hidden_dim), nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.Wo = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x: Tensor, cu_seqlens: Tensor, max_seqlen: int) -> Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "\n",
    "        Args:\n",
    "            x: Input tensor of shape [total_seq_len, hidden_dim].\n",
    "            cu_seqlens: Cumulative sequence lengths tensor of shape [batch_size + 1]\n",
    "                    Used instead of an attention mask for both masking and\n",
    "                    variable-length sequences. Example:\n",
    "                        cu_seqlens = torch.tensor([0, 10, 30, 60])\n",
    "                    This means there are three sequences in the batch:\n",
    "                        - First sequence has 10 tokens\n",
    "                        - Second sequence has 20 tokens\n",
    "                        - Third sequence has 30 tokens\n",
    "            max_seqlen: Maximum sequence length in the batch. In the example above,\n",
    "                        the maximum sequence length is 30.\n",
    "\n",
    "        Returns:\n",
    "            Tensor of shape [total_seq_len, hidden_dim] after attention.\n",
    "        \"\"\"\n",
    "        if not FLASH_ATTN_AVAILABLE:\n",
    "            raise ImportError(\"Flash Attention is not available. Please install it with `pip install flash-attn`\")\n",
    "        \n",
    "        total_seq_len, hidden_dim = x.shape\n",
    "        q,k,v = self.Wq(x), self.Wk(x), self.Wv(x) # [batch_size, seq_len, d_out]\n",
    "\n",
    "        k_reshaped = k.view(total_seq_len, self.num_heads, self.head_dim)\n",
    "        q_reshaped = q.view(total_seq_len, self.num_heads, self.head_dim)\n",
    "        v_reshaped = v.view(total_seq_len, self.num_heads, self.head_dim)\n",
    "        \n",
    "        # Call Flash Attention\n",
    "        output = flash_attn_varlen_func(\n",
    "            q_reshaped,\n",
    "            k_reshaped,\n",
    "            v_reshaped,\n",
    "            cu_seqlens_q=cu_seqlens,\n",
    "            cu_seqlens_k=cu_seqlens,\n",
    "            max_seqlen_q=max_seqlen,\n",
    "            max_seqlen_k=max_seqlen,\n",
    "            causal=True\n",
    "        )\n",
    "\n",
    "        return self.dropout(self.Wo(output.reshape(total_seq_len, hidden_dim)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a2119c",
   "metadata": {},
   "source": [
    "### FeedForward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbab0dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, act=nn.ReLU()):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(in_dim, hidden_dim, bias=False)\n",
    "        self.act = act\n",
    "        self.l2 = nn.Linear(hidden_dim, in_dim, bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.l2(self.act(self.l1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0f91a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLU(nn.Module):\n",
    "    \"\"\"\n",
    "    The Gated Linear Unit has two parallel linear transforms: one for the gate and one for the value.\n",
    "    Apply the activation only to the gate, then multiply elementwise with the value, followed by a\n",
    "    final linear projection and optional dropout.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_dim: int,\n",
    "        intermediate_dim: int,\n",
    "        act: nn.Module = nn.GELU,\n",
    "        dropout: float = 0.0,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize a GLU.\n",
    "\n",
    "        Args:\n",
    "            hidden_dim: Dimension of the input and output features\n",
    "            intermediate_dim: Dimension of each intermediate branch\n",
    "                              Often set to 2/3 * 4 * hidden_dim to maintain similar parameter\n",
    "                              count to a standard MLP with 4x expansion\n",
    "            activation: Activation function to use, defaults to GELU\n",
    "            dropout: Output dropout probability (0.0 means no dropout)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.Wv = nn.Linear(hidden_dim, intermediate_dim)\n",
    "        self.Wg = nn.Linear(hidden_dim, intermediate_dim)\n",
    "        self.act = act\n",
    "        self.Wo = nn.Linear(intermediate_dim, hidden_dim)\n",
    "        self.do = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "\n",
    "        Args:\n",
    "            x: Input tensor of shape [batch_size, seq_len, hidden_dim] or [total_seq_len, hidden_dim]\n",
    "\n",
    "        Returns:\n",
    "            Tensor of shape [batch_size, seq_len, hidden_dim] or [total_seq_len, hidden_dim]\n",
    "        \"\"\"\n",
    "        gate = self.act(self.Wg(x))\n",
    "        val = self.Wv(x)\n",
    "        out = self.Wo(gate * val)\n",
    "        return self.do(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36280c0f",
   "metadata": {},
   "source": [
    "### Transformer Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd61c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, emb_dim, ctx_len, n_head, drop_out=0, ff_mult=4, qkv_bias=False, act=nn.ReLU()):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(emb_dim)\n",
    "        self.ln2 = nn.LayerNorm(emb_dim)\n",
    "        self.ln3 = nn.LayerNorm(emb_dim)\n",
    "        self.ln4 = nn.LayerNorm(emb_dim)\n",
    "        self.mha = SDPACausalAttentionBlock(hidden_dim=emb_dim, num_heads=n_head, dropout=drop_out)\n",
    "        self.ff = GLU(emb_dim, int(emb_dim*ff_mult), act=act)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        skip1 = x\n",
    "        x = self.ln1(x)\n",
    "        x = self.mha(x)\n",
    "        x = self.ln2(x)\n",
    "        x = x + skip1\n",
    "        \n",
    "        skip2 = x\n",
    "        x = self.ln3(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.ln4(x)\n",
    "        x = x + skip2\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d382d7ae",
   "metadata": {},
   "source": [
    "### GPT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cf425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(cfg['vocab_sz'], cfg['emb_dim'])\n",
    "        self.pos_emb = nn.Embedding(cfg['vocab_sz'], cfg['emb_dim'])\n",
    "        self.do = nn.Dropout(cfg['drop_out'])\n",
    "        self.tb = nn.Sequential(\n",
    "            *[TransformerBlock(cfg['emb_dim'], cfg['ctx_len'], cfg['n_head'], cfg['drop_out_tb'],\n",
    "                              cfg['ff_mult'], cfg['qkv_bias'], cfg['act']) for _ in range(cfg['n_tb'])])\n",
    "        self.final_ln = nn.LayerNorm(cfg['emb_dim'])\n",
    "        self.final_l  = nn.Linear(cfg['emb_dim'], cfg['vocab_sz'])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        bs, seq_len = x.shape\n",
    "        tok = self.token_emb(x)\n",
    "        pos = self.pos_emb(torch.arange(seq_len, device=x.device))\n",
    "        x = self.do(tok + pos)\n",
    "        x = self.tb(x)\n",
    "        x = self.final_ln(x)\n",
    "        x = self.final_l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2225f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_params(model): return sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5c38f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_memory(model):\n",
    "    total_params = get_total_params(model)\n",
    "    total_size_bytes = total_params * 4   # Assuming fp32\n",
    "    # Convert to megabytes\n",
    "    total_size_mb = total_size_bytes / (1024 * 1024)\n",
    "    print(f\"Total params: {total_params:,}\")\n",
    "    print(f\"Total size: {total_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f022896",
   "metadata": {},
   "source": [
    "### Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc54096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx is (batch, n_tokens) array of indices in the current context\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]  # Crop current context if it exceeds the supported context size\n",
    "        with torch.no_grad(): logits = model(idx_cond)         # (bs, n_tokens, vocab_sz)\n",
    "        logits = logits[:, -1, :]                              # (bs, vocab_sz)\n",
    "        probas = torch.softmax(logits, dim=-1)                 # (bs, vocab_sz)\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (bs, 1)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)                # (bs, n_tokens+1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511281b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880ff652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4c8521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:].to(def_device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4747a7b",
   "metadata": {},
   "source": [
    "## Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bca503",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torcheval.metrics import  MulticlassAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d440d568",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixedPrecision(TrainCB):\n",
    "    order = DeviceCB.order+10\n",
    "    def __init__(self, n_inp=1, dtype=torch.bfloat16):\n",
    "        super().__init__(n_inp=n_inp)\n",
    "        self.dtype=dtype\n",
    "    \n",
    "    def before_fit(self, learn): self.scaler = torch.amp.GradScaler('cuda')\n",
    "\n",
    "    def before_batch(self, learn):\n",
    "        self.autocast = torch.autocast(\"cuda\", dtype=self.dtype)\n",
    "        self.autocast.__enter__()\n",
    "\n",
    "    def after_loss(self, learn): self.autocast.__exit__(None, None, None)\n",
    "        \n",
    "    def backward(self, learn): self.scaler.scale(learn.loss).backward()\n",
    "\n",
    "    def step(self, learn):\n",
    "        self.scaler.step(learn.opt)\n",
    "        self.scaler.update()\n",
    "\n",
    "class AccelerateCB(TrainCB):\n",
    "    order = DeviceCB.order+10\n",
    "    def __init__(self, n_inp=1, mixed_precision=\"fp16\"):\n",
    "        super().__init__(n_inp=n_inp)\n",
    "        self.acc = Accelerator(mixed_precision=mixed_precision)\n",
    "        \n",
    "    def before_fit(self, learn):\n",
    "        learn.model,learn.opt,learn.dls.train,learn.dls.valid = self.acc.prepare(\n",
    "            learn.model, learn.opt, learn.dls.train, learn.dls.valid)\n",
    "    \n",
    "    def after_fit(self, learn): learn.model = self.acc.unwrap_model(learn.model)\n",
    "    def backward(self, learn): self.acc.backward(learn.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ba3aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(pred, targ): return F.cross_entropy(pred.flatten(0, 1), targ.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a6ef94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "768 // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83922cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'n_tb': 12,    # num transformer blocks\n",
    "    'vocab_sz': 3008,\n",
    "    'emb_dim': 384,\n",
    "    'ctx_len': ctx_len,\n",
    "    'n_head': 12,\n",
    "    'drop_out': 0,\n",
    "    'drop_out_tb': 0,  # dropout within transformer blocks\n",
    "    'ff_mult': 2/3 * 4,\n",
    "    'qkv_bias': False,\n",
    "    'act': nn.GELU(),   # activation function\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72d6941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 24,787,136\n",
      "Total size: 94.56 MB\n"
     ]
    }
   ],
   "source": [
    "model = torch.compile(GPTModel(cfg).to(def_device), mode=\"reduce-overhead\")\n",
    "get_total_memory(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d44a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMMetricsCB(MetricsCB):\n",
    "    def __init__(self, *ms, **metrics):\n",
    "        super().__init__(*ms, **metrics)\n",
    "    \n",
    "    def after_batch(self, learn):\n",
    "        x,y,*_ = learn.batch\n",
    "        for m in self.metrics.values(): m.update(learn.preds.flatten(0, 1), y.flatten())\n",
    "        self.loss.update(to_cpu(learn.loss), weight=len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd56e4c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/10 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "      <progress value='41' class='' max='30647' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.13% [41/30647 00:29&lt;6:07:18 13.372]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "opt = torch.optim.AdamW\n",
    "cbs = [LLMMetricsCB(accuracy=MulticlassAccuracy()), ProgressCB(), DeviceCB(), MixedPrecision()]\n",
    "learn = Learner(model, dls, loss_func=loss_fn, cbs=cbs, opt_func=opt)\n",
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8295f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1f47ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, epochs = 1e-4, 2\n",
    "tmax = epochs * len(dls.train)\n",
    "sched = partial(lr_scheduler.OneCycleLR, max_lr=lr, total_steps=tmax)\n",
    "xtra = [BatchSchedCB(sched)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b11ddac",
   "metadata": {},
   "source": [
    "GLU for ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639085e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0.436</td>\n",
       "      <td>2.730</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>1:02:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.568</td>\n",
       "      <td>1.761</td>\n",
       "      <td>0</td>\n",
       "      <td>eval</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.596</td>\n",
       "      <td>1.605</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>1:06:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.599</td>\n",
       "      <td>1.592</td>\n",
       "      <td>1</td>\n",
       "      <td>eval</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seed(42)\n",
    "model = torch.compile(GPTModel(cfg).to(def_device), mode=\"reduce-overhead\")\n",
    "cbs = [LLMMetricsCB(accuracy=MulticlassAccuracy()), ProgressCB(plot=True), DeviceCB(), MixedPrecision()]\n",
    "learn = Learner(model, dls, loss_func=loss_fn, cbs=cbs+xtra, opt_func=opt)\n",
    "learn.fit(epochs, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0cf04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Once upon a time, there lived a bunny in a field. Her name was Lucy. Lucy loved to have feasts and parties with her bunny friends. One day, when Lucy was about to leave for a feast at a friend's house, she realized she's starting to feel sick. She was so weak she could not run or get enough food, so she couldn't even call for help!\n",
      "\n",
      "Lucy was so sad she didn't feel like when it was getting late. She regretted not getting to see the festival. Eventually, it was time to go to the festival. Lucy was sad that she had to leave.\n",
      "\n",
      "Then, Lucy had an idea. She decided to take a special nap under her favourite dress and put it in her dresser. After that, when she saw the festival, she realized that she had been weak for a moment. But, it made her feel better. She was relieved to see that all the way to the festival had paid off, but she learned that it must be okay to have an even worthier way. \n",
      "\n",
      "Lucy was happy and excited to have re\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Once upon a time, there lived a bunny in a field. Her name was Lucy. Lucy loved to have feasts and parties with her bunny friends. One day, when Lucy was about to leave for a feast at a friend's house, she realized she's starting to feel sick. She was so weak she could\"\n",
    "model.eval()\n",
    "token_ids = generate(\n",
    "    model=model.eval(),\n",
    "    idx=text_to_token_ids(\"Once upon a time, there lived a bunny in a field. Her name was Lucy. Lucy loved to have feasts and parties with her bunny friends. One day, when Lucy was about to leave for a feast at a friend's house, she realized she's starting to feel sick. She was so weak she could\", tokenizer).to(def_device),\n",
    "    max_new_tokens=180,\n",
    "    context_size=cfg[\"ctx_len\"],\n",
    "    top_k=25,\n",
    "    temperature=1.1\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f52dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97909f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Once upon a time, there lived a bunny in a fie...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Once upon a time, there lived a bunny in a fie...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Once upon a time, there lived a bunny in a fie...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Once upon a time, there lived a bunny in a fie...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Once upon a time, there lived a bunny in a fie...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  completion\n",
       "0  Once upon a time, there lived a bunny in a fie...         NaN\n",
       "1  Once upon a time, there lived a bunny in a fie...         NaN\n",
       "2  Once upon a time, there lived a bunny in a fie...         NaN\n",
       "3  Once upon a time, there lived a bunny in a fie...         NaN\n",
       "4  Once upon a time, there lived a bunny in a fie...         NaN"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('evaluation_prompts.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd516a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(row, model, tokenizer, max_tokens=180, context_size=cfg[\"ctx_len\"], \n",
    "                top_k=25, temperature=1.3):\n",
    "    # Tokenize the prompt\n",
    "    toks = text_to_token_ids(row['prompt'], tokenizer)\n",
    "    \n",
    "    # Generate completion\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=toks.to(def_device),\n",
    "        max_new_tokens=max_tokens,\n",
    "        context_size=context_size,\n",
    "        top_k=top_k,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    \n",
    "    # Extract only the generated part (not the original prompt)\n",
    "    completion = token_ids_to_text(token_ids[:, toks.shape[1]:], tokenizer)\n",
    "    \n",
    "    return completion\n",
    "\n",
    "# Apply the function to each row in the dataframe\n",
    "df['completion'] = df.apply(lambda row: process_row(row, model, tokenizer), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b414bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Once upon a time, there lived a bunny in a fie...</td>\n",
       "      <td>not move.\\n\\nLucy saw that Lucy was tired and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Once upon a time, there lived a bunny in a fie...</td>\n",
       "      <td>not breathe.\\n\\nLuckily, Lucy heard a loud ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Once upon a time, there lived a bunny in a fie...</td>\n",
       "      <td>not find her way back home. Lucy's mommy was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Once upon a time, there lived a bunny in a fie...</td>\n",
       "      <td>barely breathe again!\\n\\nLucy knew her friend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Once upon a time, there lived a bunny in a fie...</td>\n",
       "      <td>hard out.\\n\\nAt home, Lucy's mom gave her a w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  Once upon a time, there lived a bunny in a fie...   \n",
       "1  Once upon a time, there lived a bunny in a fie...   \n",
       "2  Once upon a time, there lived a bunny in a fie...   \n",
       "3  Once upon a time, there lived a bunny in a fie...   \n",
       "4  Once upon a time, there lived a bunny in a fie...   \n",
       "\n",
       "                                          completion  \n",
       "0   not move.\\n\\nLucy saw that Lucy was tired and...  \n",
       "1   not breathe.\\n\\nLuckily, Lucy heard a loud ye...  \n",
       "2   not find her way back home. Lucy's mommy was ...  \n",
       "3   barely breathe again!\\n\\nLucy knew her friend...  \n",
       "4   hard out.\\n\\nAt home, Lucy's mom gave her a w...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c81171",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"0401_init.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12510bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Once upon a time, there lived a bunny in a fie...</td>\n",
       "      <td>not move.\\n\\nLucy saw that Lucy was tired and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Once upon a time, there lived a bunny in a fie...</td>\n",
       "      <td>not breathe.\\n\\nLuckily, Lucy heard a loud ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Once upon a time, there lived a bunny in a fie...</td>\n",
       "      <td>not find her way back home. Lucy's mommy was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Once upon a time, there lived a bunny in a fie...</td>\n",
       "      <td>barely breathe again!\\n\\nLucy knew her friend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Once upon a time, there lived a bunny in a fie...</td>\n",
       "      <td>hard out.\\n\\nAt home, Lucy's mom gave her a w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  Once upon a time, there lived a bunny in a fie...   \n",
       "1  Once upon a time, there lived a bunny in a fie...   \n",
       "2  Once upon a time, there lived a bunny in a fie...   \n",
       "3  Once upon a time, there lived a bunny in a fie...   \n",
       "4  Once upon a time, there lived a bunny in a fie...   \n",
       "\n",
       "                                          completion  \n",
       "0   not move.\\n\\nLucy saw that Lucy was tired and...  \n",
       "1   not breathe.\\n\\nLuckily, Lucy heard a loud ye...  \n",
       "2   not find her way back home. Lucy's mommy was ...  \n",
       "3   barely breathe again!\\n\\nLucy knew her friend...  \n",
       "4   hard out.\\n\\nAt home, Lucy's mom gave her a w...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"0401_init.csv\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d027adbf",
   "metadata": {},
   "source": [
    "Hyperparameters: Learning rate, optimizer: Gradient clipping, batch size: 4k\n",
    "\n",
    "Mixed precision -> weight decay needed. (bfloat16)\n",
    "\n",
    "Distributed data parallel: Split data into 2 and use graident accumulation\n",
    "\n",
    "Fully Sharded data parallel: shard of data into GPUs as layer goes.\n",
    "\n",
    "CPU offload\n",
    "\n",
    "DataLoader: Use for loop.\n",
    "\n",
    "!!!!! Look at the data. !!!!!\n",
    "\n",
    "Eval: next token accuracy, loss\n",
    "\n",
    "Try GLU instead of ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87eff7e9",
   "metadata": {},
   "source": [
    "Tips: \n",
    "\n",
    "1. Try simple model.\n",
    "2. Weight Tying.\n",
    "3. Hyperparameter sweep\n",
    "4. minbpe\n",
    "\n",
    "\n",
    "Get sequencing packing to work -> iterate faster\n",
    "flash attention."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8019726f",
   "metadata": {},
   "source": [
    "Use triton cross entropy loss or compile nn.crosstropyloss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c27a80a",
   "metadata": {},
   "source": [
    "Add view(-1,...) before flash attention and remove view(-1,...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e289471c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682eba64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
