{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68bbf607",
   "metadata": {},
   "source": [
    "Improvement: Using sequence packing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb8bde8",
   "metadata": {},
   "source": [
    "# Tiny Stories Hackathon\n",
    "> From Cluster of stars study group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d371da66",
   "metadata": {},
   "source": [
    "## TinyStories Hackathon Rules\n",
    "This hackathon is intended to be a fun competition to give ourselves practice pretraining LLMs on consumer hardware. We will follow the [TinyStories paper](<https://arxiv.org/abs/2305.07759>) and train small language models on small datasets and hardware.\n",
    "\n",
    "The hackathon will end on April 7th, [AOE](<https://en.wikipedia.org/wiki/AoE>)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c70b6a",
   "metadata": {},
   "source": [
    "### Datasets\n",
    "1. [**TinyStories:**](<https://huggingface.co/datasets/roneneldan/TinyStories>)\n",
    "   Note that the TinyStories dataset is split into two versions both in the HF dataset:\n",
    "     - GPT-3.5 generated TinyStories\n",
    "    - GPT-4 generated TinyStories\n",
    "   The tar file appears to have the cleanest versions with the least number of duplicates.\n",
    "2. **[Simple Wikipedia](<https://huggingface.co/datasets/lsb/simplewiki2023>)** (optional)\n",
    "   This dataset can be used to give your model more world knowledge than from just the TinyStories dataset. But be careful that \n",
    "it doesn't cause your model to use words which a typical 3 to 4-year-olds doesn't understand. It may need to be cleaned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1528f9",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "Models will be evaluated by LLM-as-a-judge following the methodology outlined in the TinyStories paper. More details including how to submit your model's outputs early next week."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a15400",
   "metadata": {},
   "source": [
    "### Model Size Limits\n",
    "Participants will be slotted into one of the following categories based on their hardware:\n",
    "- **Small**: Up to 30M parameters. Low-to-mid range laptop GPUs and Apple Silicon.\n",
    "- **Medium**: Up to 60M parameters. Mid-range GPUs (including high-end laptop GPUs and Apple Silicon)\n",
    "- **Large**: Up to 120M parameters. High-end GPUs and multi-GPU systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2e1a81",
   "metadata": {},
   "source": [
    "### Tokenizers\n",
    "While you must train your model from scratch, you are welcome to use any pre-trained tokenizer or train your own tokenizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7dbdaa",
   "metadata": {},
   "source": [
    "### Model Architecture\n",
    "You are welcome to use any model architecture you want provided you stay within the parameter budget of your hardware by following the parameter counting rules below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cadc72b",
   "metadata": {},
   "source": [
    "### Parameter Counting\n",
    "The Parameter budget is the number of unique floating-point weights receiving gradient updates:\n",
    "- Unique Weights: Count each distinct floating-point weight stored in the model once.\n",
    "- Reuse Multiplier: For each weight, multiply by the number of distinct times it contributes to forward computation (e.g., due to layer-sharing, layer reuse, or non-standard head-sharing). Weight-tied embedding and decoder weights are the exception and are only counted once. MQA/GQA doesn't count as head-sharing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ec912d",
   "metadata": {},
   "source": [
    "### Teams\n",
    "Teams are limited to a maximum of 2 members and must be formed and declared within the first week."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385b91a3",
   "metadata": {},
   "source": [
    "### Training Frameworks\n",
    "You might want to take a look at the following libraries and frameworks and adopt one for pretraining:\n",
    "- [Composer](<https://docs.mosaicml.com/projects/composer/en/stable/index.html>) and optionally [LLM Foundry](<https://github.com/mosaicml/llm-foundry>)\n",
    "- [PyTorch Lightning](<https://lightning.ai/docs/pytorch/stable/>) and optionally [LitGPT](<https://github.com/Lightning-AI/litgpt>)\n",
    "- Hugging Face [Trainer](<https://huggingface.co/docs/transformers/en/main_classes/trainer>), [Accelerate](<https://huggingface.co/docs/accelerate/en/index>), and optionally [Axolotl](<https://axolotl-ai-cloud.github.io/axolotl/>) (a wrapper on top of HF)\n",
    "- [fastai](<https://docs.fast.ai/>) with either [fastxtend](<https://fastxtend.benjaminwarner.dev/text.huggingface.html>)/[blurr](<https://ohmeow.github.io/blurr/>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc82c861",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc14c85",
   "metadata": {},
   "source": [
    "### Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e940d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import tiktoken\n",
    "import torch\n",
    "\n",
    "from minai import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3fecab",
   "metadata": {},
   "source": [
    "## Sequence packing\n",
    "\n",
    "Going through https://huggingface.co/blog/sirluk/llm-sequence-packing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a517a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bd9673300b449d19ef98d6d90e8e330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e6b96278c604037afa4a8858e556845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "446e02720c584c1aa8e60c11388a3ec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec6833d7715a42668e49dcae3cac4f9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d3e0efa0d3d45caadcd02f6620a27f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setup\n",
    "import torch; torch.set_printoptions(linewidth=200)\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "config = AutoConfig.from_pretrained(\"gpt2\")\n",
    "model = AutoModelForCausalLM.from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab571f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[464, 3797, 3332, 319, 262, 2603],\n",
       " [464, 3290, 15063, 616, 26131],\n",
       " [3666, 25949, 318, 257, 4701]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence1 = \"The cat sat on the mat\"\n",
    "sentence2 = \"The dog ate my homework\"\n",
    "sentence3 = \"My aunt is a teacher\"\n",
    "\n",
    "sentences = [sentence1, sentence2, sentence3]\n",
    "tokenized_sentences = tokenizer(sentences, return_attention_mask=False, add_special_tokens=False)[\"input_ids\"]\n",
    "tokenized_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd6f817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50256"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c10a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[464,\n",
       " 3797,\n",
       " 3332,\n",
       " 319,\n",
       " 262,\n",
       " 2603,\n",
       " 50256,\n",
       " 464,\n",
       " 3290,\n",
       " 15063,\n",
       " 616,\n",
       " 26131,\n",
       " 50256,\n",
       " 3666,\n",
       " 25949,\n",
       " 318,\n",
       " 257,\n",
       " 4701,\n",
       " 50256]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sentences = [t for s in tokenized_sentences for t in s + [tokenizer.eos_token_id]]\n",
    "tokenized_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b57a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The cat sat on the mat<|endoftext|>The dog ate my homework<|endoftext|>My aunt is a teacher<|endoftext|>'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a24acf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=torch.int32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sentences = torch.tensor(tokenized_sentences)\n",
    "attn_mask = torch.ones(tokenized_sentences.size(0), tokenized_sentences.size(0), dtype=torch.int).tril()\n",
    "attn_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438e01ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = tokenized_sentences.size(0)\n",
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d9ea8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 12, 18])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get indices of all EOS tokens\n",
    "eos_indices = (tokenized_sentences == tokenizer.eos_token_id).nonzero().squeeze()\n",
    "eos_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fec834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12, 18])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eos_indices[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6bfe8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 12])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eos_indices[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557b33f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eos_indices[[0]]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51a0d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 6, 6])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from indices, get length of each sequence\n",
    "reps = torch.cat([eos_indices[[0]]+1, eos_indices[1:] - eos_indices[:-1]])\n",
    "reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb28d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6,  6,  6,  6,  6,  6,  6, 12, 12, 12, 12, 12, 12, 18, 18, 18, 18, 18, 18])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.repeat_interleave(eos_indices, reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470dbc0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6,  6,  6,  6,  6,  6,  6, 12, 12, 12, 12, 12, 12, 18, 18, 18, 18, 18, 18]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.repeat_interleave(eos_indices, reps).view(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12341dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6,  6,  6,  6,  6,  6,  6, 12, 12, 12, 12, 12, 12, 18, 18, 18, 18, 18, 18],\n",
       "        [ 6,  6,  6,  6,  6,  6,  6, 12, 12, 12, 12, 12, 12, 18, 18, 18, 18, 18, 18],\n",
       "        [ 6,  6,  6,  6,  6,  6,  6, 12, 12, 12, 12, 12, 12, 18, 18, 18, 18, 18, 18],\n",
       "        [ 6,  6,  6,  6,  6,  6,  6, 12, 12, 12, 12, 12, 12, 18, 18, 18, 18, 18, 18],\n",
       "        [ 6,  6,  6,  6,  6,  6,  6, 12, 12, 12, 12, 12, 12, 18, 18, 18, 18, 18, 18],\n",
       "        [ 6,  6,  6,  6,  6,  6,  6, 12, 12, 12, 12, 12, 12, 18, 18, 18, 18, 18, 18],\n",
       "        [ 6,  6,  6,  6,  6,  6,  6, 12, 12, 12, 12, 12, 12, 18, 18, 18, 18, 18, 18],\n",
       "        [ 6,  6,  6,  6,  6,  6,  6, 12, 12, 12, 12, 12, 12, 18, 18, 18, 18, 18, 18],\n",
       "        [ 6,  6,  6,  6,  6,  6,  6, 12, 12, 12, 12, 12, 12, 18, 18, 18, 18, 18, 18],\n",
       "        [ 6,  6,  6,  6,  6,  6,  6, 12, 12, 12, 12, 12, 12, 18, 18, 18, 18, 18, 18],\n",
       "        [ 6,  6,  6,  6,  6,  6,  6, 12, 12, 12, 12, 12, 12, 18, 18, 18, 18, 18, 18],\n",
       "        [ 6,  6,  6,  6,  6,  6,  6, 12, 12, 12, 12, 12, 12, 18, 18, 18, 18, 18, 18],\n",
       "        [ 6,  6,  6,  6,  6,  6,  6, 12, 12, 12, 12, 12, 12, 18, 18, 18, 18, 18, 18],\n",
       "        [ 6,  6,  6,  6,  6,  6,  6, 12, 12, 12, 12, 12, 12, 18, 18, 18, 18, 18, 18],\n",
       "        [ 6,  6,  6,  6,  6,  6,  6, 12, 12, 12, 12, 12, 12, 18, 18, 18, 18, 18, 18],\n",
       "        [ 6,  6,  6,  6,  6,  6,  6, 12, 12, 12, 12, 12, 12, 18, 18, 18, 18, 18, 18],\n",
       "        [ 6,  6,  6,  6,  6,  6,  6, 12, 12, 12, 12, 12, 12, 18, 18, 18, 18, 18, 18],\n",
       "        [ 6,  6,  6,  6,  6,  6,  6, 12, 12, 12, 12, 12, 12, 18, 18, 18, 18, 18, 18],\n",
       "        [ 6,  6,  6,  6,  6,  6,  6, 12, 12, 12, 12, 12, 12, 18, 18, 18, 18, 18, 18]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# repeat each eos index n times along dimension 1 (n is the number of tokens in the sequence)\n",
    "repeated_idx = torch.repeat_interleave(eos_indices, reps).view(1,-1).expand(T, -1)\n",
    "repeated_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e192f7b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "        [ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2],\n",
       "        [ 3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3],\n",
       "        [ 4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4],\n",
       "        [ 5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5],\n",
       "        [ 6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6],\n",
       "        [ 7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7],\n",
       "        [ 8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8],\n",
       "        [ 9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9],\n",
       "        [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
       "        [11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11],\n",
       "        [12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12],\n",
       "        [13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13],\n",
       "        [14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14],\n",
       "        [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15],\n",
       "        [16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16],\n",
       "        [17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "        [18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create tensor with all indices from 0 to T-1 repeated T times along dimesion 1\n",
    "mask_indices = torch.arange(T).view(-1,1).expand(-1, T)\n",
    "mask_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a7190e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create causal mask and additionally mask out all tokens from preceeding sequences\n",
    "mask = torch.ones(T, T).tril().expand(-1, -1)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94555c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mask_indices > repeated_idx).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e065aa72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.masked_fill_(mask_indices > repeated_idx, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d736afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False],\n",
       "        [ True,  True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False],\n",
       "        [ True,  True,  True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False],\n",
       "        [ True,  True,  True,  True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False],\n",
       "        [ True,  True,  True,  True,  True, False, False, False, False, False, False, False, False, False, False, False, False, False, False],\n",
       "        [ True,  True,  True,  True,  True,  True, False, False, False, False, False, False, False, False, False, False, False, False, False],\n",
       "        [ True,  True,  True,  True,  True,  True,  True, False, False, False, False, False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False,  True, False, False, False, False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False,  True,  True, False, False, False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False,  True,  True,  True, False, False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False,  True,  True,  True,  True, False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False,  True,  True,  True,  True,  True, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False,  True,  True,  True,  True,  True,  True, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False, False, False, False,  True, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False, False, False, False,  True,  True, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False, False, False, False,  True,  True,  True, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False, False, False, False,  True,  True,  True,  True, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False, False, False, False,  True,  True,  True,  True,  True, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False, False, False, False,  True,  True,  True,  True,  True,  True]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_attention_mask_for_packed_sequence(x, token_id, eos: bool = True):\n",
    "    # store sequence length in variable for easier readability\n",
    "    T = tokenized_sentences.size(0)\n",
    "    # get indices of all EOS tokens\n",
    "    eos_indices = (tokenized_sentences == tokenizer.eos_token_id).nonzero().squeeze()\n",
    "    # from indices, get length of each sequence\n",
    "    reps = torch.cat([eos_indices[[0]]+1, eos_indices[1:] - eos_indices[:-1]])\n",
    "    # repeat each eos index n times along dimension 1 (n is the number of tokens in the sequence)\n",
    "    repeated_idx = torch.repeat_interleave(eos_indices, reps).view(1,-1).expand(T, -1)\n",
    "    # create tensor with all indices from 0 to T-1 repeated T times along dimesion 1\n",
    "    mask_indices = torch.arange(T).view(-1,1).expand(-1, T)\n",
    "    # create causal mask and additionally mask out all tokens from preceeding sequences\n",
    "    mask = torch.ones(T, T, dtype=torch.bool).tril().expand(-1, -1)\n",
    "    mask.masked_fill_(mask_indices > repeated_idx, False)\n",
    "    return mask\n",
    "\n",
    "get_attention_mask_for_packed_sequence(tokenized_sentences, tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e4cf12",
   "metadata": {},
   "source": [
    "Position embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bfd2ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_ids = torch.arange(T) - torch.repeat_interleave(torch.cat([torch.tensor([0]), eos_indices+1], dim=0)[:-1], reps)\n",
    "pos_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b14d17",
   "metadata": {},
   "source": [
    "Doing it in Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbae299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  464,  3797,  3332,   319,   262,  2603, 50256,   464,  3290, 15063,   616, 26131, 50256,  3666, 25949,   318,   257,  4701, 50256],\n",
       "        [   49,   462,  2492,   470,  3170,   287,   257,  1110, 50256,  3666, 20599,  3323,   318,  1336,   286,   304,  1424, 50256, 50256]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence4 = \"Rome wasn't built in a day\"\n",
    "sentence5 = \"My hovercraft is full of eels\"\n",
    "\n",
    "sentences = [sentence4, sentence5]\n",
    "tokenized_sentences2 = tokenizer(sentences, return_attention_mask=False, add_special_tokens=False)[\"input_ids\"]\n",
    "tokenized_sentences2 = torch.tensor([t for s in tokenized_sentences2 for t in s + [tokenizer.eos_token_id]])\n",
    "\n",
    "batch = torch.nn.utils.rnn.pad_sequence(\n",
    "  [tokenized_sentences, tokenized_sentences2],\n",
    "  batch_first=True, padding_value=tokenizer.eos_token_id\n",
    ")\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423d3cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([19]), torch.Size([18]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sentences.shape, tokenized_sentences2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7c68d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.utils.rnn.pad_sequence([torch.ones(3), torch.ones(10)], padding_value=99).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224d96f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.utils.rnn.pad_sequence([torch.ones(3), torch.ones(10)], padding_value=99, batch_first=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0953a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 19)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B, T = batch.shape\n",
    "B, T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0044f590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([38])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.view(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac05307d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False,  True, False, False, False, False, False,  True, False, False, False, False, False,  True, False, False, False, False, False, False, False, False,\n",
       "         True, False, False, False, False, False, False, False, False,  True,  True])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(batch.view(-1) == tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae841d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 6, 12, 18, 27, 36, 37]),)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(batch.view(-1) == tokenizer.eos_token_id).nonzero(as_tuple=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6a1a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7, 13, 19, 28, 37, 38])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(batch.view(-1) == tokenizer.eos_token_id).nonzero().flatten() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7ee83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7, 13, 19, 28, 37, 38])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eos_idx = (batch.view(-1) == tokenizer.eos_token_id).nonzero(as_tuple=True)[0] + 1\n",
    "eos_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf543d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  7, 13, 19, 28, 37, 38])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eos_idx_expanded = torch.cat(\n",
    "  [eos_idx, torch.arange(0,B*T+1,T)]\n",
    ").unique().sort()[0]\n",
    "eos_idx_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0685292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([19,  7, 13, 19,  9, 18, 19])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_idx = eos_idx_expanded - (eos_idx_expanded // T) * T\n",
    "normalized_idx = torch.where(normalized_idx == 0, T, normalized_idx)\n",
    "normalized_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73ca8d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 6, 6, 9, 9, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reps = normalized_idx[1:] - normalized_idx[:-1]\n",
    "reps = torch.where(reps < 1, normalized_idx[1:], reps)\n",
    "reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bbb508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 7,  7,  7,  7,  7,  7,  7, 13, 13, 13, 13, 13, 13, 19, 19, 19, 19, 19, 19],\n",
       "         [ 7,  7,  7,  7,  7,  7,  7, 13, 13, 13, 13, 13, 13, 19, 19, 19, 19, 19, 19],\n",
       "         [ 7,  7,  7,  7,  7,  7,  7, 13, 13, 13, 13, 13, 13, 19, 19, 19, 19, 19, 19],\n",
       "         [ 7,  7,  7,  7,  7,  7,  7, 13, 13, 13, 13, 13, 13, 19, 19, 19, 19, 19, 19],\n",
       "         [ 7,  7,  7,  7,  7,  7,  7, 13, 13, 13, 13, 13, 13, 19, 19, 19, 19, 19, 19],\n",
       "         [ 7,  7,  7,  7,  7,  7,  7, 13, 13, 13, 13, 13, 13, 19, 19, 19, 19, 19, 19],\n",
       "         [ 7,  7,  7,  7,  7,  7,  7, 13, 13, 13, 13, 13, 13, 19, 19, 19, 19, 19, 19],\n",
       "         [ 7,  7,  7,  7,  7,  7,  7, 13, 13, 13, 13, 13, 13, 19, 19, 19, 19, 19, 19],\n",
       "         [ 7,  7,  7,  7,  7,  7,  7, 13, 13, 13, 13, 13, 13, 19, 19, 19, 19, 19, 19],\n",
       "         [ 7,  7,  7,  7,  7,  7,  7, 13, 13, 13, 13, 13, 13, 19, 19, 19, 19, 19, 19],\n",
       "         [ 7,  7,  7,  7,  7,  7,  7, 13, 13, 13, 13, 13, 13, 19, 19, 19, 19, 19, 19],\n",
       "         [ 7,  7,  7,  7,  7,  7,  7, 13, 13, 13, 13, 13, 13, 19, 19, 19, 19, 19, 19],\n",
       "         [ 7,  7,  7,  7,  7,  7,  7, 13, 13, 13, 13, 13, 13, 19, 19, 19, 19, 19, 19],\n",
       "         [ 7,  7,  7,  7,  7,  7,  7, 13, 13, 13, 13, 13, 13, 19, 19, 19, 19, 19, 19],\n",
       "         [ 7,  7,  7,  7,  7,  7,  7, 13, 13, 13, 13, 13, 13, 19, 19, 19, 19, 19, 19],\n",
       "         [ 7,  7,  7,  7,  7,  7,  7, 13, 13, 13, 13, 13, 13, 19, 19, 19, 19, 19, 19],\n",
       "         [ 7,  7,  7,  7,  7,  7,  7, 13, 13, 13, 13, 13, 13, 19, 19, 19, 19, 19, 19],\n",
       "         [ 7,  7,  7,  7,  7,  7,  7, 13, 13, 13, 13, 13, 13, 19, 19, 19, 19, 19, 19],\n",
       "         [ 7,  7,  7,  7,  7,  7,  7, 13, 13, 13, 13, 13, 13, 19, 19, 19, 19, 19, 19]],\n",
       "\n",
       "        [[ 9,  9,  9,  9,  9,  9,  9,  9,  9, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19],\n",
       "         [ 9,  9,  9,  9,  9,  9,  9,  9,  9, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19],\n",
       "         [ 9,  9,  9,  9,  9,  9,  9,  9,  9, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19],\n",
       "         [ 9,  9,  9,  9,  9,  9,  9,  9,  9, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19],\n",
       "         [ 9,  9,  9,  9,  9,  9,  9,  9,  9, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19],\n",
       "         [ 9,  9,  9,  9,  9,  9,  9,  9,  9, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19],\n",
       "         [ 9,  9,  9,  9,  9,  9,  9,  9,  9, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19],\n",
       "         [ 9,  9,  9,  9,  9,  9,  9,  9,  9, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19],\n",
       "         [ 9,  9,  9,  9,  9,  9,  9,  9,  9, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19],\n",
       "         [ 9,  9,  9,  9,  9,  9,  9,  9,  9, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19],\n",
       "         [ 9,  9,  9,  9,  9,  9,  9,  9,  9, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19],\n",
       "         [ 9,  9,  9,  9,  9,  9,  9,  9,  9, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19],\n",
       "         [ 9,  9,  9,  9,  9,  9,  9,  9,  9, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19],\n",
       "         [ 9,  9,  9,  9,  9,  9,  9,  9,  9, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19],\n",
       "         [ 9,  9,  9,  9,  9,  9,  9,  9,  9, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19],\n",
       "         [ 9,  9,  9,  9,  9,  9,  9,  9,  9, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19],\n",
       "         [ 9,  9,  9,  9,  9,  9,  9,  9,  9, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19],\n",
       "         [ 9,  9,  9,  9,  9,  9,  9,  9,  9, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19],\n",
       "         [ 9,  9,  9,  9,  9,  9,  9,  9,  9, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeated_idx = torch.repeat_interleave(\n",
    "  normalized_idx[1:], reps\n",
    ").view(B,1,T).expand(-1,T,-1)\n",
    "repeated_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147128b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False],\n",
       "         [ True,  True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True, False, False, False, False, False, False, False, False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True, False, False, False, False, False, False, False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True, False, False, False, False, False, False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False,  True, False, False, False, False, False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False,  True,  True, False, False, False, False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False,  True,  True,  True, False, False, False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False,  True,  True,  True,  True, False, False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False,  True,  True,  True,  True,  True, False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False,  True,  True,  True,  True,  True,  True, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False, False, False, False, False, False, False,  True, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False, False, False, False, False, False, False,  True,  True, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False, False, False, False, False, False, False,  True,  True,  True, False, False, False],\n",
       "         [False, False, False, False, False, False, False, False, False, False, False, False, False,  True,  True,  True,  True, False, False],\n",
       "         [False, False, False, False, False, False, False, False, False, False, False, False, False,  True,  True,  True,  True,  True, False],\n",
       "         [False, False, False, False, False, False, False, False, False, False, False, False, False,  True,  True,  True,  True,  True,  True]],\n",
       "\n",
       "        [[ True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False],\n",
       "         [ True,  True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True, False, False, False, False, False, False, False, False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True, False, False, False, False, False, False, False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True, False, False, False, False, False, False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True, False, False, False, False, False, False, False, False, False, False, False],\n",
       "         [ True,  True,  True,  True,  True,  True,  True,  True,  True, False, False, False, False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False, False, False,  True, False, False, False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False, False, False,  True,  True, False, False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False, False, False,  True,  True,  True, False, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False, False, False,  True,  True,  True,  True, False, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False, False, False,  True,  True,  True,  True,  True, False, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False, False, False,  True,  True,  True,  True,  True,  True, False, False, False, False],\n",
       "         [False, False, False, False, False, False, False, False, False,  True,  True,  True,  True,  True,  True,  True, False, False, False],\n",
       "         [False, False, False, False, False, False, False, False, False,  True,  True,  True,  True,  True,  True,  True,  True, False, False],\n",
       "         [False, False, False, False, False, False, False, False, False,  True,  True,  True,  True,  True,  True,  True,  True,  True, False],\n",
       "         [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False,  True]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_indices = torch.arange(T).view(1,-1,1).expand(B, -1, T)\n",
    "# create mask\n",
    "mask = torch.ones(T, T, dtype=torch.bool).tril().expand(B, -1, -1)\n",
    "mask = mask.masked_fill(mask_indices >= repeated_idx, False)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ccb6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]],\n",
       "\n",
       "        [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]], dtype=torch.int32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2295a339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attention_mask_for_packed_sequence(x, token_id, eos: bool = True):\n",
    "    B, T = x.shape\n",
    "    eos_idx = (x.view(-1) == token_id).nonzero(as_tuple=True)[0] + eos\n",
    "    eos_idx_expanded = torch.cat([eos_idx, torch.arange(0,B*T+1,T)]).unique().sort()[0]\n",
    "    normalized_idx = eos_idx_expanded - (eos_idx_expanded // T) * T\n",
    "    normalized_idx = torch.where(normalized_idx == 0, T, normalized_idx)\n",
    "    reps = normalized_idx[1:] - normalized_idx[:-1]\n",
    "    reps = torch.where(reps < 1, normalized_idx[1:], reps)\n",
    "    repeated_idx = torch.repeat_interleave(normalized_idx[1:], reps).view(B,1,T).expand(-1,T,-1)\n",
    "    mask_indices = torch.arange(T).view(1,-1,1).expand(B, -1, T)\n",
    "    mask = torch.ones(T, T, dtype=torch.bool).tril().expand(B, -1, -1)\n",
    "    mask = mask.masked_fill(mask_indices >= repeated_idx, False)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5e1076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 1, 2, 3, 4, 5, 6, 7, 8, 0]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_ids = (torch.arange(B*T) - torch.repeat_interleave(eos_idx_expanded[:-1], reps)).view(B,T)\n",
    "pos_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14130cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]],\n",
       "\n",
       "        [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]], dtype=torch.int32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_attention_mask_for_packed_sequence(batch, tokenizer.eos_token_id).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c42cff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d623b88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f4bc327",
   "metadata": {},
   "source": [
    "Grab tiny stories data from hugging face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e7cd32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 2119719\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset('roneneldan/TinyStories')\n",
    "trn = ds['train']\n",
    "val = ds['validation']\n",
    "trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967927c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 21990\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38f566a",
   "metadata": {},
   "source": [
    "For now, we can just use gpt2 tokenizer to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b102ef73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One day, a little girl named Lily found a needle in her room. She knew it was difficult to play with it because it was sharp. Lily wanted to share the needle with her mom, so she could sew a button on her shirt.\\n\\nLily went to her mom and said, \"Mom, I found this needle. Can you share it with me and sew my shirt?\" Her mom smiled and said, \"Yes, Lily, we can share the needle and fix your shirt.\"\\n\\nTogether, they shared the needle and sewed the button on Lily\\'s shirt. It was not difficult for them because they were sharing and helping each other. After they finished, Lily thanked her mom for sharing the needle and fixing her shirt. They both felt happy because they had shared and worked together.'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "\n",
    "txt = trn[0]['text']\n",
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2724526e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3198, 1110, 11, 257, 1310, 2576, 3706, 20037, 1043, 257]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(txt)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cf1135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One day, a little girl named Lily found a'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(txt)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489b7912",
   "metadata": {},
   "source": [
    "Let's encode them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50878a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(b):\n",
    "    b['text'] = [tokenizer.encode(o, allowed_special={'<|endoftext|>'}) for o in b['text']]\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c69ff67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 2119719\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ds.with_transform(encode)\n",
    "trn = ds['train']\n",
    "val = ds['validation']\n",
    "trn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc3a7c2",
   "metadata": {},
   "source": [
    "Now we have numbers. We have to decode them to read text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ee9952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One d'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn[0]['text'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa90df89",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument 'tokens': Can't extract `str` to `Vec`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrn\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/torch_latest/lib/python3.11/site-packages/tiktoken/core.py:284\u001b[39m, in \u001b[36mEncoding.decode\u001b[39m\u001b[34m(self, tokens, errors)\u001b[39m\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, tokens: Sequence[\u001b[38;5;28mint\u001b[39m], errors: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mreplace\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    273\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Decodes a list of tokens into a string.\u001b[39;00m\n\u001b[32m    274\u001b[39m \n\u001b[32m    275\u001b[39m \u001b[33;03m    WARNING: the default behaviour of this function is lossy, since decoded bytes are not\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    282\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m    283\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m284\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_core_bpe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m, errors=errors)\n",
      "\u001b[31mTypeError\u001b[39m: argument 'tokens': Can't extract `str` to `Vec`"
     ]
    }
   ],
   "source": [
    "tokenizer.decode(trn[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a0f96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 2119719\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset('roneneldan/TinyStories')\n",
    "trn = ds['train']\n",
    "val = ds['validation']\n",
    "trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96694f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyDataset(Dataset):\n",
    "    def __init__(self, txt, tokenizer, ctx_sz):\n",
    "        \"\"\"Tokenize `txt` and chunk with `ctx_sz`\"\"\"\n",
    "        self.inps, self.targs = [], []\n",
    "        toks = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "        \n",
    "        for i in range(0, len(toks) - ctx_sz, ctx_sz):\n",
    "            x = toks[i:i + ctx_sz]\n",
    "            y = toks[i + 1:i + ctx_sz + 1]\n",
    "            self.inps.append(torch.tensor(x))\n",
    "            self.targs.append(torch.tensor(y))\n",
    "    \n",
    "    def __len__(self): return len(self.inps)\n",
    "    \n",
    "    def __getitem__(self, i): return self.inps[i], self.targs[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66fc0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One day, a little girl named Lily found a needle in her room. She knew it was difficult to play with it because it was sharp. Lily wanted to share the needle with her mom, so she could sew a button on her shirt.\\n\\nLily went to her mom and said, \"Mom, I found this needle. Can you share it with me and sew my shirt?\" Her mom smiled and said, \"Yes, Lily, we can share the needle and fix your shirt.\"\\n\\nTogether, they shared the needle and sewed the button on Lily\\'s shirt. It was not difficult for them because they were sharing and helping each other. After they finished, Lily thanked her mom for sharing the needle and fixing her shirt. They both felt happy because they had shared and worked together.'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bab5ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m ctx_sz = \u001b[32m128\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m ds[\u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mds\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m211\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: unhashable type: 'slice'"
     ]
    }
   ],
   "source": [
    "ctx_sz = 128\n",
    "ds['train'] = ds['train'][:211]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746d0ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ds['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40149aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "eot_token = 50256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fdd697",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument 'text': 'list' object cannot be converted to 'PyString'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m trn_ds = \u001b[43mTinyDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrn\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx_sz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m trn_ds[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mTinyDataset.__init__\u001b[39m\u001b[34m(self, txt, tokenizer, ctx_sz)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Tokenize `txt` and chunk with `ctx_sz`\"\"\"\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mself\u001b[39m.inps, \u001b[38;5;28mself\u001b[39m.targs = [], []\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m toks = \u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtxt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallowed_special\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m<|endoftext|>\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(toks) - ctx_sz, ctx_sz):\n\u001b[32m      8\u001b[39m     x = toks[i:i + ctx_sz]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/torch_latest/lib/python3.11/site-packages/tiktoken/core.py:124\u001b[39m, in \u001b[36mEncoding.encode\u001b[39m\u001b[34m(self, text, allowed_special, disallowed_special)\u001b[39m\n\u001b[32m    121\u001b[39m         raise_disallowed_special_token(match.group())\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_core_bpe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallowed_special\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeEncodeError\u001b[39;00m:\n\u001b[32m    126\u001b[39m     \u001b[38;5;66;03m# BPE operates on bytes, but the regex operates on unicode. If we pass a str that is\u001b[39;00m\n\u001b[32m    127\u001b[39m     \u001b[38;5;66;03m# invalid UTF-8 to Rust, it will rightfully complain. Here we do a quick and dirty\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    130\u001b[39m     \u001b[38;5;66;03m# string, but given that this is input we want to support, maybe that's okay.\u001b[39;00m\n\u001b[32m    131\u001b[39m     \u001b[38;5;66;03m# Also we use errors=\"replace\" to handle weird things like lone surrogates.\u001b[39;00m\n\u001b[32m    132\u001b[39m     text = text.encode(\u001b[33m\"\u001b[39m\u001b[33mutf-16\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m\"\u001b[39m).decode(\u001b[33m\"\u001b[39m\u001b[33mutf-16\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mreplace\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: argument 'text': 'list' object cannot be converted to 'PyString'"
     ]
    }
   ],
   "source": [
    "trn_ds = TinyDataset(trn['text'], tokenizer, ctx_sz)\n",
    "trn_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b8462f",
   "metadata": {},
   "source": [
    "### Chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3e776a",
   "metadata": {},
   "source": [
    "Let's try to use very small subset of data to get started. Our goal is to add `eot_token` to the end of each text. Then, chop them up into `seq_len` to create each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03d6089",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 256\n",
    "chunk_sz = seq_len\n",
    "eot_token = 50256\n",
    "eot_tensor = torch.tensor([eot_token])\n",
    "\n",
    "div_by = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8778d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "353"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_len = trn.num_rows // div_by // 3\n",
    "data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a17a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3198,  1110,    11,   257,  1310,  2576,  3706, 20037,  1043,   257,\n",
       "        17598,   287,   607,  2119,    13,  1375,  2993,   340,   373,  2408,\n",
       "          284,   711,   351,   340,   780,   340,   373,  7786,    13, 20037,\n",
       "         2227,   284,  2648,   262, 17598,   351,   607,  1995,    11,   523,\n",
       "          673,   714, 34249,   257,  4936,   319,   607, 10147,    13,   198,\n",
       "          198,    43,   813,  1816,   284,   607,  1995,   290,   531,    11,\n",
       "          366, 29252,    11,   314,  1043,   428, 17598,    13,  1680,   345,\n",
       "         2648,   340,   351,   502,   290, 34249,   616, 10147,  1701,  2332,\n",
       "         1995, 13541,   290,   531,    11,   366,  5297,    11, 20037,    11,\n",
       "          356,   460,  2648,   262, 17598,   290,  4259,   534, 10147,   526,\n",
       "          198,   198, 41631,    11,   484,  4888,   262, 17598,   290,   384,\n",
       "        19103,   262,  4936,   319, 20037,   338, 10147,    13,   632,   373,\n",
       "          407,  2408,   329,   606,   780,   484,   547,  7373,   290,  5742,\n",
       "         1123,   584,    13,  2293,   484,  5201,    11, 20037, 26280,   607,\n",
       "         1995,   329,  7373,   262, 17598,   290, 18682,   607, 10147,    13,\n",
       "         1119,  1111,  2936,  3772,   780,   484,   550,  4888,   290,  3111,\n",
       "         1978,    13])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_tensor = [torch.tensor(o) for o in trn[:data_len]['text']]\n",
    "seq_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f806d9d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3198,  1110,    11,   257,  1310,  2576,  3706, 20037,  1043,   257,\n",
       "        17598,   287,   607,  2119,    13,  1375,  2993,   340,   373,  2408,\n",
       "          284,   711,   351,   340,   780,   340,   373,  7786,    13, 20037,\n",
       "         2227,   284,  2648,   262, 17598,   351,   607,  1995,    11,   523,\n",
       "          673,   714, 34249,   257,  4936,   319,   607, 10147,    13,   198,\n",
       "          198,    43,   813,  1816,   284,   607,  1995,   290,   531,    11,\n",
       "          366, 29252,    11,   314,  1043,   428, 17598,    13,  1680,   345,\n",
       "         2648,   340,   351,   502,   290, 34249,   616, 10147,  1701,  2332,\n",
       "         1995, 13541,   290,   531,    11,   366,  5297,    11, 20037,    11,\n",
       "          356,   460,  2648,   262, 17598,   290,  4259,   534, 10147,   526,\n",
       "          198,   198, 41631,    11,   484,  4888,   262, 17598,   290,   384,\n",
       "        19103,   262,  4936,   319, 20037,   338, 10147,    13,   632,   373,\n",
       "          407,  2408,   329,   606,   780,   484,   547,  7373,   290,  5742,\n",
       "         1123,   584,    13,  2293,   484,  5201,    11, 20037, 26280,   607,\n",
       "         1995,   329,  7373,   262, 17598,   290, 18682,   607, 10147,    13,\n",
       "         1119,  1111,  2936,  3772,   780,   484,   550,  4888,   290,  3111,\n",
       "         1978,    13, 50256,  7454,  2402,   257,   640,    11,   612,   373,\n",
       "          257,  1310,  1097,  3706,  1355,   538,    13,  1355,   538,  6151,\n",
       "          284,   467,  3049,   290,   711,   287,   262,  4252,    13,  1355,\n",
       "          538,   373,   257,  5448,  1097,   780,   339,  1464,   550,   922])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat = torch.cat([torch.cat([s, eot_tensor]) for s in seq_tensor])\n",
    "cat[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb5f5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([71323])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52aa06b6",
   "metadata": {},
   "source": [
    "Let's create batches with `seq_length`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8381a351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_batches = []\n",
    "for i in range(0, cat.shape[0]-seq_len, seq_len):\n",
    "    trn_batches.append(cat[i:i+seq_len])\n",
    "len(trn_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefc4a22",
   "metadata": {},
   "source": [
    "### Dataset (!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb7b90b",
   "metadata": {},
   "source": [
    "Let's create inputs and targets for a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758a6335",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'complete_segments' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m inps = \u001b[43mcomplete_segments\u001b[49m[:, :-\u001b[32m1\u001b[39m]\n\u001b[32m      2\u001b[39m targs = complete_segments[:, \u001b[32m1\u001b[39m:]\n\u001b[32m      3\u001b[39m inps.shape, targs.shape\n",
      "\u001b[31mNameError\u001b[39m: name 'complete_segments' is not defined"
     ]
    }
   ],
   "source": [
    "inps = complete_segments[:, :-1]\n",
    "targs = complete_segments[:, 1:]\n",
    "inps.shape, targs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce24dbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "inps[0][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3229ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "targs[0][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3e53f6",
   "metadata": {},
   "source": [
    "We can create a dataset now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ac4a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds = Dataset(inps, targs)\n",
    "trn_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68240679",
   "metadata": {},
   "source": [
    "We got the training dataset. Now, we can get the validation dataset with the same approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e86d1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_len = val.num_rows // div_by * 10\n",
    "val_data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcddecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_seq_tensor = [torch.tensor(o) for o in val[:val_data_len]['text']]\n",
    "val_seq_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01220591",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_cat = torch.cat([torch.cat([s, eot_tensor]) for s in val_seq_tensor])\n",
    "val_cat[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380f87d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_num_complete_segments = val_cat.size(0) // chunk_sz\n",
    "val_num_complete_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabd13d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_complete_segments = val_cat[:val_num_complete_segments * chunk_sz].view(-1, chunk_sz)\n",
    "val_complete_segments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faeb46a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_inps = val_complete_segments[:, :-1]\n",
    "val_targs = val_complete_segments[:, 1:]\n",
    "val_inps.shape, val_targs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bade8855",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = Dataset(val_inps, val_targs)\n",
    "val_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08757872",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f409779a",
   "metadata": {},
   "source": [
    "We need a dataloader with the batch size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1646800e",
   "metadata": {},
   "source": [
    "TODO: do `drop_last=True` for training dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f8ee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 4\n",
    "\n",
    "trn_dl, val_dl = get_dls(trn_ds, val_ds, bs)\n",
    "dls = DataLoaders(trn_dl, val_dl)\n",
    "xb,yb = next(iter(trn_dl))\n",
    "xb.shape,yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c656d492",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb[:5], yb[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09aec692",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa3adb4",
   "metadata": {},
   "source": [
    "We make the model using transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4a6a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bad50e3",
   "metadata": {},
   "source": [
    "### MultiHeadAttention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55093be6",
   "metadata": {},
   "source": [
    "Here's the `MultiHeadAttention` with Causal attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7811bd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "x = torch.randn((2, 2, 3)) # (bs, ctx_len, d_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5a55ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, ctx_len, n_head, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % n_head == 0), \"d_out must be divisible by num_heads\"\n",
    "        self.n_head = n_head\n",
    "        self.d_in = d_in\n",
    "        self.d_out = d_out\n",
    "        self.head_dim = d_out // n_head\n",
    "        self.w_q = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.w_k = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.w_v = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.register_buffer(\"mask\", torch.triu(torch.ones((ctx_len, ctx_len)), diagonal=1).bool())\n",
    "    \n",
    "    def forward(self, x): \n",
    "        bs, num_tokens, d_in = x.shape\n",
    "        q = self.w_q(x)  # (bs, num_tokens, d_out)\n",
    "        k = self.w_k(x)\n",
    "        v = self.w_v(x)\n",
    "        \n",
    "        q = q.view(bs, num_tokens, self.n_head, self.head_dim)  # (bs, num_tokens, n_head, head_dim)\n",
    "        k = k.view(bs, num_tokens, self.n_head, self.head_dim)\n",
    "        v = v.view(bs, num_tokens, self.n_head, self.head_dim)\n",
    "        \n",
    "        q = q.transpose(1,2) # (bs, n_head, num_tokens, head_dim)\n",
    "        k = k.transpose(1,2)\n",
    "        v = v.transpose(1,2)\n",
    "        \n",
    "        attn_scr = q@k.transpose(2,3) # (bs, n_head, num_tokens, num_tokens)\n",
    "        attn_scr = attn_scr.masked_fill(self.mask[:num_tokens, :num_tokens], -torch.inf)\n",
    "        attn_wt = torch.softmax(attn_scr / k.shape[-1]**0.5, -1)\n",
    "        \n",
    "        ctx_vec = attn_wt@v  # (bs, n_head, num_tokens, head_dim)\n",
    "        ctx_vec = ctx_vec.transpose(1,2).reshape(bs, num_tokens, -1) # (bs, num_tokens, d_out)\n",
    "        \n",
    "        # concat\n",
    "        return ctx_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2907f359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.0806, -0.0211,  0.1296, -0.0414],\n",
       "          [ 0.2287,  0.1592, -0.0296, -0.1997]],\n",
       " \n",
       "         [[ 0.6081,  0.0087,  0.2989, -0.4998],\n",
       "          [ 0.1026,  0.0422,  0.3105, -0.2781]]], grad_fn=<UnsafeViewBackward0>),\n",
       " torch.Size([2, 2, 4]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mha = MultiHeadAttention(d_in=3, d_out=4, ctx_len=2, n_head=2)\n",
    "mha(x), mha(x).shape  # Outputs (bs, num_tokens, d_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a2119c",
   "metadata": {},
   "source": [
    "### FeedForward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbab0dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, act=nn.ReLU()):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(in_dim, hidden_dim)\n",
    "        self.act = act\n",
    "        self.l2 = nn.Linear(hidden_dim, in_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.l2(self.act(self.l1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333b6ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "x = torch.randn(4)\n",
    "ff = FeedForward(4, 4*4)\n",
    "ff(x), ff(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36280c0f",
   "metadata": {},
   "source": [
    "### Transformer Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd61c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, emb_dim, ctx_len, n_head, drop_out=0, ff_mult=4, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(emb_dim)\n",
    "        self.ln2 = nn.LayerNorm(emb_dim)\n",
    "        self.mha = MultiHeadAttention(emb_dim, emb_dim, ctx_len, n_head, qkv_bias=qkv_bias)\n",
    "        self.do = nn.Dropout(drop_out)\n",
    "        self.ff = FeedForward(emb_dim, emb_dim*ff_mult)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        skip1 = x\n",
    "        x = self.ln1(x)\n",
    "        x = self.mha(x)\n",
    "        x = self.do(x)\n",
    "        x = x + skip1\n",
    "        \n",
    "        skip2 = x\n",
    "        x = self.ln2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.do(x)\n",
    "        x = x + skip2\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39725b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "x = torch.randn((2, 2, 3)) # (bs, ctx_len, d_in)\n",
    "tb = TransformerBlock(emb_dim=3, ctx_len=2, n_head=1)\n",
    "tb(x), tb(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d382d7ae",
   "metadata": {},
   "source": [
    "### GPT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825cd1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'n_tb': 1,    # num transformer blocks\n",
    "    'vocab_sz': 50257,\n",
    "    'emb_dim': 48,\n",
    "    'ctx_len': seq_len,\n",
    "    'n_head': 1,\n",
    "    'drop_out': 0,\n",
    "    'drop_out_tb': 0,  # dropout within transformer blocks\n",
    "    'ff_mult': 4,\n",
    "    'qkv_bias': False,\n",
    "     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cf425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(cfg['vocab_sz'], cfg['emb_dim'])\n",
    "        self.pos_emb = nn.Embedding(cfg['vocab_sz'], cfg['emb_dim'])\n",
    "        self.do = nn.Dropout(cfg['drop_out'])\n",
    "        self.tb = nn.Sequential(\n",
    "            *[TransformerBlock(cfg['emb_dim'], cfg['ctx_len'], cfg['n_head'], cfg['drop_out_tb'],\n",
    "                              cfg['ff_mult'], cfg['qkv_bias']) for _ in range(cfg['n_tb'])])\n",
    "        self.final_ln = nn.LayerNorm(cfg['emb_dim'])\n",
    "        self.final_l  = nn.Linear(cfg['emb_dim'], cfg['vocab_sz'])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        bs, seq_len = x.shape\n",
    "        tok = self.token_emb(x)\n",
    "        pos = self.pos_emb(torch.arange(seq_len, device=x.device))\n",
    "        x = self.do(tok + pos)\n",
    "        x = self.tb(x)\n",
    "        x = self.final_ln(x)\n",
    "        x = self.final_l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bb2212",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = xb[:3]\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2ab458",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "model = GPTModel(cfg)\n",
    "logits = model(batch)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2225f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_params(model): return sum(p.numel() for p in model.parameters())\n",
    "total_params = get_total_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c5a418",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.token_emb.weight.shape, model.final_l.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5c38f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_memory(model):\n",
    "    total_params = get_total_params(model)\n",
    "    total_size_bytes = total_params * 4   # Assuming fp32\n",
    "    # Convert to megabytes\n",
    "    total_size_mb = total_size_bytes / (1024 * 1024)\n",
    "    print(f\"Total params: {total_params:,}\")\n",
    "    print(f\"Total size: {total_size_mb:.2f} MB\")\n",
    "\n",
    "get_total_memory(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f022896",
   "metadata": {},
   "source": [
    "### Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc54096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx is (batch, n_tokens) array of indices in the current context\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]  # Crop current context if it exceeds the supported context size\n",
    "        with torch.no_grad(): logits = model(idx_cond)         # (bs, n_tokens, vocab_sz)\n",
    "        logits = logits[:, -1, :]                              # (bs, vocab_sz)\n",
    "        probas = torch.softmax(logits, dim=-1)                 # (bs, vocab_sz)\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (bs, 1)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)                # (bs, n_tokens+1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfd542d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_context = \"Hello, I am\"\n",
    "\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"encoded:\", encoded)\n",
    "\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "print(\"encoded_tensor.shape:\", encoded_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e879d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval() # disable dropout\n",
    "\n",
    "out = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=encoded_tensor, \n",
    "    max_new_tokens=6, \n",
    "    context_size=cfg[\"ctx_len\"]\n",
    ")\n",
    "\n",
    "print(\"Output:\", out)\n",
    "print(\"Output length:\", len(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2125798",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816caf06",
   "metadata": {},
   "source": [
    "For convenience, we create functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511281b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16486221",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_token_ids('wassup my dawg', tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880ff652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e130b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids_to_text(text_to_token_ids('wassup my dawg', tokenizer), tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1658bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=cfg[\"ctx_len\"]\n",
    ")\n",
    "\n",
    "token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836abf4a",
   "metadata": {},
   "source": [
    "Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f01991b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in trn_dl:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_dl:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e846d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in trn_dl:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_dl:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e49f700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "#     input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "#     logits = model(input_batch)\n",
    "#     loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "#     return loss\n",
    "\n",
    "\n",
    "# def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "#     total_loss = 0.\n",
    "#     if len(data_loader) == 0:\n",
    "#         return float(\"nan\")\n",
    "#     elif num_batches is None:\n",
    "#         num_batches = len(data_loader)\n",
    "#     else:\n",
    "#         # Reduce the number of batches to match the total number of batches in the data loader\n",
    "#         # if num_batches exceeds the number of batches in the data loader\n",
    "#         num_batches = min(num_batches, len(data_loader))\n",
    "#     for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "#         if i < num_batches:\n",
    "#             loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "#             total_loss += loss.item()\n",
    "#         else:\n",
    "#             break\n",
    "#     return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efa9006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d823ed63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # Note:\n",
    "# # Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
    "# # which is approximately 2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
    "# # However, the resulting loss values may be slightly different.\n",
    "\n",
    "# #if torch.cuda.is_available():\n",
    "# #    device = torch.device(\"cuda\")\n",
    "# #elif torch.backends.mps.is_available():\n",
    "# #    device = torch.device(\"mps\")\n",
    "# #else:\n",
    "# #    device = torch.device(\"cpu\")\n",
    "# #\n",
    "# # print(f\"Using {device} device.\")\n",
    "\n",
    "\n",
    "# model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "\n",
    "# torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n",
    "\n",
    "# with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "#     train_loss = calc_loss_loader(trn_dl, model, device)\n",
    "#     val_loss = calc_loss_loader(val_dl, model, device)\n",
    "\n",
    "# print(\"Training loss:\", train_loss)\n",
    "# print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4747a7b",
   "metadata": {},
   "source": [
    "## Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bca503",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torcheval.metrics import  MulticlassAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ba3aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(pred, targ): return F.cross_entropy(pred.flatten(0, 1), targ.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83922cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'n_tb': 4,    # num transformer blocks\n",
    "    'vocab_sz': 50257,\n",
    "    'emb_dim': 96*2,\n",
    "    'ctx_len': seq_len,\n",
    "    'n_head': 4,\n",
    "    'drop_out': 0,\n",
    "    'drop_out_tb': 0,  # dropout within transformer blocks\n",
    "    'ff_mult': 4,\n",
    "    'qkv_bias': False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662065d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "model = GPTModel(cfg)\n",
    "start_context = \"Once upon a time, there lived a bunny in a field. Her name was Lucy. Lucy loved to have feasts and parties with her bunny friends. One day, when Lucy was about to leave for a feast at a friend's house, she realized she's starting to feel sick. She was so weak she could\"\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=cfg[\"ctx_len\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d44a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMMetricsCB(MetricsCB):\n",
    "    def __init__(self, *ms, **metrics):\n",
    "        super().__init__(*ms, **metrics)\n",
    "    \n",
    "    def after_batch(self, learn):\n",
    "        x,y,*_ = to_cpu(learn.batch)\n",
    "        for m in self.metrics.values(): m.update(to_cpu(learn.preds.flatten(0, 1)), y.flatten())\n",
    "        self.loss.update(to_cpu(learn.loss), weight=len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd56e4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs = [LLMMetricsCB(accuracy=MulticlassAccuracy()), ProgressCB(), TrainCB()]\n",
    "learn = Learner(model, dls, loss_func=loss_fn, cbs=cbs)\n",
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfba866",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find(gamma=1.1, max_mult=2, start_lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639085e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "model = GPTModel(cfg)\n",
    "cbs = [LLMMetricsCB(accuracy=MulticlassAccuracy()), ProgressCB(), TrainCB()]\n",
    "learn = Learner(model, dls, loss_func=loss_fn, cbs=cbs)\n",
    "learn.fit(10, lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0cf04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=cfg[\"ctx_len\"])\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fd832b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d027adbf",
   "metadata": {},
   "source": [
    "Hyperparameters: Learning rate, optimizer: Gradient clipping, batch size: 4k\n",
    "\n",
    "Mixed precision -> weight decay needed. (bfloat16)\n",
    "\n",
    "Distributed data parallel: Split data into 2 and use graident accumulation\n",
    "\n",
    "Fully Sharded data parallel: shard of data into GPUs as layer goes.\n",
    "\n",
    "CPU offload\n",
    "\n",
    "DataLoader: Use for loop.\n",
    "\n",
    "!!!!! Look at the data. !!!!!\n",
    "\n",
    "Eval: next token accuracy, loss\n",
    "\n",
    "Try GLU instead of ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87eff7e9",
   "metadata": {},
   "source": [
    "Tips: \n",
    "\n",
    "1. Try simple model.\n",
    "2. Weight Tying.\n",
    "3. Hyperparameter sweep\n",
    "4. minbpe\n",
    "\n",
    "\n",
    "Get sequencing packing to work -> iterate faster\n",
    "flash attention."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
